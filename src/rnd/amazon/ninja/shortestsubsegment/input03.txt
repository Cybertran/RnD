Handbook & Prospectus-PhD/MPhil IGNOU – AT A GLANCE The Indira Gandhi National Open University (IGNOU), established by an Act of Parliament in 1985, provides seamless education to the people of India transcending the barriers of place, age, caste, pace, creed, and religion. The objectives of the University are : • Democratizing higher education by taking it to the doorsteps of the learners; • Providing access to high quality education to all irrespective of age, region, religion, and gender; • Offering need-based academic programmes having professional and vocational orientation; • Promotion and development of open and distance learning system; and • Setting and maintaining standards in distance education in the country. The special features of IGNOU can be listed thus : • International jurisdiction; • Flexible admission rules; • Continuous upgrade of information and communication technologies; • Nationwide student support services network; • Cost-effective programmes; • Modular approach to programmes; and • Resource sharing, collaboration and networking with Conventional Universities, Open Universities and Educational Institutions/Organizations. Some notable facts about IGNOU are as under:  Emergence of IGNOU as the largest Open University system in the world;  Student enrolment touching 3 million mark;  Pan-India network of learner support centres;  Statutory declaration of Term-End-Exam results within 45 days;  Academic programmes approaching 500;  Recognition as a Centre of Excellence in Distance Education by the Commonwealth of Learning (1993);  Award of Excellence for Distance Education Materials by the Commonwealth of Learning (1999);  IGNOU working as the nodal agency for round-the-clock Educational Channels.  UNESCO declaring IGNOU as the largest institution of higher learning in the world in 2010. ( These channels and regular transmissions are done from the studio at Electronic Media Production Centre, IGNOU ) ; and Research Unit, IGNOU 5 5Handbook & Prospectus-PhD/MPhil RESEARCH POLICY Research is an academic institution’s most lasting contribution to society. Research activities are normally composed of two main aspects – the production of theoretical knowledge and an integral experiential encounter with subjects constituting the society. Indeed, the body of published material built up by hundreds of researcher-writers and creation of a massive data base from which to retrieve information regularly and which is constantly augmented, corrected and revised is a natural corollary of research activities. This body of published material and the data base constitute the research canon that is central to the functioning of a reputed academic institution like IGNOU and that forms a material expression of its scholarship. In about twenty years, since its inception, IGNOU’s Research Programme has shifted gear from the initial focus on distance education and its methodologies and practices to vital contributions to both theoretical and empirical research in various academic disciplines and interdisciplinary areas. This shift has been smooth without any major impediment and has yielded the desired objective of the creation of a viable ‘research canon’. The core of our research endeavour is harnessed to the creation and continual expansion of this research canon. A principal objective of IGNOU’s Research Programme has been to maintain a strong focus on the flow of theoretical ideas and to connect it with the empirical works of subject oriented researches in sciences, social sciences, humanities, management, technology and other disciplines offered by the University as areas of probe and investigation from time to time. There has to be a conjunctive mix of theoretical ideas and extended probes into concrete social situations. It is now commonly agreed that the object of the subject/discipline oriented research is to delineate a methodology of investigation that guarantees the discovery of ‘truth’ and to prescribe that methodology as canonical imperatives which practicing researchers are obliged to follow. Our research programme has indeed had great practical import; studying the philosophy of research and training into research methods have become important ingredients of our research programme. RESEARCH DEGREE PROGRAMMES General Eligibility Criteria and Selection Procedure A candidate is eligible for Admission and Registration for the MPhil/PhD programme provided he/she has qualified : 6 (a) For the award of Master’s Degree of any recognized University/other qualification recognized as equivalent thereto in such fields of study as are notified for the purpose from time to time by the University. The minimum qualifying marks are 55% at Post Graduation level (50% in case of reserved categories), and (b) In the Entrance Examination conducted by the University at the national level on the pattern of UGC/CSIR. Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil However, candidates holding MPhil degree or those candidates who have cleared JEST of DAE or UGC-NET or GATE of IIT or those having at least five years of related Teaching/Practical/Industry/Professional experience as validated by the respective Disciplines may be exempted from appearing in the Entrance Examination. N. B.: Additional eligibility conditions have been prescribed by individual Disciplines. Candidates are advised to refer these details in the Table given at the end of the Prospectus and ensure that they meet the desired condition/s. Candidates who are employees of IGNOU shall have completed at least two year service in the University on the date they submit the Application for admission. Programme Fee The PhD Programme Fee is Rs. 7,000/- per annum for 2 years. MPhil candidates are to pay one-time fee of Rs. 10,500/- which is inclusive of the Course Fee. Individual Disciplines may assign course work for PhD candidates for which additional fee may be charged (The fee as stated above is subject to revision as decided by the University from time-to-time) . Duration The maximum durations of the PhD Programme and the MPhil programme are 5 years and 4 years respectively. Reservation IGNOU follows the provisions of the Government of India Policy on Reservation for admission to its Research Degree Programmes. FORTY STEPS TO RESEARCH DEGREE In this section, the important steps which doctoral students are expected to follow are listed. We assure that if you proceed along these steps you should be able to complete your doctoral work in a smooth and effective way. You are advised to keep checking on these steps as you pursue your research. Steps before Admission into Research Programmes 1. When you first aspire to do your PhD or MPhil through IGNOU you should log on to the IGNOU website at www.ignou.ac.in. The Home Page opens and you get the link Research Degree Programmes there. You will here find detailed information on the Research Degree Programmes of IGNOU viz., MPhil and PhD You would do well to carefully read and even download this information and choose your area of research based on this information. 2. Now look for Admission Advertisement on the Website. The University advertises for research programmes twice a year, once for the January cycle and second time for the July cycle. The advertisement is placed, almost four months in advance of the impending cycle, on the University website indicating the Disciplines which are offering Research Programmes for particular cycle. Please note that all the Disciplines may not offer Research Programme in both cycles. Research Unit, IGNOU 7 7Handbook & Prospectus-PhD/MPhil 3. The Application Form is also placed on the Website. You may download the Application Form and fill in the details. Remember you should respond to each and every item contained in the Application Form. If there is inadequate or wrong information, your Application Form is likely to be rejected. 4. You must ensure that the Application Fee, as indicated in the Advertisement, in the form of Demand Draft drawn in favour of IGNOU payable at New Delhi is made ready before the last date indicated in the Advertisement and is attached with your Application Form. 5. You must ensure that copies of all documents testifying the information submitted by you in the Application are attached along with your Application Form. 6. If you are required to attach a research proposal with your Application Form, you must study the Guidelines : Research Proposal given below and prepare a Research Proposal accordingly. Please note that if you intend to have a supervisor who is not an IGNOU faculty, you will have to attach a CV of the supervisor and a letter of consent from the proposed Supervisor. 7. Kindly note that every Discipline specifies its own criteria for admitting students. Therefore, you are advised to carefully read and understand the requirements of the Discipline you are applying for as given in the Table attached at the end of the Prospectus. 8. Upon the receipt of your Application Form at the Research Unit, IGNOU, an initial scrutiny will be made to examine if all the essential conditions of eligibility are met and relevant documents are attached with the Application Fee. 9. Thereafter, all information contained in your Application Form is recorded in the Master Data Base of the Research Unit. The Application Form is then sent to the concerned Discipline through the related School of Study for further consideration. 10. There is a Doctoral Committee in each Discipline which is vested with the power to decide and manage admissions in the Research Programmes (see Comprehensive Guidelines). The Doctoral Committee will examine the Application Form and may get in touch with you to advise you to revise and resubmit your Research Proposal for which reasonable time will be given to you. The Doctoral Committee will thus shortlist candidates who are found to be suitable for making their presentations before the Doctoral Committee. 11. At the same time, Application Forms of candidates who are supposed to take the Entrance Examination before facing the Interview will be screened and checked for eligibility. The Discipline-wise list of eligible candidates who will appear in the Entrance Examination will be displayed on the Website. Hall Tickets enabling the candidates to take the Entrance Examination will be dispatched by the Research Unit and also displayed on our Website. In case, you do not receive the Hall Ticket dispatched by post, you are advised to download the same from the Website and appear in the Examination. You are advised to regularly check our Website for Research related information and notifications. 8 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil 12. The Research Unit, in cooperation with Teaching Faculty of the University, will conduct the Entrance Examination on the date fixed for the purpose and announced in advance to help you make your travel arrangements. Generally the Entrance Examinations are organized in the last week of April and September for respective cycles of admission beginning July and January every year. 13. Candidates who are successful in the Entrance Examination will be duly informed and called for Interview/Viva/Presentation of Research Proposal before the Doctoral Committee of the Discipline. 14. Those candidates who are exempted from appearing in the Entrance Examination will also be called to make their presentations before the Doctoral Committee. Here again, the Doctoral Committee may give guidance on your Research proposal. It is at the discretion of the Doctoral Committee to conduct Interview/Viva/Presentations according to the convenience of the Experts. 15. The details of candidates who are finally selected by the Doctoral Committee along with the allotted Supervisor/s in each case will be sent to the School Board for consideration. In the case of MPhil, the Topic of Dissertation will also be decided at the time of Interview/Viva and will be recommended to School Board for consideration. 16. The admission of the candidates recommended by the School Board will be placed for final approval to the Research Council/Research Council Standing Committee after which an Offer Letter for provisional Admission/Registration will be sent by the Research Unit to the candidates. The Offer Letter will inform the candidate about his selection and advise her/him to deposit the required fee for the MPhil/PhD Programme within a stipulated time. 17. It is only when you deposit the fee that you are admitted to the Research Programme technically. You will then be assigned an enrolment number by the Research Unit. Please note that failure to deposit the fee within the stipulated time will result in the cancellation of your admission. 18. If your topic of research and the Research Proposal are not finalised at the time of Interview you may be given a maximum of six month time to work on your research topic to finalize the title, methodology, research approach, and such aspects of your work as are advised by the Doctoral Committee. You will be guided by your Supervisor/s in this matter. You should finalize your topic and Research Proposal within six months of your provisional Admission/Registration. In case you fail to do so, your admission will be cancelled and no refund of fees will be made. Please understand that it is your responsibility to finalize the Research Topic and Research Proposal within the six month period. 19. After the finalization of your Research Proposal and its approval by the Research Council/Research Council Standing Committee you will be issued a Confirmation Letter. With this your admission into the University’s Research Programme is formalised. Research Unit, IGNOU 9 9Handbook & Prospectus-PhD/MPhil Steps after Admission into Research Programmes Course Work 20. At the time of approving your Research Proposal the Doctoral Committee may also assign Course Work related to the thrust areas of research and research methodology. The details of Course Work, evaluation methodology and the teaching schedule will be given by the Research Programme Coordinator. 21. Generally, Course Work is assigned to those candidates who are seeking admission to MPhil programme and to the PhD candidates who have not done MPhil However, Course Work can also be assigned by the Doctoral Committee to PhD candidates who have done MPhil 22. The Course Work will have to be completed in a maximum period of one year. A candidate shall be deemed to have completed the Course Work successfully on obtaining at least C Grade (measured on a five point scale) or 50% of the maximum score in the Course Work. Progress through Research 23. Research is a senior level study. You should take responsibility for the progress of your research which will be monitored by your Supervisor/s. You are supposed to submit Six Monthly Progress Reports of your research work on the prescribed format given in the Prospectus. You are advised to submit your Progress Report to the Supervisor for his considerations and placement before the Doctoral Committee on a regular basis and within the stipulated time. 24. As a Research Student you will have to give Two Seminar Presentations during your tenure as a Research Scholar and submit a Certificate to this effect in the prescribed format to the Research Unit. (MPhil candidates are exempted). 25. You are also required to publish at least One Research Paper (Published/Accepted for publication) in a peer reviewed/refereed Journal and submit a Certificate to this effect in the prescribed format to the Research Unit before submitting the PhD Thesis. (MPhil candidates are exempted). 26. Before the submission of the thesis, a Pre-submission Seminar will be organized by your Supervisor. The seminar will be open to all. The report of this seminar, incorporating suggestions for improvement, if any, will be sent to Research Unit for records. The Supervisor will ensure that the suggestions given at the Pre-submission Seminar are incorporated by you in the Thesis and a Certificate to this effect in the prescribed format is submitted to the Research Unit. (MPhil candidates are exempted). Dissertation/Thesis Submission 27. On the completion of your study, you shall submit a Summary of the Thesis in electronic form and 5 hard copies of the same (3000-5000 words), duly approved by the Supervisor/s at least 45 days before the submission of Thesis. (MPhil candidates are exempted). 10 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil 28. Thereafter, four hard bound copies of the Thesis along with one in the electronic form on a CD shall be submitted by you to the Research Unit through your Supervisor/s and the Director of the School. The Thesis shall include a Certificate signed by the Supervisor/s about the originality of your research work in the prescribed format. In case of MPhil candidates, two hard bound copies of the dissertation along with one in the electronic form on a CD shall be submitted to the Research Unit through the Director concerned. The dissertation shall include a certificate signed by the Supervisor about the originality of the work. 29. The thesis will be examined by three External Experts nominated by the Vice Chancellor from a list of seven experts submitted by the Supervisor/s through the School Board concerned. In case of MPhil, the dissertation will be examined by one external examiner nominated by the Vice Chancellor from a list of at least 5 experts submitted by the supervisor through the School Board concerned. The report of the Examiner/s in each case will be submitted on the prescribed format. 30. In case any examiner suggests certain modifications and re-submission of the Thesis, the same will be communicated to you and you will be asked to re-submit the Thesis incorporating all the modifications within six months. The Supervisor/s will ensure that the suggestions of the examiner are adequately addressed. The modified Thesis shall be referred again to the examiner concerned for re-evaluation. 31. If one of the examiners does not recommend the Thesis for the award of a PhD degree, the Thesis shall be referred to another examiner for independent evaluation. However, if this examiner also rejects the Thesis, the Thesis shall be rejected by the University. Viva-Voce Examination 32. The reports received from Examiners of the thesis will be shown to you beforehand so as to enable you to address the issues raised therein while preparing to defend the Thesis during the viva-voce examination. 33. An open defence of the Thesis in the viva-voce shall be conducted at IGNOU by a panel comprising one of the external examiners nominated by the Vice Chancellor and the principal supervisor of the candidate. The Director concerned shall be the Chairperson of the panel. The supervisor shall be the convener of the panel. The date for open defence, venue, and topic of the thesis with a brief abstract shall be communicated to the Research Unit by the Supervisor. This will also be given wide publicity to facilitate larger participation in the session. In case of MPhil, after evaluation of the dissertation by the examiner, the viva-voce shall be conducted by a panel comprising the external examiner, the supervisor of the candidate, as Convener of the panel, and the Director concerned as the Chairperson of the panel. The evaluated marks will be given on prescribed format. 34. Successful completion of the MPhil Programme will require the candidate to secure minimum 50% marks in each course, 50% in the dissertation work and 50% in viva-voce. Research Unit, IGNOU 11 11Handbook & Prospectus-PhD/MPhil 35. In case the candidate does not obtain the qualifying marks in the dissertation, the evaluation report shall be sent to the Supervisor who can guide the research student in improving the dissertation for re-submission. This provision can be invoked only once. 36. A joint report of the viva-voce examination of the PhD candidate will be submitted to the Research Unit by the Director of the School concerned on the prescribed format. Award of the Degree 37. All evaluation reports and the joint report giving the final recommendation shall be placed before the Vice Chancellor for approval. The Vice Chancellor’s decision will be placed before the Academic Council through the Research Council. 38. After approval by the Academic Council/Research Council, notification about the award of Doctoral Degree shall be issued by the Student Evaluation Division (SED) of the University. 39. Pending the approval of the Academic Council, a Provisional Notification of the award of PhD will be issued by the Student Evaluation Division (SED). 40. Congratulations! You have meticulously worked through your research topic and deservingly earned your Doctorate. CHECK LIST Before submission of Dissertation for MPhil or Thesis for PhD you are advised to ensure that the requirements specified in this check list are fulfilled : For MPhil Programme (1) Completion of Course Work. (2) Certification of Originality of Dissertation Work by your Supervisor(s). For PhD Programme 12 (1) Registration for 2nd/3rd year through payment of fee for two/three years as applicable. (2) Submission of all six monthly progress report for the period of research. (3) Completion of Course Work, if applicable. (4) Presentation of at least two Seminar/Conference Papers. (5) Publication/Acceptance of at least one Research Paper in a referred Journal. (6) Completion of Pre-submission Seminar. (7) Certification of Originality of your research by the Supervisor(s). Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil GUIDELINES : RESEARCH PROPOSAL Research Proposal is the statement of your scheme of research. You have decided the topic which you want to explore. Now is the time to put some questions to your own self. What is the purpose of your research? It is not supposed to be just a rehash of what other people have said on the subject. You would certainly like to contribute something original to the world of knowledge through the proposed research. It is therefore important to organize your proposed scheme in the form of a cogent and viable write-up. This write-up makes for your research proposal. We give below the main components of a research proposal as is generally expected by our decision taking bodies, viz. Doctoral Committee, School Board and Research Council. It should contain the following : (1) Title Give proposed Research Title. ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (2) Introduction Give a broad description of proposed Research Work. Explain important concepts in the study (use more space if needed). ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (3) Objectives Establish the rationale for undertaking the study in the background of work done on that theme or the logic of the originality of your research work; identify gaps in the knowledge and justify the need for the present study (use more space if needed). ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (4) Give broad aims of the study and also the specific objectives. ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (5) State the hypothesis, if any, which the research intends to examine. In case the study does not contain explicit hypothesis it may be mentioned so. ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ Research Unit, IGNOU 13 13Handbook & Prospectus-PhD/MPhil (6) Review of Literature Review some important and related Published Works and analyze them in the context of your study (use more space if needed). ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (7) Methodology Write a paragraph on the Research Methodology you propose to use (use more space if needed). ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (8) Bibliography Selected list of references used and proposed for the study should be mentioned (use more space if needed). ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ Note : The Research Proposal should be between 3000-5000 words. SCHOLARSHIPS AND FELLOWSHIPS 14 (a) Candidates who have qualified UGC-NET, GATE, JEST, etc. and have been awarded Fellowships by these and such other agencies are welcome to enrol for Doctoral Studies at IGNOU. The University will disburse the fellowships awarded to them as per the rules of the awarding agencies. (b) The University also awards Fellowships (IGNOU-Research Fellowship) to full time PhD students of IGNOU. The objective of the IGNOU-RF scheme is to provide opportunities to full time research students who have no other financial support to undertake research leading to PhD degree in the disciplines offered by IGNOU. The tenure of IGNOU-RF is initially for a period of two years from the date of the award. If the research work is found satisfactory, fellowship for an additional year will be awarded to the candidate. There is no provision for extension beyond three years. The value of the award is Rs. 5000/- pm for all three years presently. (c) The University has the Research and Teaching Assistantship Scheme (RTA) which provides opportunities to the researchers to undertake advanced studies and research and teaching in the field of Open and Distance Learning. RTAs will have to work as full time students in the University and will have to assist the Faculty in teaching related activities. The tenure of the Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil award is initially for a period of three years which is extendable by two years (on annual basis) based on satisfactory progress evaluated every year. There is no provision for extension beyond five years. The value of RTA award is Rs. 18,000/- per month with an annual contingent grant of Rs. 20,000/- for three years. SOME IMPORTANT RULES Some important rules governing the Research Programme are as follows : (1) All registrations to MPhil/PhD Programmes shall be provisional and the same shall be confirmed according to the procedures prescribed by the Research Council from time to time. (2) A candidate, who has been offered registration, shall deposit the prescribed registration fee within a period of three months from the date of registration, failing which his/her registration will be treated as cancelled. However, under special circumstances, extension up to six months may be given. The decision of the University in such matters will be final. (3) The registration of a student may be cancelled for any of the following reasons : (i) Non-payment of fees. (ii) Unsatisfactory progress. (iii) Non-compliance with the provisions of the Ordinance and other Regulations of the University. (iv) Failure to submit the Dissertation/Thesis within the time limit prescribed. (4) The Research Council may consider requests for re-registration from students whose registration is cancelled. An application for re-registration, if made within a period not exceeding six months from the cancellation of the registration, may be considered only on the recommendation of the supervisor(s) and the School Board as the case may be. RESEARCH RESOURCES University Library The IGNOU library is the most resourceful information centre in the country in the field of Distance Education. The library has the largest collection of books, journals and other related materials in the field of Distance Education throughout the country. It was established in 1986 in tune with the objectives of IGNOU. The primary mission of the library is to support the educational and research programmes of the University by providing physical and intellectual access to information. In accordance with the objectives of the University, the library aims to develop a comprehensive collection of documents useful to readers. The IGNOU library uses LIBSYS, Research Unit, IGNOU 15 15Handbook & Prospectus-PhD/MPhil an integrated Library Management software package with all the modules for the library housekeeping operations. Using LIBSYS Web OPAC, users can search the Library online catalogue by Author, Title, Subject and Keywords. The library also provides the facility of accessing e-resources. Chairs of the University The University has identified certain areas in the knowledge domain for focused efforts aimed at knowledge advancement as also extension work wherever possible and has instituted several Chairs for this purpose. The Chairs are Academic Resources which provide opportunity to the researchers to enrich themselves in numerous ways. A brief mention of such Chairs is presented below : (i) Bahadur Shah Zafar Chair established to commemorate the 150 th Anniversary of the First War of Independence which is supported by the grants released by the Ministry of Culture, Govt. of India. (ii) The Chair for Sustainable Development was established by the University to mark the decade of education for Sustainable Development by the United Nations. The main focus of the Chair is the promotion of research and education in the field of sustainability science. (iii) Visualizing that satellite communications will play a critical role in the growth of the Open and Distance Learning System in the country, the University in collaboration with the ISRO has established the ISRO Chair for Satellite Communication Education in IGNOU The Chair will undertake research and educational activities in the application of satellite communication to education. (iv) The Tagore Chair for Indian Literature is located in the School of Humanities. The Chair is established to organize symposia, seminars and undertake researches in Indian Literature. (v) The Catholic Bishops Council of India has established the CBCI-IGNOU Chair in the University to address the needs of the disadvantaged sections of the society through educational programmes, extension activities and research. (vi) The Chair for Technology enabled Education is a University level located in the School of Education. The Chair will take up various academic activities for effective utilization of technology for development, planning and transaction of the curriculum. (vii) The Rajiv Gandhi Chair for Contemporary Studies was established by MHRD to conduct research and studies on themes close to the heart of the former Prime Minister. The objective of the Chair is to create National Centres for academic deliberations and action oriented research in the frontier areas of contemporary relevance for improving the quality of life and life management systems. (viii) The UNESCO Chair in Teacher Education through Distance Mode acts as a focal point for activities implemented in the field of teacher education through distance mode. (ix) 16 The Dr. B. R. Ambedkar Chair on Social Change and Development focuses on dissemination of the ideas and thoughts of Dr. Ambedkar. It also undertakes projects for documenting the history of the movements which tried to remove the caste system. Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil (x) The Raman Chair for Mathematics and Science Education is situated in the School of Sciences aims at mapping out policies for national initiatives for furthering the cause of education in the fields. (xi) The Visvesvarayya Chair for Work Education Linkages is located in the School of Engineering and Technology. It aims at identifying technological gaps between the needs in the field and available technology. It also develops tailor made education and training programmes to cater to the customized needs of the industry. IGNOU Researchers Forum As outlined in the Research Policy, studying the philosophy of research and training into research methods are important ingredients. Modern research methods have impacted the structures of society and relations of power. They have also remained pervasive in cultural relations throughout the world. The research programmes of the University should therefore draw upon a variety of theoretical positions and their associated strategies and techniques. Moreover, the researchers should also seek to develop adequate and appropriate approaches to subjects that are diverse, hybrid and diasporic. It is felt that the research programmes of the University function in an atmosphere of intellectual exchange and cultural negotiation. Keeping this in mind, the IGNOU Researchers Forum has been formed to provide a platform for interaction among the researchers and to ensure that the essence of the Research Policy is realized. The Forum meets on a regular basis and encourages research scholars to make their presentations and participate in the discussions and debates. The Forum is open, for participation to all teachers, staff and students. International Collaborations From time-to-time the University works out schemes which provide an opportunity to enter into international collaborations. Under these schemes students and teachers of the University may visit universities and other institutions overseas for study and interaction. COMPREHENSIVE GUIDELINES: PhD [ Relevant Notifications and necessary alterations in conformity with the Ordinance on Research Degree Programmes and UGC (Minimum Standards and Procedure for Awards of MPhil/PhD Degree), Regulation 2009 incorporated. ] 1. Admission to PhD Program shall take place in two sessions, viz. January and July every year. The admission schedule will be announced through advertisement on the IGNOU website and/or in national newspapers for each session indicating the Disciplines which are on offer in the session. All applications in the prescribed format shall be received at the Research Unit of IGNOU by duly notified dates. The format of application may be downloaded from the website or purchased at the designated Regional Centres and/or Study Centres and IGNOU Headquarter at Maidan Garhi, New Delhi. The applications shall be submitted at the Research Unit as stated above. Research Unit, IGNOU 17 17Handbook & Prospectus-PhD/MPhil 2. The eligibility for admission in PhD program is 55% post-graduation level (50% for reserved category). marks at the (i) Candidates who fulfil the eligibility criteria and have qualified UGC (NET), SLET, IIT (GATE), DAE (JEST), etc. will be selected after making the presentation of their research proposal before Doctoral Committee of the Discipline in an interview. Such candidates, after admission, will be prescribed course work by the Discipline concerned. (ii) Candidates who fulfil the eligibility criteria and also have MPhil Degree and/or five years of Work/Professional experience as validated by the respective Disciplines may be exempted from appearing in Entrance Examination. Such candidates will be invited to make the presentation of their research proposals before Doctoral Committee of the Discipline in an interview. Selected candidates may be prescribed Course Work as deemed appropriate by the Discipline. (iii) Candidates who fulfil the eligibility criteria and do not have MPhil/NET/or five years work experience will appear in the Entrance Examination. Those who qualify the Entrance Examination will appear in the interview conducted by the Discipline concerned. Such candidates, after admission, will undergo course work prescribed by the Discipline. 3. The Applications received at the Research Unit will be subjected to an initial scrutiny for the eligibility. Thereafter, the Applications of MPhil and SLET/NET/GATE/ JEST qualified candidates will be sent to respective Schools for conduct of interview and research proposal presentations before the Doctoral Committee/s of the Discipline/s. 4. Candidates short-listed with MPhil, NET/SLET/GATE/JEST or five year work experience, as validated by the Discipline, will be invited to present their research proposals before the Doctoral Committee of the Discipline. The recommendation of the Doctoral Committee shall be placed before the School Board for approval. The Director of the School shall forward the recommendation of the School Board to the Research Unit, in the prescribed format, for the consideration of the Research Council Standing Committee (RCSC)/Research Council (RC) for final approval. Subsequently, Research Unit shall send an offer letter to the candidate intimating the approval of provisional admission in the respective PhD Programme. A candidate who accepts the offer will remit the prescribed fee within the stipulated time to the Research Unit. The candidate whose research topic and synopsis are already approved by the Research Council on the recommendation of the Doctoral Committee shall be issued a letter by the Research Unit confirming registration as PhD student. In case the Doctoral Committee suggests modification(s), the candidate may finalise the Synopsis/Research topic in consultation with the Supervisor. Thereafter, the modified Synopsis/Research topic should be processed through the Doctoral Committee and the School Board before its consideration in the RC. The candidate will get six month time for finalizing the research topic and synopsis. Failure to finalize synopsis within six months, as above, will result in the cancellation of provisional Registration/Admission without any refund of fee. 5. Applications of candidates who have to appear in the Entrance Examination will be processed by the Research Unit and uploaded on IGNOU Website. Simultaneously, Hall Tickets will be issued to them. Candidates who qualify in the 18 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Entrance Examination will appear in an interview conducted by the Discipline. Selected candidates will be enrolled provisionally and will undergo course work of one year duration prescribed by the Doctoral Committee of the Discipline. The candidate shall be deemed to have completed the course work successfully on obtaining at least C Grade (measured on a five point scale) or 50% of the maximum score in the course work. The candidate will get six months time to finalize research topic and synopsis since the completion of course work (of one year duration) and will attract the same provision of cancellation as in Sl. No. 4 above on failure to finalize synopsis within a period of six months since provisional Registration/Admission. 6. Students enrolled in PhD program may work on full-time basis or on part-time basis at the University (vide Clause 3.3 of the Ordinance on Research Degree Programmes). All those who have been awarded a fellowship either by IGNOU or any other funding agency will work as full-time research students. Change from part-time to full-time or vice versa will have to be approved by the Doctoral Committee and the School Board and placed before the RCSC/RC for approval within a reasonable time. The decision of the RCSC/RC in this matter will be final. 7. Minor change in the topic of PhD thesis can be made within 11⁄2 years of provisional registration for PhD. This minor change in the topic will have to be approved by Doctoral Committee, School Board and thereafter placed before RCSC/RC for approval. No minor change of topic will be permitted after 11⁄2 years of provisional registration. 8. In case there is a major change of topic as decided by the Doctoral Committee, the student will have to go through the process of fresh registration. 9. There will be a Doctoral Committee for each Discipline that will manage all aspects of research program pertaining to the Discipline. The Doctoral Committee of each Discipline will comprise the following: (i) Director of the School - Chairperson (ii) Faculty of the Discipline concerned - Members (iii) At least one External Expert from a Panel recommended by the School Board and approved by the Vice Chancellor - Member Programme Coordinator of PhD - Convener (iv) 10. The term of an External Expert on the Panel of the Doctoral Committee will be two years and the Expert will be eligible for re-nomination. 11. Doctoral Committee will perform the following functions : (i) Organize all such activities as are relevant to the research programme of the Discipline; (ii) Approve the topic of research, the synopsis, and the allocation of supervisor; (iii) Assess and approve the progress reports of PhD students; (iv) Prescribe course work; (v) Approve change of topic of dissertation/thesis, change of supervisor and status of researcher (full time to part time and vice-versa); Research Unit, IGNOU 19 19Handbook & Prospectus-PhD/MPhil (vi) Recommend, or not, extension of tenure of fellowships, if applicable, beyond the initial period of the award; (vii) Approve the finalized synopsis within six month period of provisional admission/registration of students; (viii) Consider and recommend to the School Board for approval the CVs and names of supervisors in accordance with the Ordinance; (ix) Ensure observance of the admission schedule in each cycle as announced by the Research Unit; and (x) Ensure the observance of the Reservation Policy of the Government of India. 12. The courses will be designed and developed as per the laid down procedures of the University and the details along with the evaluation methodology will be provided by the Research Programme Coordinator as worked out by the Doctoral Committee for the approval of the School Board and RC/RCSC. The schedule of the course work, decided by the Doctoral Committee, will be announced by the Research Programme Coordinator. 13. Records related to admission, registration, payment of fees, and other learner records will be maintained by the Research Unit. The relevant information on the payment of fee by the research student will be regularly communicated by the Research Unit to the respective Disciplines enabling them to keep an update on the status of the research student. 14. All research Supervisors approved by IGNOU in accordance with the Ordinance on Research Degree Programmes can guide research students. 15. A Supervisor shall be deemed to have renewed her/his quota of enrolment on completion of three years of registration of a candidate under her/his supervision. 16. The progress of the research student shall be monitored by the supervisor(s). However, generating the six monthly progress reports on the prescribed format will be the responsibility of the research student. S/He shall submit her/his progress report to the Supervisor for placing the same before the Doctoral Committee. The recommendation of the Doctoral Committee will be placed before the School Board. The minutes of the Doctoral Committee and that of the School Board will be forwarded by the Director of the School for placing before the RCSC/RC. In case of unsatisfactory progress over a time period of one year and/or non-submission of timely report/fee, the University reserves the right to cancel the registration under Clause 3.6 of the Ordinance. 17. Each research student will give at least two seminars prior to the pre-submission seminar before the Doctoral Committee. 18. The maximum duration after registration for the PhD Program shall be five years. The maximum duration can be extended by a maximum of one year with the permission of the Vice Chancellor. The request for extension shall have to be moved by the research student through Supervisor and the Doctoral Committee. In such cases, a prescribed fee will have to be paid by the student for the period of extension. 20 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil 19. When the research student is nearing the completion of his PhD work a pre-submission seminar, open to all, will be organized by the Supervisor. The report of the seminar, and suggestions for improvement, if any, will be sent by the Supervisor through the Director of the School to the Research Unit for records. The Supervisor will ensure that constructive suggestions made in the pre-submission seminar to improve the quality of research are incorporated in the thesis. 20. At least one research paper should be published/accepted for publication in a peer reviewed/refereed Journal (online or print) before the submission of thesis. 21. The research student shall submit a copy in electronic form on a CD and four hard copies of the summary of the thesis (3000-5000 words) to the Research Unit, duly approved by the Supervisor(s), at least 45 days before the submission of thesis. 22. Four hard bound copies of the thesis along with one in the electronic form on a CD shall be submitted to the Research Unit through the Director concerned. The thesis shall include a certificate in the prescribed format signed by the Supervisor(s) about the originality of the work. 23. The thesis shall be examined by three external experts nominated by the Vice Chancellor from a list of seven experts submitted by the Supervisor(s) through the School Board concerned. The report of the evaluation will be given on a prescribed format. 24. In case an examiner suggests certain modifications or re-submission of the thesis, the same should be communicated to the candidate, who will be asked to resubmit the thesis with all the modifications within six months. The research Supervisor(s) will ensure that the suggestions of the examiner are adequately addressed before resubmission of the thesis. The modified thesis shall be referred again to the examiner concerned for re-evaluation. 25. If one of the examiners does not recommend the thesis for the award of a PhD degree, the thesis shall be referred to another examiner for independent evaluation. If the fourth examiner recommends the thesis for the award, the viva-voce examination shall be organized by the Director of the School as prescribed at Sl. No. 25. However, if this examiner also rejects the thesis, the thesis shall be deemed to be rejected by the University. 26. The examiners’ reports will be communicated to the School concerned and the Supervisor to be shared with the candidate prior to the viva-voce examination to enable her/him to address the issues that arise in the reports while preparing to defend the thesis. 27. The viva-voce examination shall be conducted at IGNOU as an open defence of the thesis by a panel comprising one of the external examiners nominated by the Vice Chancellor and the Supervisor(s) of the candidate. The Director concerned shall be the Chairperson of the panel. The Supervisor from IGNOU shall be the Convener of the panel. The date for open defence, venue, and topic of the thesis with a brief abstract shall be communicated to the Research Unit by the Director of the School concerned. This should also be given wide publicity by the Research Unit so as to facilitate larger participation. Research Unit, IGNOU 21 21Handbook & Prospectus-PhD/MPhil 28. The report of the viva-voce examination prepared by the External Examiner and the Research Supervisor(s) in the prescribed format will be sent to the Research Unit through the Director of the School concerned. The report shall be placed before the Vice Chancellor for approval. 29. The Research Unit will communicate the approval of the Vice Chancellor along with other relevant matter to the Student Evaluation Division for issuing the notification. 30. The PhD degree will be awarded at the Convocation. COMPREHENSIVE GUIDELINES : MPhil [Relevant Notifications and necessary alterations in conformity with the Ordinance on Research Degree Programmes and UGC (Minimum Standards and Procedure for Awards of MPhil/PhD Degree), Regulation 2009 incorporated.] 1. Admission to MPhil Program shall take place in two sessions, viz. January and July every year. The admission schedule will be announced through advertisement on the IGNOU website and/or in national newspapers for each session indicating the Disciplines which are on offer in the session. All applications in the prescribed format shall be received at the Research Unit of IGNOU by duly notified dates. The format of application may be downloaded from the website or purchased at the designated Regional Centres and/or Study Centres and IGNOU Headquarter at Maidan Garhi, New Delhi. The applications shall be submitted at the Research Unit as stated above. 2. Candidates having post graduation with 55% marks (50% for reserved category) will be eligible for admission into MPhil Programme. 3. There will be a Doctoral Committee for each Discipline that will manage all aspects of research program pertaining to the Discipline. The Doctoral Committee of each Discipline will comprise the following : (i) Director of the School - Chairperson (ii) Faculty of the Discipline concerned - Members (iv) At least one External Expert from a panel recommended by the School Board and approved by the VC - Member Programme Coordinator of PhD - Convener (iv) 4. 22 Doctoral Committee will perform the following functions : (i) Organize all such activities as are relevant to the research programme of the Discipline; (ii) Approve the topic of research, the synopsis, and the allocation of supervisor; (iii) Prescribe course work; (iv) Approve change of topic of dissertation, change of supervisor and status of researcher (full time to part time and vice-versa); Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil (v) Recommend, or not, extension of tenure of fellowships, if applicable, beyond the initial period of the award; (vi) Consider and recommend to the School Board for approval the CVs and names of supervisors in accordance with the Ordinance; (vii) Ensure observance of the admission schedule in each cycle as announced by the Research Unit; and (viii) Ensure the observance of the Reservation Policy of the Government of India. 5. Applications of candidates who have to appear in the Entrance Examination will be processed by the Research Unit and uploaded on IGNOU Website. Simultaneously, Hall Tickets will be issued to them. Candidates who qualify in the Entrance Examination will appear in an interview conducted by the Doctoral Committee. The Doctoral Committee will recommend the selected candidates and place their cases along with the topics of their dissertation before the School Board for approval. The approval of the School Board will be forwarded to the RC/RCSC for approval. After approval by RC/RCSC the Research Unit shall inform the student about his/her selection through an Offer Letter. A student who accepts the offer will remit the prescribed fee within the stipulated time to the Research Unit. Thereafter, her/his admission will be confirmed through a confirmation letter issued by Research Unit. 6. All the candidates so admitted shall undergo course work. The candidates may simultaneously undertake course work and dissertation work. 7. The maximum duration for completing MPhil Programme shall be 4 years. 8. Two hard bound copies of the dissertation along with one in the electronic form on a CD shall be submitted to the Research Unit through the Director concerned. The dissertation shall include on the prescribed format a certificate signed by the Supervisor(s) about the originality of the work. 9. The dissertation shall be examined by an external examiner nominated by the Vice Chancellor from a list of at least 5 experts submitted by the Supervisor through the School Board concerned. The report of the examiner will be submitted on the prescribed format. 10. After evaluation of the dissertation by the examiner, the viva-voce shall be conducted by a panel comprising the external examiner, the Supervisor of the candidate, as Convener of the panel, and the Director concerned as the Chairperson of the panel. The report of the evaluation will be given on the prescribed format. 11. Successful completion of the MPhil Programme will require the candidate to secure minimum 50% marks in each course, 50% in the dissertation work and 50% in viva-voce. 12. In case the candidate does not obtain the qualifying marks in the dissertation, the evaluation report shall be sent to the Supervisor who can guide the research student in revising the dissertation for re-submission. The revised dissertation will be examined by the same examiner and the re-evaluation report will be considered as final report. This provision can be invoked only once. Research Unit, IGNOU 23 23Handbook & Prospectus-PhD/MPhil PLEASE NOTE : 1. The next pages comprise the Application Form consisting of two Parts, namely, Part-A and Part-B. 2. Before you start filling in the two Parts of the Application Form make sure that you have read the Instructions for filling up the Form very carefully. 3. Remember that making wrong entries in the Application Form will lead to rejection. 4. An electronic version of the Prospectus is also available on the internet at : <www.ignou.ac.in>. 5. Make sure that you fill Part-A and Part-B of Application Form before submission. In case, any part is not filled your Application will be rejected. 6. Ensure that all attested documents in support of information given by you are attached along with your Application Form. 24 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil INSTRUCTIONS FOR FILLING-UP THE APPLICATION FORM (PART-A) Please fill up the Application Form and mail or submit in person the same along with copies of attested Certificates to : Director, Research Unit, Block-6, Room No. 18, Indira Gandhi National Open University, Maidan Garhi, New Delhi-110 068 Please abide by the dates mentioned in the Advertisement Notification on the website of IGNOU. Some instructions for filling up Part-A of Application Form are given below : 1. Please strike out the Session which is not applicable. 2. Please strike out the Programme Code which is not applicable. 3. For Programme Code, refer to Appendix-RU-I of this Prospectus. 4. For Research Discipline, refer to Appendix-RU-I of this Prospectus and write down the name of the Discipline. 5. Enrolment Number: leave it blank. University will allot the Enrolment Number. 6. Regional Centre Code is shown by default. You need not fill it. 7. For State Code, refer to Appendix-RU-II of this Prospectus. 8. (a) and (b) if you are already registered or have done a programme with IGNOU, please write the relevant code in the boxes. If A1 then write the Enrolment Number and Programme Code. 9. Please follow the rule of Date/Month/Year e.g. 5th June 1976 should be written as 0 5 0 6 1 9 7 6 10. If your name is MUKESH KUMAR SHARMA, then write it as below: M U K E S H K U M A R S H A R M A 11. Please write your Father’s/Husband’s/Mother’s name. If name is RAKESH KUMAR SHARMA, then write it as below : R A K E S H K U M A R S H A R M A 12. Fill in your address for correspondence where you will receive letters from the University. Do not give Post Box Number as Address. Leave a box blank between each unit of address like House Number, Street Name, P.O., etc. 13 to 16 Write your Landline Telephone Number, Fax Number, Mobile Number and E-mail Address if any. Research Unit, IGNOU 25 25Handbook & Prospectus-PhD/MPhil 17 to 25 Write relevant codes in the appropriate Boxes. For example, if you are Male, put (A1) in box against Sl. No. 18. 26. For (a) and (b), write the relevant code in the box. If A1, then fill the Column 26(b) also. 27. Write the relevant code in the box. 28. (a) and (b) write the relevant code if you are below poverty line and also mention the annual family income. 29. (a) and (b) write the relevant code if you are receiving Scholarships and tick the box for the name of the Agency. Also, write the amount received per year. 30. Fill all the Columns beginning with your Matriculation till the highest Degree obtained by you so far. 31. For fee details, the amount is shown by default. Please enter the Demand Draft Number, Date, Amount, Place of Bank and Name of the Issuing Bank. Make sure that your Demand Draft is drawn in favour of IGNOU payable at New Delhi only. In case you have bought the Prospectus by paying Rs. 1000/-, you need not enclose the Demand Draft. However, if you have downloaded the Application Form, you must attach Demand Draft. CHECK LIST Before sending the filled in form to Director, Research Unit, please check whether you have : (a) Affixed your Photograph. (b) Enclosed the attested certificates as proof of information given. (c) Enclosed Category Certificate for SC/ST/PH/OBC (Non-creamy Layer) Minority Candidates. No change of category shall be entertained from student after the submission of Application Form. (d) Enclosed Age certificate wherever required. (e) Enclosed a Demand Draft as Application Fee and have written your Name, Programme Code, Discipline and Application Form Number on the reverse of the Demand Draft issued by bank. (f) In case of below poverty line students, documentary proof (photocopy of BPL Ration Card) is to be attached separately. (g) Enclosed Annexure RU-III and RU-IV. 26 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Application Number : INDIRA GANDHI NATIONAL OPEN UNIVERSITY bafnjk xak/kh jk"Vah; eqDr fo’ofo|ky; APPLICATION FORM (Part A) FOR MPhil/PhD PROGRAMMES 1. SESSION : JANUARY PHOTOGRAPH JULY (Strike out the Session not applicable) 2. PROGRAMME APPLIED FOR : MPHIL Affix your latest passport size (4 cm X 5 cm) photograph duly attested by you PHD (Strike out which is not applicable) 3. Programme Code : 4. Research Discipline : 5. Enrolment Number : 6. Regional Centre Code : C O (To be issued by the University) 7. State Code : 8 (a) Are you already Registered with IGNOU : (A1 - YES, B2 - NO) (b) If YES, write the Enrolment No. and 9. Programme Code Date of Birth Date Month Year 10. Name of the Applicant (Leave one box blank between First, Middle and Surname) 11. Father’s/Husband’s/Mother’s Name (Strikeout whichever is not applicable) 12. Address for Correspondence (Please do not give Post Box No. Leave a blank box between each unit of address) City District PIN Code State 13. Landline Telephone Number (if any) with STD CODE STD CODE Telephone Number 15. Mobile No. 17. 14. FAX Number (if any) STD CODE FAX Number 16. Email Address/ID (if any) Nationality : A1 - Indian, B1 - Others 18. Gender (Write the relevant Code in the box) A1 – Male, B2 – Female, C3 – Others Research Unit, IGNOU 19. Category (Write the relevant Code in the box) A1 – GEN, B2 – SC, C3 – ST, D4A – OBC (Creamy), D4B – OBC (Non Creamy) 20. Territory Code (Write the relevant Code in the box) A1 – Urban, B2 – Rural, C3 – Tribal 5 5Handbook & Prospectus-PhD/MPhil 21. Marital Status (Write the relevant Code in the box) 22. Religion (Write the relevant Code in the box) A1 – Married, B2 – Unmarried A1 – Hindu, B2 – Muslim, C3 – Christian D4 – Sikh, E5 – Jain, F6 – Budhist G7 – Parsi, H8 - Jews, I9 – Others 23. Whether Minority 24. Social Status 26a. Whether a Person with Disability 26b. If yes, give Nature of Disability 27. Employment Status 28a. Whether Below Poverty Line (Write the relevant Code in the box) A1 – Yes B2 – No 25. Whether Kashmiri Migrant (Write the relevant Code in the box) A1 – Ex-servicemen B2 – War Widow C3 – Not Applicable (Write the relevant Code in the box) A1 – Yes B2 – No (Write the relevant Code in the box) A1 – Yes B2 – No (Write the relevant Code in the box) A1 – Speech and Hearing Impairment D4 – Low Vision B2 – Locomotor Impairment E5 – Any other, C3 – Visual Impairment pl specify ________________ (Write the relevant Code in the box) A1 – Unemployed B2 – IGNOU Employee C3 – Employed D4 – KVS Employee 28b. Annual Family Income A1 – Yes B2 – No 29a. Are you in Receipt of any of these Scholarships (Write the relevant Code in the box) A1 – Yes B2 – No. Rs. 29b. If Yes, please specify Agency and Amount (Rs. _________per year) (Tick which is applicable) UGC CSIR ICMR DST ICSSR ICHR OTHERS (Pl specify) 30. Details of Educational Qualifications (from Graduation onwards) Sl. No. University Name of the Examination Year of Passing Subjects Percentage of Marks 31. Details of Application Fee (to be paid by a Demand Draft in favour of IGNOU, payable at New Delhi, if the Form is downloaded from IGNOU website. Candidates buying the Prospectus need not attach Demand Draft.) (Note : Application shall not be accepted without this fee) Amount : Rs. 1 0 0 0 . DD Date : 0 0 DD Number : Place of Bank : Date Month Year Name of the Bank : DECLARATION BY THE APPLICANT I hereby declare that I have read and understood the conditions of eligibility for the academic programme for which I seek the admission. I fulfil the minimum eligibility criteria and I have provided the necessary information. I also declare that the information submitted above is true and correct to the best of my knowledge. In the event of any information being found incorrect or misleading, my candidature shall be liable to cancellation by the University at any point of time even after award of Degree and I shall not be entitled to refund of any fee paid by me to the University. Further, I have carefully studied the rules of the University as printed in the Prospectus and I accept them and shall not raise any dispute in the future over the same rules. Dated : __________________________Signature of the Applicant 6 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil INSTRUCTIONS FOR FILLING-UP THE APPLICATION FORM (PART-B) Some instructions for filling up Part-B of Application Form are given below : 1. Please strike out the Session which is not applicable. 2. Please strike out the Programme Code which is not applicable. 3. For Programme Code, refer to Appendix-RU-I of this Prospectus. 4. For Research Discipline, refer to Appendix-RU-I of this Prospectus and write the name of the Discipline. 5. (a) and (b) please tick in the relevant box. If Yes fill in details of Dissertation, Research Discipline, Month and Year of Award and University. 6. (a) Please write the position in which you are working. (b) Give the Date and Year from which you are working in the Organization. (c) Name the Organization in which you are working. (d) Fill in the Address of the Organization. (e) Write down the Landline Telephone Number, Fax Number, Mobile Number and E-mail Address if any of the Organization through which you may be contacted. 7. Give details about various jobs held by you as evidence of your Work Experience after Post Graduation. 8. Mention the Title of the Thesis, you propose to work on. 9. This will be filled in later by the Research Unit. 10. Tick mark if you have enclosed/not enclosed your Research Proposal. 11. If you propose to work with external Research Supervisor or a Co-supervisor, give details as required in this section. Make sure that you enclose the CV of the Research Supervisor in case you intend to have such support. Research Unit, IGNOU 29 29Handbook & Prospectus-PhD/MPhil CHECK LIST Before sending the filled in form to Director, Research Unit, please check whether you have : (a) Enclosed MPhil Certificate. (b) Enclosed proof of your current employment. (c) Enclosed proof of your employment after Post Graduation. (d) Research proposal. (e) Consent Letter of External Research Supervisor, if any. (f) 30 Brief CV of the External Research Supervisor. Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Application Number : INDIRA GANDHI NATIONAL OPEN UNIVERSITY bafnjk xak/kh jk"Vah; eqDr fo’ofo|ky; APPLICATION FORM (Part B) FOR MPhil/PhD PROGRAMMES 1. SESSION : JANUARY JULY PHOTOGRAPH (Strike out the Session not applicable) 2. PROGRAMME APPLIED FOR : MPHIL PHD Affix your latest passport size (4 cm X 5 cm) photograph duly attested by you (Strike out which is not applicable) 3. Programme Code : 4. Research Discipline : 5. Whether you have M. Phil. : If YES, YES NO (i) Please specify the Title of Dissertation : (ii) Research Discipline/Area : (iii) Month and Year of Award of M. Phil. : Month Year (iv) Name of the University and Place : 6. If Employed, please give details of current Employment : (a) Designation (b) Serving from (c) Name of the Organization (d) Address of employer City (e) Landline Telephone Number with STD CODE STD CODE Telephone Number Mobile No. PIN Code (f) FAX Number (if any) STD CODE FAX Number Email Address/ID (if any) 7. Work Experience after Post Graduation (Please mention in Chronological Order) : Name and Address of the Organization Nature of Post Designation (Temporary/Ad-hoc/ Permanent) Research Unit, IGNOU Tasks Undertaken Period of Service Number of Years of Experience (Years and Months) From To Year Month 29 29Handbook & Prospectus-PhD/MPhil 8. Proposed Title of the Thesis of Ph. D. : 9. Approved Title of the Thesis (to be filled by the Office after acceptance of Application) 10. Research proposal for Ph. D. ENCLOSED NOT ENCLOSED (Tick whichever is applicable) Note : Candidates for M. Phil. need not enclosed Research Proposal. M. Phil. selections are based on entrance test plus interview to be conducted by the University 11 . In case you propose to have External Research Supervisor, please furnish the following details Note : External Research Supervisors must be approved and empanelled by the concerned School Board of the University. (i) Name of the External Research Supervisor : (ii) Name and Address of the Institution : (iii) (a) Present Position (if in Service) : (b) if Retired, give details (iv) Address and Contact details : (v) Consent letter for Guiding Student : Enclosed Not Enclosed (Tick whichever is applicable) (vi) CV of the Research Supervisor : Enclosed Not Enclosed (Tick whichever is applicable) (CV should be a brief in 2-3 pages duly signed by the Supervisor) DECLARATION BY THE APPLICANT I hereby declare that statements made in this application form are true and correct to the best of my knowledge and belief. I am aware that if at any stage it is found that the statement made by me are not true or misleading, my admission/registration will be cancelled by the University and I shall not be entitled to refund of any fee paid by me to the University. Further, I have carefully studied the rule of the University as printed in the Prospectus and I accept them and shall not raise any dispute in the future over the same rules. Dated : __________________________ Signature of the Applicant 30 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Checklist : (Tick the relevant Boxes) (1) Certificates in support of educational qualification(s) (2) Date of birth Certificate (Age Certificate) (3) Category certificate (if applicable) (4) Work Experience Certificate (5) CV of External Supervisor if any (6) Consent letter of External Supervisor, if applicable Research Unit, IGNOU for SC/ST/OBC/PH/Kashmiri Migrant/War Widow 33 33Handbook & Prospectus-PhD/MPhil SOME USEFUL FORMS The following Forms are for your use : 34  Certificate of Presentation of Seminar/Conference Papers  Certificate of Publication of Papers  Certificate of Completion of Course Work  Certificate of Completion of Pre-submission Seminar  Certificate of Originality Thesis/Dissertation)  Progress Report  Registration Form for 2nd Year/3rd Year for PhD Programme  Joint Report of Viva-Voce of Research (to be attached with Research Unit, IGNOU theHandbook & Prospectus-PhD/MPhil INDIRA GANDHI NATIONAL OPEN UNIVERSITY RESEARCH UNIT CERTIFICATE OF PRESENTATION OF SEMINAR/CONFERENCE PAPERS This is to certify that Mr./Ms. _______________________________________________ pursuing PhD Programme in ________________________________________________ with Enrolment Number _________________________________ has made the following Two Seminar Presentations in the Forums mentioned, thereby fulfilling the Programme requirements : (1) __________________________________________________________________ __________________________________________________________________ __________________________________________________________________ __________________________________________________________________ (2) __________________________________________________________________ __________________________________________________________________ __________________________________________________________________ __________________________________________________________________ Date : Research Supervisor Research Unit, IGNOU Research Programme Coordinator 35 35Handbook & Prospectus-PhD/MPhil INDIRA GANDHI NATIONAL OPEN UNIVERSITY RESEARCH UNIT CERTIFICATE OF PUBLICATION OF PAPERS This is to certify that Mr./Ms. _______________________________________________ pursuing PhD Programme in ________________________________________________ with Enrolment Number ______________________________________ has the following Publications/Letters of Acceptance in the Journals mentioned thereby fulfilling the Programme requirements : Sl. No. Title of the Paper Publication Details 1. 2. Date : 36 Research Supervisor Research Programme Coordinator Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil INDIRA GANDHI NATIONAL OPEN UNIVERSITY RESEARCH UNIT CERTIFICATE OF COMPLETION OF COURSE WORK This is to certify that Mr./Ms. _______________________________________________ pursuing PhD/MPhil Programme in _________________________________________ with Enrolment Number ________________________ has completed the following Course Work thereby fulfilling the Programme requirements : Sl. No. Course Title Course Credits 1. 2. 3. 4. 5. 6. Date : Research Supervisor Research Unit, IGNOU Research Programme Coordinator 37 37Handbook & Prospectus-PhD/MPhil INDIRA GANDHI NATIONAL OPEN UNIVERSITY RESEARCH UNIT CERTIFICATE OF COMPLETION OF PRE-SUBMISSION SEMINAR This is to certify that Mr./Ms. _______________________________________________ pursuing PhD Programme in ________________________________________________ with Enrolment Number __________________________ has made his/her presentation in the pre-submission seminar held on ___________________________ thereby fulfilling the Programme requirements. Date : 38 Research Supervisor Research Programme Coordinator Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil INDIRA GANDHI NATIONAL OPEN UNIVERSITY RESEARCH UNIT CERTIFICATE OF ORIGINALITY OF RESEARCH (To be attached with the Thesis/Dissertation) This is to certify that the thesis entitled _________________________________________ submitted by Smt./Km./Shri __________________________________________ is her/his original Research Work and has not been presented for the award of any Degree elsewhere. Date : Research Unit, IGNOU Research Supervisor 39 39Handbook & Prospectus-PhD/MPhil INDIRA GANDHI NATIONAL OPEN UNIVERSITY RESEARCH UNIT PROGRESS REPORT FOR MPHIL AND PHD STUDENTS (To be submitted on Six Monthly basis after Admission) Progress Report for the Period _________________________ (1) Name and Enrolment Number : (2) Address : (3) Mobile Number : (4) Email ID : (5) Discipline and School : (6) Month of MPhil/PhD Registration and Cycle : (7) Topic Approved for MPhil/PhD : (8) Name of the Research Supervisor/s : (9) Status of PhD Research : (Progress of the Research in terms of Problem Formulation, Pilot Study, Field Work, Experimentation, Data Collection, Data Analysis, Report Writing, etc. may be given – use more space as needed) ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (10) Details of Course Work undertaken (i) Course work Assigned with Credits : (ii) Course work Completed with Credits : (11) Teaching Activities undertaken : (Participation in Writing and Editing ODL Study Materials, Academic Counseling, Evaluation, Teleconferencing, IRC, etc. may be given – use more space as needed.) ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ 40 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil (12) Participation in seminars, conferences during the period under report-use more space as needed ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (13) Presentation of papers in seminars/conferences during the period under report-use more space as needed ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (14) Publications during the period-use more space as needed : (i) Professional : (ii) General : (15) Details of Books/Research Papers reviewed-use more space as needed : ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ (16) Any other special contributions by the researcher to the institution during the period under report-use more space as needed : ____________________________________________________________________ ____________________________________________________________________ ____________________________________________________________________ OBSERVATIONS OF THE SUPERVISOR (including on the research aptitude of the candidate) : Evaluation of the Progress of the Researcher : Progress is Very Good/Good/Satisfactory/Needs improvement Date : Research Supervisor Research Unit, IGNOU Research Programme Coordinator 41 41Handbook & Prospectus-PhD/MPhil INDIRA GANDHI NATIONAL OPEN UNIVERSITY RESEARCH UNIT REGISTRATION FORM FOR 2ND AND 3RD YEAR FOR PHD PROGRAMMES (1) Name and Enrolment Number (2) Address (3) Contact Number (4) E-mail ID (5) Discipline and School (6) Topic of PhD Research (7) Demand Draft Number, Date (8) Bank Issuing Demand Draft (9) Indicate if the fees is for 2 nd or 3 rd Year Date : Signature of the Candidate Full Name of the Candidate Encl. : Demand Draft along with this Application Form Please super-scribe the Envelope “Registration Fee for 2nd/3rd Year” as the case may be. 42 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil INDIRA GANDHI NATIONAL OPEN UNIVERSITY RESEARCH UNIT JOINT REPORT OF VIVA-VOCE This is to certify that Mr./Ms. _________________________________________________ (Enrolment Number) __________________ pursuing MPhil/PhD Programme in (Discipline) _________________________________________________________________________ on the topic _______________________________________________________________ ______________________________________ has been examined by us in the Viva-Voce conducted on ____________ (Date) at __________________________________ (Venue). *The marks for the Viva-Voce examination of MPhil are ___________________________. * Wherever applicable. The Board has the following observations to make : (1) __________________________________________________________________ __________________________________________________________________ __________________________________________________________________ __________________________________________________________________ (2) __________________________________________________________________ __________________________________________________________________ __________________________________________________________________ __________________________________________________________________ The Board recommends/does not recommend the award of the Degree of Master/Doctor of Philosophy to Mr./Ms. _____________________________________________________ Research Supervisor Research Unit, IGNOU Director External Examiner 43 43Handbook & Prospectus-PhD/MPhil LIST OF DOCTOR OF PHILOSOPHY (PhD) PROGRAMMES Sl. No. Name of the Programme, Code and Coordinator Eligibility Course Work SCHOOL OF AGRICULTURE (SOA) 1. Doctor of Philosophy in Agriculture Extension (PHDAGE) Dr. P. K Jain pkjain@ignou.ac.in M. Sc. in Agriculture Extension/ Extension Education/Home Science Extension/Dairy Extension/ Veterinary and Animal Husbandry Extension/Fisheries Extension/ Agricultural Communication/ Development/Communication/ Agricultural Extension and Communication, Masters degree in any branch of Agricultural Sciences or allied fields- with bridge course in Agricultural Extension(will appear in Entrance Examination). All Courses of 8 Credits each : RAE-002 : Advances in Agriculture Extension RAE-003 : Agriculture Extension Management RAE-004 : Information Communication Technology in Agriculture RAE-005 : Research Methodology and Scaling Techniques Bridge Course RAE-006 : Fundamentals of Agriculture Extension and Communication 2. Doctor of Philosophy in Dairy Science and Technology (PHDDR) Dr. M. K. Salooja mkslooja@ignou.ac.in Master’s Degree in Dairy Science (Dairy Technology, Dairy Chemistry, Dairy Microbiology, Dairy Engineering), Food Science/ Food Technology, M. V. Sc. (Animal Products Technology/Live Products Technology/Dairy Science), M. Sc. Agriculture (Dairy Science/Dairy Technology), M. Sc. (Agriculture/Processing and Food Engineering) with B. Tech. in Dairy Technology (will appear in Entrance Examination). Compulsory Courses (4 Credits each) RDR-001 : Advances in Lipid Technology RDR-002 : Advances in Protein Technology RDR-003 : Product Monitoring and Process Control RDR-004 : R & D Management in Dairy Industry Four Optional Courses (4 Credits each) RDR-005 : Developments in Dairy Processing RDR-006 : Dairy By-products Technology and Processing RDR-007 : Advances in Chemistry of Milk Processing RDR-008 : Advances in Analytical Techniques in Dairy Chemistry RDR-009 : Applied Food Biotechnology RDR-010 : Dairy and Food Microbiology RDR-011 : Dairy and Food Engineering-I RDR-012 : Dairy and Food Engineering-II 44 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Sl. No. Name of the Programme, Code and Coordinator Eligibility Course Work SCHOOL OF CONTINUING EDUCATION (SOCE) 3. Doctor of Philosophy in Child An MPhil Degree and a Development (PHDCDEV) Post-Graduate Degree in the discipline of Child Development Prof. Neerja Chadha (or Human Development/Human neerja_chadha@ignou.ac.in Development and Family Studies/ Human Development and Childhood Studies or an allied discipline such as Psychology/ Sociology/Anthropology/Social Work/Education/Disability Studies and other allied fields such as Physiotherapy/Occupational Therapy, etc.) with minimum 55% marks (50% marks for SC/ST/PH candidates) or an equivalent grade from a University or a recognized Institution of higher learning. The student should have exhibited interest in the discipline of Child Development and familiarity with Research Methodology, during the MPhil programme, and through Teaching/Research/Professional/ Public Service experience in the area of Child Development. Evidence of interest and candidate’s familiarity with Research Methodology in the area of Child Development will be evaluated by candidate’s research publications; at least three published in reputed National/ International Journals of which at least one should be in a peer reviewed Journal. OR Master’s Degree in the discipline of Child Development (or Human Development/Human Development and Family Studies/Human Development and Childhood Studies or an allied discipline such as Psychology/Sociology/ Anthropology/Social Work/ Education/Disability Studies and other allied fields such as Physiotherapy/Occupational Therapy, etc.) with minimum 55% marks (50% marks for SC/ST/PH candidates) or an equivalent grade from a University or a recognized Institution of Research Unit, IGNOU 45 45Handbook & Prospectus-PhD/MPhil Sl. No. Name of the Programme, Code and Coordinator Eligibility Course Work higher learning, and at least 5 years of Teaching/Professional experience in a University or a recognized Institution of higher Learning/Research as well as Demonstrable Research experience and familiarity with Research Methodology in the area of Child Development. Evidence of demonstrable research experience and candidate’s familiarity with Research Methodology will be evaluated by candidate’s Research Publications; at least three published in reputed National/ International Journals of which at least one should be in a peer reviewed Journal. SCHOOL OF COMPUTER AND INFORMATION SCIENCE (SOCIS) 4. Doctor of Philosophy in One of the following (All will Computer and Information appear in Entrance Examination): Sciences (PHDCISC) 1. M. Tech/MPhil in Computer Prof. Shashi Bhushan Science/Information shashibhushan@ignou.ac.in Technology 2. MCA/MSc. in Computer Science 3. B. Tech. in Computer Science/ Information Technology with five year experience either in Teaching or in Software Industry 5. Doctor of Philosophy in Food MPhil Degree and a Master Degree and Nutrition (PHDFN) in Nutrition/Dietetics with 55% and above (50% and above in case of Prof. Deeksha Kapur SC/ST/PH) or an equivalent grade deekshakapur@ignou.ac.in from a recognized Institution of higher learning. OR A Masters Degree (M. Sc.) in Foods and Nutrition with 55% and above (50% and above in case of SC/ST/PH) or an equivalent grade from a recognized Institution and FIVE years Teaching/Industry/ Professional/Public service experience (in an area related to Nutrition/Dietetics) at senior level SCHOOL OF EDUCATION (SOE) 6. Doctor of Philosophy in (All will appear in Entrance Education (PHDEDU) Examination) Prof. C. B. Sharma MPhil in Education sharmacb2000@yahoo.com OR Master degree in Education and five years Teaching experience 46 1. Research Methodology : (2 Credits) 2. Analysis and Design of Algorithm (4 Credits) 3. Topics in Mathematical Science (4 Credits) 4. Operating Systems (4 Credits) 5. Elective Courses (8 Credits) All students eligible for PhD would be required to enrol simultaneously and successfully complete the Course “Research Methods and Biostatistics” (MFN-009). However, students with an MPhil may be exempted from taking the Research Methods and Biostatistics Course, on the recommendation of the Doctoral Committee Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Sl. No. Name of the Programme, Code and Coordinator Eligibility Course Work SCHOOL OF ENGINEERING AND TECHNOLOGY (SOET) 7. Doctor of Philosophy in Civil Engineering (PHDCENG) Prof. Ajit Kumar ajit@ignou.ac.in Master of Engineering/Technology in Civil or in the relevant field of Civil Engineering (will appear in Entrance Examination). 8. Doctor of Philosophy in Mechanical Engineering (PHDMCE) Dr. Ashish Agarwal ashisha@ignou.ac.in Master of Engineering/Technology in Mechanical or in the relevant field of Mechanical Engineering (will appear in Entrance Examination). SCHOOL OF GENDER AND DEVELOPMENT STUDIES (SOGDS) 9. Doctor of Philosophy in Master’s Degree and five years Gender and Development Teaching/Research or work Studies (PHDGDS) experience Prof. Annu J. Thomas OR athomas@ignou.ac.in MPhil Degree in any discipline with demonstrable evidence of Research Publications/Interest in areas relevant to Gender and Development Studies 10. Doctor of Philosophy in Academic performance at Women’s Studies (PHDWS) MPhil/Master’s level, Post Graduate Degree in relevant discipline, Prof. Anu Aneja number of years of Teaching anuaneja@ignou.ac.in experience and Demonstrable Evidence of Research Publications/ Interest in Women’s and Gender Issues Civil Engineering :  Mathematics  Research Methodology  System Dynamics  Construction Management Mechanical Engineering :  Operations Research  Materials Management  System Dynamics  Production and Operation Management  Mathematics  Research Methodology Candidates would spend six months in research related activities SCHOOL OF HUMANITIES (SOH) 11. Doctor of Philosophy in Hindi (PHDHIN) Prof. Satyakam satyakam@ignou.ac.in Master Degree in Hindi (will appear in the Entrance Examination) OR Master Degree and MPhil in Hindi OR Master Degree and five years Teaching/Research experience in Lecturer’s Grade Research Unit, IGNOU Theory courses are compulsory. Two more shall be allotted from electives. RHD-001 : Anusandhan Ka Swaroop Aur Pravidhi (Theory) RHD-002 : Sahitya Ke Naye Vimarsh (Theory) RHDE-001 : Aadhunic Sahitya Aur Chintan (Elective) RHDE-002 : Madhyakalin Sahitya Aur Chintan (Elective) RHDE-003 : Jansanchar Madhyam (Elective) RHDE-004 : Anuvad, Sanskrit Aur Bhasha-Asmita (Elective) RHDE-005 : Hindi Bhasha Aur Bhasha Vigyan (Elective) 47 47Handbook & Prospectus-PhD/MPhil Sl. No. Name of the Programme, Code and Coordinator Eligibility Course Work RHDE-006 : Tulnatmak Sahitya (Elective) RHDE-007 : Sanskrit, Pali-Prakrit-Apbrhansh Aur Adhunik Bharitya Bhashaon Ke Sahitya Ka Itihas (Elective) (8 Credits each) 12. Doctor of Philosophy in English (PHDENG) Dr. Prema Eden Samdup psamdup@ignou.ac.in Master Degree in English and MPhil and having five years Teaching/Research experience in Lecturer’s Grade Theory courses are compulsory. Two more shall be allotted from electives. REG-001 : Research Methodology (Theory) REG-002 : Resistance Literature (Theory) REGE-001 : Gender (Elective) REGE-002 : Literature and Migration (Elective) REGE-003 : Translation : Theory and Practice (Elective) REGE-004 : The Nature and Structure of Language (Elective) REGE-005 : Folk Narratives Text and Performance (Elective) (8 Credits each) SCHOOL OF HEALTH SCIENCES (SOHS) 13. Doctor of Philosophy in Nursing professionals having Nursing (PHDNUR) MPhil from a recognized University Prof. Bimla Kapoor OR bkapoor@ignou.ac.in M. Sc. Nursing and having five Prof. Pity Koul years Teaching/Industry/ pkoul@ignou.ac.in Administration/Professional/ Clinical experience The scholars will do the course work in the form of assignments and presentation recommended by Doctoral Committee which will be evaluated internally by the PhD Coordinators of Nursing Discipline SCHOOL OF INTER-DISCIPLINARY AND TRANS-DISCIPLINARY STUDIES (SOITS) 14. Doctor of Philosophy in Preferably Master Degree in Social (1) RITS-001 : Inter- Inter-Disciplinary and Sciences or Humanities and disciplinary and Trans-Disciplinary Studies MPhil Degree or 5 years of Trans-disciplinary (PHDITS) Teaching/Professional experience. Research PhD Research proposal in an area Dr. Nandini Sinha Kapur (2) RITS-002 : Research of Interdisciplinary Research nandini@ignou.ac.in Methods in Social Science should be enclosed. (3) RITS-003 : Area Studies OR (4) RITS-004 : Literature Post-Graduate Degree in any Survey discipline with research proposal All Courses are of 8 Credits on any aspect of interdisciplinary each studies preferably from Social Sciences and Humanities background (will appear in the Entrance Examination) 48 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Sl. No. Name of the Programme, Code and Coordinator Eligibility Course Work SCHOOL OF MANAGEMENT SCIENCES (SOMS) 15. Doctor of Philosophy in Commerce (PHDCOM) Prof. Naval Kishor nkishor@ignou.ac.in Prof. Madhu Tyagi mtyagi@ignou.ac.in MPhil and with Post Graduate Degree in Commerce or any other allied disciplines from any recognized University/Institution of higher learning. OR Master Degree in Commerce or any other allied disciplines from any recognized University/Institute of higher learning with 5 years of Teaching/Professional/Industry experience 16. Doctor of Philosophy in Management (PHDMGMT) Prof. P. C. Basak pcbasak@ignou.ac.in Master Degree/equivalent Degree from a recognized University/ Institution (will appear in Entrance Examination) OR Master Degree and with M. Phil or 5 years relevant Teaching/Professional experience SCHOOL OF SCIENCES (SOS) 17. Doctor of Philosophy in Biochemistry Dr. Seema Kalra seemakalra@ignou.ac.in Dr. Maneesha Pandey maneesha@ignou.ac.in 1. M.Sc/M. Tech./M. Pharma in Life Sciences/Allied Sciences 18. Doctor of Philosophy in Chemistry (PHDCHE) Prof. Sunita Malhotra smalhotra@ignou.ac.in Dr. Kamalika Banerjee kamalika@ignou.ac.in MPhil or 5 years Teaching/ Professional experience with Master Degree in relevant area 19. Doctor of Philosophy in Geography Dr. Subhakanta Mohapatra subhakanta@ignou.ac.in MPhil and Post graduate degree in Geography/Applied Geography/ Earth Systems Science/relevant discipline of Geospatial Technology fulfilling general eligibility criteria 2. MPhil and Master Degree in a relevant Discipline OR Master Degree in the relevant Discipline with five years of Teaching/Research and Professional experience OR Post Graduate Degree in the Disciplines mentioned above and five year experience in Research/ Teaching/Professional experience Research Unit, IGNOU 49 49Handbook & Prospectus-PhD/MPhil Sl. No. Name of the Programme, Code and Coordinator 20. Doctor of Philosophy in Geology Dr. Meenal Mishra meenamishra@ignou.ac.in Eligibility Course Work MPhil and Master Degree in Geology/Applied Geology/Earth Sciences/Marine Geology/ Hydrogeology OR Master Degree in the above mentioned fields of study and having five years Teaching/ Research/Professional experience 21. Doctor of Philosophy in Life Sciences (PHDLS) Prof. Neera Kapoor neerakapoor@ignou.ac.in MPhil Degree in any area of Life Sciences (Botany, Zoology, Microbiology and Biotechnology) and Master Degree in a relevant Discipline OR Master Degree in the relevant discipline and having five years Teaching/Research experience in higher education 50 Core Courses Research Methodology (4 Credit) Biological Techniques (6 Credit) Biostatics and Computer Applications in Biological Research (6 Credit) Optional Courses (Any Two) Molecular Cell Biology (8 Credit) Biotechnology (8 Credit) Biochemistry (8 Credit) Microbial Ecology and Systematics (8 Credit) Molecular Microbiology (8 Credit) Applied Microbiology (8 Credit) Bioinformatics (8 Credit) Genomics and Proteomics (8 Credit) Insect Biosystematics (8 Credit) Insect Pest Management (8 Credit) Insect Toxicology (8 Credit) Medical Entomology (8 Credit) Plant Disease Management (8 Credit) Post Harvest Management of Pests and Diseases (8 Credit) Natural Plant Products (8 Credit) Plant Tissue Culture (8 Credit) Genetics (8 Credit) Plant Taxonomy (8 Credit) Introduction to Nematology (8 Credit) Nematological Techniques (8 Credit) Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Sl. No. Name of the Programme, Code and Coordinator Eligibility Course Work Nematode Biosystematics (8 Credit) Nematode Ecology (8 Credit) Medical Genetics (8 Credit) Human Physiology (8 Credit) Animal Systematics (8 Credit) Human Brain and Disorders (8 Credit) Cancer Biology (8 Credit) Techniques in Animal Biotechnology (8 Credit) Biology Education (8 Credit) 22. Doctor of Philosophy in Physics (PHDPH) Dr. S. Lamba slamba@ignou.ac.in Masters and MPhil Degree in Physics OR Master Degree in relevant discipline and working in recognized College/Research Institution and having minimum five years Teaching/Research experience SCHOOL OF TRANSLATION STUDIES AND TRAINING (SOTST) Master Degree in Translation 23. Doctor of Philosophy in Translation Studies (PHDTT) Studies and MPhil Degree Dr. Deo Shankar Navin OR deoshankar@hotmail.com Master Degree in Translation Dr. Jagdish Sharma Studies and five years of jagdishsharma@ignou.ac.in Teaching/Research experience Dr. Rajendra Pd. Pandey OR rajendrapandey@ignou.ac.in Master Degree in Translation Studies or in allied subjects (will appear in Entrance Examination). All courses are of 8 Credits each Compulsory Courses RTT-001 : Research Methodology RTT-002 : Translation Theory and Practice RTT-003 : Critiquing Translation Any one of the following: RTT-004 : Translation and Power RTT-005 : Translation and Nationalist Movement RTT-006 : Translating Women Writing RTT-007 : Translating Dalit Writing SCHOOL OF TOURISM AND HOSPITALITY SERVICES MANAGEMENT (SOTHSM) 55% marks in Post Graduation in RTS-001 : Interdisciplinary 24. Doctor of Philosophy in Tourism and Hospitality the relevant field Approaches in Tourism and Services (PHDTS) Hospitality Candidate with MPhil/NET/ Dr. Paramita Suklabaidya Professional experience as RTS-002 : Tourism Concepts paramitz@ignou.ac.in validated by the faculty in the RTS-003 : Research relevant field would be exempted Methodology in Tourism and from taking the Entrance Hospitality Examination RTS-004 : Seminar Presentations (8 Credits each) Research Unit, IGNOU 51 51Handbook & Prospectus-PhD/MPhil Sl. No. Name of the Programme, Code and Coordinator Eligibility Course Work STAFF TRAINING AND RESEARCH IN DISTANCE EDUCATION (STRIDE) 25. Doctor of Philosophy in Distance Education (PHDDE) Dr. R. Satyanarayana rsatyanarayana@ignou.ac.in Post Graduate Degree in any Discipline (will appear in Entrance Examination) OR Post Graduate Degree in Distance Education with specialization in Educational Technology/ Instructional Design/Education (will appear in Entrance Examination) OR MPhil or five years of Teaching/ Professional/Administrative experience in Open Distance Learning (ODL). 32 Credits (Exempted for candidates with MPhil Degree or 5 year experience subject to recommendation of the Doctoral Committee) Both MPhil and PhD programmes are modular in nature with exit option for MPhil or PhD as the case may be RDE-001 : Research Methodology RDE-002 : Information and Communication Technology RDE-003 : Web-based Education RDE-004 : Contexts and Concerns of Distance Education RED-005 : Term Paper and Seminar SCHOOL OF VOCATIONAL EDUCATION AND TRAINING (SOVET) 26. Doctor of Philosophy in Vocational Education (PHDVED) Prof. C. G. Naidu cgnaidu@ignou.ac.in Master Degree and MPhil OR Master Degree and five years Teaching/Research/Professional experience Research Methodology and Statistical Methods in VET (8 Credits) VET Perspectives (8 Credits) Planning and Management of VET (4 Credits) Instructional and Training Processes in VET (4 Credits) Trade/Area Specific Course (4 Credits) Critical Review of Literature and Contributions in VET (4 Credits) LIST OF MASTER OF PHILOSOPHY (MPhil) PROGRAMMES (All will appear in Entrance Examination) SCHOOL OF TRANSLATION STUDIES AND TRAINING (SOTST) 27. Master of Philosophy in Translation Studies (MPHILTT) M. A. In Translation Studies The course work details are given in the section on PhD STAFF TRAINING AND RESEARCH IN DISTANCE EDUCATION (STRIDE) 28. 52 Master of Philosophy in Distance Education (MPHILDE) Candidates having Masters Degree in a relevant Discipline and fulfilling the general eligibility criteria may apply Course work details are given in the section on PhD Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Appendix RU-I Programme Names and Codes Sl. No. Name of the Programme Programme Code Name of the School 1. Doctor of Philosophy in Agriculture Extension PHDAGE SOA 2. Doctor of Philosophy in Dairy Science and Technology PHDDR SOA 3. Doctor of Philosophy in Child Development PHDCDEV SOCE 4. Doctor of Philosophy in Food and Nutrition PHDFN SOCE 5. Doctor of Philosophy in Computer and Information Sciences PHDCISC SOCIS 6. Doctor of Philosophy in Education PHDEDU SOE 7. Doctor of Philosophy in Civil Engineering PHDCENG SOET 8. Doctor of Philosophy in Mechanical Engineering PHDCMCE SOET 9. Doctor of Philosophy in Gender and Development Studies PHDGDS SOGDS 10. Doctor of Philosophy in Women’s Studies PHDWS SOGDS 11. Doctor of Philosophy in Hindi PHDHIN SOH 12. Doctor of Philosophy in English PHDENG SOH 13. Doctor of Philosophy in Nursing PHDNUR SOHS 14. Doctor of Philosophy in Inter-disciplinary and Trans-disciplinary Studies IPHDAP SOITS 15. Doctor of Philosophy in Commerce PHDCOM SOMS 16. Doctor of Philosophy in Management PHDMGMT SOMS 17. Doctor of Philosophy in Biochemistry * To be Allotted SOS 18. Doctor of Philosophy in Chemistry PHDCHE SOS 19. Doctor of Philosophy in Geography * To be Allotted SOS 20. Doctor of Philosophy in Geology * To be Allotted SOS 21. Doctor of Philosophy in Life Sciences PHDLS SOS 22. Doctor of Philosophy in Physics PHDPH SOS 23. Doctor of Philosophy in Translation Studies PHDTT SOTST 24. Doctor of Philosophy in Tourism and Hospitality PHDTS SOTHSM 25. Doctor of Philosophy in Distance Education PHDDE STRIDE 26. Doctor of Philosophy in Vocational Education PHDVED SOVET 27. Master of Philosophy in Translation Studies MPHILTT SOTST 28. Master of Philosophy in Distance Education MPHILDE STRIDE * To be allotted through a Supplementary Communication Research Unit, IGNOU 53 53Handbook & Prospectus-PhD/MPhil Appendix RU-II State Codes Code Description Code Description 01 Andhra Pradesh 19 Mizoram 02 Andaman & Nicobar Islands (UT) 20 Nagaland 03 Arunachal Pradesh 21 Orissa 04 Assam 22 Punjab 05 Bihar 23 Rajasthan 06 Chandigarh (UT) 24 Sikkim 07 Delhi 25 Tamil Nadu 08 Goa 26 Tripura 09 Gujarat 27 Uttar Pradesh 10 Haryana 28 West Bengal 11 Himachal Pradesh 29 Dadra & Nagar Haveli, Daman & Diu (UT) 12 Jammu & Kashmir 30 Lakshadweep (UT) 13 Karnataka 31 Pondicherry (UT) 14 Kerala 32 C/o 99 APO 15 Madhya Pradesh 33 Learners Abroad 16 Maharashtra 34 Chattisgarh 17 Manipur 35 Jharkhand 18 Meghalaya 36 Uttarakhand 54 Research Unit, IGNOUHandbook & Prospectus-PhD/MPhil Appendix RU-III AFFIDAVIT BY THE STUDENT (TO BE SUBMIITED ALONGWITH APPLICATION FORM) 1. I, ___________________________________________________________________ (full name of the student with Admission/Registration/Enrolment Number) S/o D/o Mr./Mrs./Ms. _________________________________________ having been admitted to ___________________________ (name of the Institution), have received a copy of the UGC Regulations on Curbing the Menace of Ragging in Higher Educational Institutions, 2009, (hereinafter called the “Regulations”) carefully read and fully understand the provisions contained in the said Regulations. 2. I have, in particular, perused Clause 3 of the Regulations and am aware as to what constitutes ragging. 3. I have also, in particular, perused Clause 7 and Clause 9.1 of the Regulations and am fully aware or the penal and administrative action that is liable to be taken against me in case I am found guilty of or abetting ragging, actively or passively, or being part of a conspiracy to promote ragging. 4. I hereby solemnly aver and undertake that (a) I will not indulge in any behaviour or act that may be constituted as ragging under Clause 3 of the Regulations. (b) I will not participate in or abet or propagate through any act of commission or omission that may be constituted as ragging under Clause 3 of the Regulations. 5. I hereby affirm that, if found guilty of ragging, I am liable for punishment according to Clause 9.1 of the Regulations, without prejudice to any other criminal action that may be taken against me under any penal law or any law for the time being in force. 6. I hereby declare that I have not been expelled or debarred from admission in any institution in the country on account of being found guilty of, abetting or being part of a conspiracy to promote, ragging and further affirm that, in case the declaration is found to be untrue, I am aware that my admission is liable to be cancelled. Declared this ____________________ day of ____________ month of _______________ year. _____________________ Signature of deponent Name : Address : Tel./Mobile No. : VERIFICATION Verified that the contents of this affidavit are true to the best of my knowledge and no part of the affidavit is false and nothing has been concealed or misstated therein. Verified at _______________ (place) this the ___________ (day) of ______________________ (month), ________________________ (year). Signature of deponent Solemnly affirmed and signed in my presence on this the _______ (day) of ________________ (month), __________________ (year) after reading the contents of this affidavit. OATH COMMISSIONER Research Unit, IGNOU 55 55Handbook & Prospectus-PhD/MPhil Appendix RU-IV AFFIDAVIT BY PARENT/GUARDIAN (TO BE SUBMIITED ALONGWITH APPLICATION FORM) 1. I, Mr./Mrs./Ms.________________________________________________________ (full name of Parent/Guardian/ Father/Mother/Guardian of, __________________________________________________ (full name of Student with Admission/Registration/Enrolment Number), having been admitted to ________________________ (name of the institution), have received a copy of the UGC Regulations on Curbing the Menace of Ragging in Higher Educational Institutions, 2009, (hereinafter called the “Regulations”) carefully read and fully understand the provisions contained in the said Regulations. 2. I have, in particular, perused Clause 3 of the Regulations and am aware as to what constitutes ragging. 3. I have also, in particular, perused Clause 7 and Clause 9.1 of the Regulations and am fully aware or the penal and administrative action that is liable to be taken against me in case I am found guilty of or abetting ragging, actively or passively, or being part of a conspiracy to promote ragging. 4. I hereby solemnly aver and undertake that (a) I will not indulge in any behaviour or act that may be constituted as ragging under Clause 3 of the Regulations. (b) I will not participate in or abet or propagate through any act of commission or omission that may be constituted as ragging under Clause 3 of the Regulations. 5. I hereby affirm that, if found guilty of ragging, I am liable for punishment according to Clause 9.1 of the Regulations, without prejudice to any other criminal action that may be taken against me under any penal law or any law for the time being in force. 6. I hereby declare that I have not been expelled or debarred from admission in any institution in the country on account of being found guilty of, abetting or being part of a conspiracy to promote, ragging and further affirm that, in case the declaration is found to be untrue, I am aware that my admission is liable to be cancelled. Declared this ____________________ day of ____________ month of _______________ year. _____________________ Signature of deponent Name : Address : Tel./Mobile No. : VERIFICATION Verified that the contents of this affidavit are true to the best of my knowledge and no part of the affidavit is false and nothing has been concealed or misstated therein. Verified at ___________________ (place) this the ___________ (day) of __________________________ (month), ________________________ (year). Signature of deponent Solemnly affirmed and signed in my presence on this the _______ (day) of ________________ (month), __________________ (year) after reading the contents of this affidavit. OATH COMMISSIONER 56 Research Unit, IGNOU.Concurrent Programming in JavaTM: Design Principles and Patterns, SecondEditionBy Doug LeaPublisher: Addison WesleyPub Date: October 01, 1999ISBN: 0-201-31009-0Pages: 432In Concurrent Programming in Java, Second Edition, you will find thoroughlyupdated coverage of the Java 2 platform and new or expanded coverage of:••••Memory modelCancellationPortable parallel programmingUtility classes for concurrency controlThe Java platform provides a broad and powerful set of APIs, tools, and technologies.One of its most powerful capabilities is the built-in support for threads. This makesconcurrent programming an attractive yet challenging option for programmers usingthe Java programming language.This book shows readers how to use the Java platform's threading model moreprecisely by helping them to understand the patterns and tradeoffs associated withconcurrent programming.You will learn how to initiate, control, and coordinate concurrent activities using theclass java.lang.Thread, the keywords synchronized and volatile, and the methods wait,notify, and notifyAll. In addition, you will find detailed coverage of all aspects ofconcurrent programming, including such topics as confinement and synchronization,deadlocks and conflicts, state-dependent action control, asynchronous message passingand control flow, coordinated interaction, and structuring web-based andcomputational services.The book targets intermediate to advanced programmers interested in mastering thecomplexities of concurrent programming. Taking a design pattern approach, the bookoffers standard design techniques for creating and implementing components thatsolve common concurrent programming challenges. The numerous code examplesthroughout help clarify the subtleties of the concurrent programming conceptsdiscussed.CopyrightAcknowledgmentsChapter 1. Concurrent Object-Oriented ProgrammingSection 1.1. Using Concurrency ConstructsSection 1.2. Objects and ConcurrencySection 1.3. Design ForcesSection 1.4. Before/After PatternsChapter 2. ExclusionSection 2.1. ImmutabilitySection 2.2. SynchronizationSection 2.3. ConfinementSection 2.4. Structuring and Refactoring ClassesSection 2.5. Using Lock UtilitiesChapter 3. State DependenceSection 3.1. Dealing with FailureSection 3.2. Guarded MethodsSection 3.3. Structuring and Refactoring ClassesSection 3.4. Using Concurrency Control UtilitiesSection 3.5. Joint ActionsSection 3.6. TransactionsSection 3.7. Implementing UtilitiesChapter 4. Creating ThreadsSection 4.1. Oneway MessagesSection 4.2. Composing Oneway MessagesSection 4.3. Services in ThreadsSection 4.4. Parallel DecompositionSection 4.5. Active ObjectsCopyrightMany of the designations used by manufacturers and sellers to distinguish their products are claimedas trademarks. Where those designations appear in this book and Addison-Wesley was aware of atrademark claim, the designations have been printed in initial caps or all caps.DukeTM designed by Joe Palrang.Sun Microsystems, Inc. has intellectual property rights relating to implementations of the technologydescribed in this publication. In particular, and without limitation, these intellectual property rightsmay include one or more U.S. patents, foreign patents, or pending applications. Sun, SunMicrosystems, the Sun Logo, and all Sun, Java, Jini, and Solaris based trademarks and logos aretrademarks or registered trademarks of Sun Microsystems, Inc. in the United States and othercountries. UNIX is a registered trademark in the United States and other countries, exclusivelylicensed through X/Open Company, Ltd.As used in this book, the terms "Java virtual machine" and "JVM" mean a virtual machine for the Javaplatform.THIS PUBLICATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHEREXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIESOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OR NON-INFRINGEMENT.THIS PUBLICATION COULD INCLUDE TECHNICAL INACCURACIES ORTYPOGRAPHICAL ERRORS. CHANGES ARE PERIODICALLY ADDED TO THEINFORMATION HEREIN; THESE CHANGES WILL BE INCORPORATED IN NEW EDITIONSOF THE PUBLICATION. SUN MICROSYSTEMS, INC. MAY MAKE IMPROVEMENTSAND/OR CHANGES IN ANY TECHNOLOGY, PRODUCT, OR PROGRAM DESCRIBED INTHIS PUBLICATION AT ANY TIME.The author and publisher have taken care in the preparation of this document, but make no expressedor implied warranty of any kind and assume no responsibility for errors or omissions. No liability isassumed for incidental or consequential damages in connection with or arising out of the use of theinformation or programs contained herein.Library of Congress Card Number 99-066823Copyright © 2000 by Addison Wesley Longman, Inc. All rights reserved. No part of this publicationmay be reproduced, stored in a retrieval system, or transmitted, in any form, or by any means,electronic, mechanical, photocopying, recording, or otherwise, without the prior consent of thepublisher. Printed in the United States of America. Published simultaneously in Canada.Text printed on recycled and acid-free paper.2 3 4 5 6 7 - MA - 02 01 00 99Second printing, November 1999AcknowledgmentsThis book began as a small set of Web pages that I put together in spring 1995, while trying to makesense of my own early attempts to use Java concurrency features in experimental development efforts.Then it grew; first on the World Wide Web, where I extended, expanded, and removed patterns toreflect my and other people's increasing experience with Java concurrency; and now into this book,which places patterns within the broader perspective of concurrent software development. The webpages also live on, but they now serve as a supplement to the conceptual presentations best suited tobook form.There have been many changes along the way, in a process that has benefited from commentary,suggestions, errata reports, and exchanges with many kind and knowledgeable people. These includeOle Agesen, Tatsuya Aoyagi, Taranov Alexander, Moti Ben-Ari, Peter Buhr, Bruce Chapman, Il-Hyung Cho, Colin Cooper, Kelly Davis, Bruce Eckel, Yacov Eckel, Saleh Elmohamed, Ed Falis,Randy Farmer, Glenn Goldstein, David Hanson, Jyrki Heikkinen, Alain Hsiung, Jerry James,Johannes Johannsen, Istvan Kiss, Ross Knippel, Bil Lewis, Sheng Liang, Jonathan Locke, SteveMacDonald, Hidehiko Masuhara, Arnulf Mester, Mike Mills, Trevor Morris, Bill Pugh, AndrewPurshottam, Simon Roberts, John Rose, Rodney Ryan, Joel Rosi-Schwartz, Miles Sabin, Aamod Sane,Beverly Sanders, Doug Schmidt, Kevin Shank, Yukari Shirota, David Spitz, David Stoutamire, HenryStory, Sumana Srinivasan, Satish Subramanian, Jeff Swartz, Patrick Thompson, Volker Turau, DennisUlrich, Cees Vissar, Bruce Wallace, Greg Wilson, Grant Woodside, Steve Yen, and Dave Yost, aswell as people who submitted anonymous electronic mail commentary.The members of Ralph Johnson's patterns seminar (especially Brian Foote and Ian Chai) read throughearly forms of some patterns and suggested many improvements. Raj Datta, Sterling Barrett, andPhilip Eskelin of the New York City Patterns Group, and Russ Rufer, Ming Kwok, Mustafa Ozgen,Edward Anderson, and Don Chin of the Silicon Valley Patterns Group performed similar valuableservice for preliminary versions of the second edition.Official and unofficial reviewers of the first- and second-edition manuscripts made helpful commentsand suggestions on tight schedules. They include Ken Arnold, Josh Bloch, Joseph Bowbeer, PatrickChan, Gary Craig, Desmond D'Souza, Bill Foote, Tim Harrison, David Henderson, Tim Lindholm,Tom May, Oscar Nierstrasz, James Robins, Greg Travis, Mark Wales, Peter Welch, and DeborraZukowski. Very special thanks go to Tom Cargill for his many insights and corrections, as well as forpermission to include a description of his Specific Notification pattern. Very special thanks also go toDavid Holmes for, among many contributions, helping to develop and extend material for tutorialsthat in turn became included in the second edition.Rosemary Simpson contributed numerous improvements in the course of creating the index. KenArnold patiently helped me deal with FrameMaker. Mike Hendrickson and the editorial crew atAddison-Wesley have been continually supportive.This book would not have been possible without the generous support of Sun Labs. Thanks especiallyto Jos Marlowe and Steve Heller for providing opportunities to work collaboratively on fun andexciting research and development projects.Thanks above all to Kathy, Keith, and Colin for tolerating all this.Doug Lea, September, 1999Chapter 1. Concurrent Object-Oriented ProgrammingThis book discusses some ways of thinking about, designing, and implementing concurrent programsin the JavaTM programming language. Most presentations in this book assume that you are anexperienced developer familiar with object-oriented (OO) programming, but have little exposure toconcurrency. Readers with the opposite background — experience with concurrency in otherlanguages — may also find this book useful.The book is organized into four coarse-grained chapters. (Perhaps parts would be a better term.) Thisfirst chapter begins with a brief tour of some frequently used constructs and then backs up to establisha conceptual basis for concurrent object-oriented programming: how concurrency and objects fittogether, how the resulting design forces impact construction of classes and components, and howsome common design patterns can be used to structure solutions.The three subsequent chapters are centered around use (and evasion) of the three kinds of concurrencyconstructs found in the Java programming language:Exclusion. Maintaining consistent states of objects by preventing unwanted interference amongconcurrent activities, often using synchronized methods.State dependence. Triggering, preventing, postponing, or recovering from actions depending onwhether objects are in states in which these actions could or did succeed, sometimes using monitormethods Object.wait , Object.notify , and Object.notifyAll .Creating threads. Establishing and managing concurrency, using Thread objects.Each chapter contains a sequence of major sections, each on an independent topic. They present high-level design principles and strategies, technical details surrounding constructs, utilities thatencapsulate common usages, and associated design patterns that address particular concurrencyproblems. Most sections conclude with an annotated set of further readings providing moreinformation on selected topics. The online supplement to this book contains links to additional onlineresources, as well as updates, errata, and code examples. It is accessible via links from:http://java.sun.com/Series or http://gee.cs.oswego.edu/dl/cpjIf you are already familiar with the basics, you can read this book in the presented order to exploreeach topic in more depth. But most readers will want to read this book in various different orders.Because most concurrency concepts and techniques interact with most others, it is not always possibleto understand each section or chapter in complete isolation from all the others. However, you can stilltake a breadth-first approach, briefly scanning each chapter (including this one) before proceedingwith more detailed coverage of interest. Many presentations later in the book can be approached afterselectively reading through earlier material indicated by extensive cross-references.You can practice this now by skimming through the following preliminaries.Terminology. This book uses standard OO terminological conventions: programs define methods(implementing operations) and fields (representing attributes) that hold for all instances (objects) ofspecified classes.Interactions in OO programs normally revolve around the responsibilities placed upon a client objectneeding an action to be performed, and a server object containing the code to perform the action. Theterms client and server are used here in their generic senses, not in the specialized sense of distributedclient/server architectures. A client is just any object that sends a request to another object, and aserver is just any object receiving such a request. Most objects play the roles of both clients andservers. In the usual case where it doesn't matter whether an object under discussion acts as a client orserver or both, it is usually called a host; others that it may in turn interact with are often calledhelpers or peers. Also, when discussing invocations of the form obj.msg(arg) , the recipient(that is, the object bound to variable obj ) is called the target object.This book generally avoids dealing with transient facts about particular classes and packages notdirectly related to concurrency. And it does not cover details about concurrency control in specializedframeworks such as Enterprise JavaBeansTM and Servlets. But it does sometimes refer to brandedsoftware and trademarked products associated with the JavaTM Platform. The copyright page of thisbook provides more information.Code listings. Most techniques and patterns in this book are illustrated by variants of an annoyinglysmall set of toy running examples. This is not an effort to be boring, but to be clear. Concurrencyconstructs are often subtle enough to get lost in otherwise meaningful examples. Reuse of runningexamples makes small but critical differences more obvious by highlighting the main design andimplementation issues. Also, the presentations include code sketches and fragments of classes thatillustrate implementation techniques, but are not intended to be complete or even compilable. Theseclasses are indicated by leading comments in the listings.Import statements, access qualifiers, and even methods and fields are sometimes omitted from listingswhen they can be inferred from context or do not impact relevant functionality. The protectedqualifier is used as a default for non-public features whenever there is no particular reason to restrictsubclass access. This emphasizes opportunities for extensibility in concurrent class design (see § 1.3.4and § 3.3.3). Classes by default have no access qualifier. Sample listings are sometimes formatted innonstandard ways to keep them together on pages or to emphasize the main constructions of interest.The code for all example classes in this book is available from the online supplement. Most techniquesand patterns in this book are illustrated by a single code example showing their most typical forms.The supplement includes additional examples that demonstrate minor variations, as well as some linksto other known usages. It also includes some larger examples that are more useful to browse andexperiment with online than to read as listings.The supplement provides links to a package, util.concurrent , that contains production-quality versions of utility classes discussed in this book. This code runs on the Java 2 Platform and hasbeen tested with 1.2.x releases. Occasional discussions, asides, and footnotes briefly mention changesfrom previous releases, potential future changes known at the time of this writing, and a fewimplementation quirks to watch out for. Check the online supplement for additional updates.Diagrams. Standard UML notation is used for interaction and class diagrams (see the FurtherReadings in § 1.1.3). The accompanying diagrams (courtesy of Martin Fowler) illustrate the onlyforms used in this book. Other aspects of UML notation, methodology, and terminology are notspecifically relied on.Most other diagrams show timethreads in which free-form gray curves trace threads traversingthrough collections of objects. Flattened arrowheads represent blocking. Objects are depicted as ovalsthat sometimes show selected internal features such as locks, fields, and bits of code. Thin (usuallylabeled) lines between objects represent relations (normally references or potential calls) betweenthem. Here's an otherwise meaningless example showing that thread A has acquired the lock for objectX, and is proceeding through some method in object Y that serves as a helper to X. Thread B ismeanwhile somehow blocked while entering some method in object X:1.1 Using Concurrency ConstructsThis section introduces basic concurrency support constructs by example and then proceeds with awalk-through of the principal methods of class Thread . Other concurrency constructs are brieflydescribed as they are introduced, but full technical details are postponed to later chapters (mainly §2.2.1 and § 3.2.2). Also, concurrent programs often make use of a few ordinary Java programminglanguage features that are not as widely used elsewhere. These are briefly reviewed as they arise.1.1.1 A Particle AppletParticleApplet is an Applet that displays randomly moving particles. In addition toconcurrency constructs, this example illustrates a few of the issues encountered when using threadswith any GUI-based program. The version described here needs a lot of embellishment to be visuallyattractive or realistic. You might enjoy experimenting with additions and variations as an exercise.As is typical of GUI-based programs, ParticleApplet uses several auxiliary classes that domost of the work. We'll step through construction of the Particle and ParticleCanvasclasses before discussing ParticleApplet .1.1.1.1 ParticleThe Particle class defines a completely unrealistic model of movable bodies. Each particle isrepresented only by its (x, y) location. Each particle also supports a method to randomly change itslocation and a method to draw itself (as a small square) given a supplied java.awt.Graphicsobject.While Particle objects do not themselves exhibit any intrinsic concurrency, their methods may beinvoked across multiple concurrent activities. When one activity is performing a move and another isinvoking draw at about the same time, we'd like to make sure that the draw paints an accuraterepresentation of where the Particle is. Here, we require that draw uses the location valuescurrent either before or after the move. For example, it would be conceptually wrong for a drawoperation to display using the y-value current before a given move, but the x-value current after themove. If we were to allow this, then the draw method would sometimes display the particle at alocation that it never actually occupied.This protection can be obtained using the synchronized keyword, which can modify either amethod or a block of code. Every instance of class Object (and its subclasses) possesses a lock thatis obtained on entry to a synchronized method and automatically released upon exit. The code-block version works in the same way except that it takes an argument stating which object to lock. Themost common argument is this , meaning to lock the object whose method is executing. When alock is held by one thread, other threads must block waiting for the holding thread to release the lock.Locking has no effect on non-synchronized methods, which can execute even if the lock is being heldby another thread.Locking provides protection against both high-level and low-level conflicts by enforcing atomicityamong methods and code-blocks synchronized on the same object. Atomic actions areperformed as units, without any interleaving of the actions of other threads. But, as discussed in §1.3.2 and in Chapter 2, too much locking can also produce liveness problems that cause programs tofreeze up. Rather than exploring these issues in detail now, we'll rely on some simple default rules forwriting methods that preclude interference problems:•••Always lock during updates to object fields.Always lock during access of possibly updated object fields.Never lock when invoking methods on other objects.These rules have many exceptions and refinements, but they provide enough guidance to write classParticle :import java.util.Random;class Particle {protected int x;protected int y;protected final Random rng = new Random();public Particle(int initialX, int initialY) {x = initialX;y = initialY;}public synchronized void move() {x += rng.nextInt(10) - 5;y += rng.nextInt(20) - 10;}public void draw(Graphics g) {int lx, ly;synchronized (this) { lx = x; ly = y; }g.drawRect(lx, ly, 10, 10);}}Notes:•••The use of final in the declaration of the random number generator rng reflects ourdecision that this reference field cannot be changed, so it is not impacted by our locking rules.Many concurrent programs use final extensively, in part as helpful, automaticallyenforced documentation of design decisions that reduce the need for synchronization (see §2.1).The draw method needs to obtain a consistent snapshot of both the x and y values. Since asingle method can return only one value at a time, and we need both the x and y values here,we cannot easily encapsulate the field accesses as a synchronized method. We insteaduse a synchronized block. (See § 2.4 for some alternatives.)The draw method conforms to our rule of thumb to release locks during method invocationson other objects (here g.drawRect ). The move method appears to break this rule bycalling rng.nextInt . However, this is a reasonable choice here because eachParticle confines its own rng — conceptually, the rng is just a part of theParticle itself, so it doesn't count as an "other" object in the rule. Section § 2.3 describesmore general conditions under which this sort of reasoning applies and discusses factors thatshould be taken into account to be sure that this decision is warranted.1.1.1.2 ParticleCanvasParticleCanvas is a simple subclass of java.awt.Canvas that provides a drawing areafor all of the Particles . Its main responsibility is to invoke draw for all existing particleswhenever its paint method is called.However, the ParticleCanvas itself does not create or manage the particles. It needs either tobe told about them or to ask about them. Here, we choose the former.The instance variable particles holds the array of existing Particle objects. This field is setwhen necessary by the applet, but is used in the paint method. We can again apply our defaultrules, which in this case lead to the creation of little synchronized get and set methods (alsoknown as accessor and assignment methods) for particles , otherwise avoiding direct access ofthe particles variable itself. To simplify and to enforce proper usage, the particles field isnever allowed to be null . It is instead initialized to an empty array:class ParticleCanvas extends Canvas {private Particle[] particles = new Particle[0];ParticleCanvas(int size) {setSize(new Dimension(size, size));}// intended to be called by appletprotected synchronized void setParticles(Particle[] ps) {if (ps == null)throw new IllegalArgumentException("Cannot set null");particles = ps;}protected synchronized Particle[] getParticles() {return particles;}public void paint(Graphics g) { // override Canvas.paintParticle[] ps = getParticles();for (int i = 0; i < ps.length; ++i)ps[i].draw(g);}}1.1.1.3 ParticleAppletThe Particle and ParticleCanvas classes could be used as the basis of several differentprograms. But in ParticleApplet all we want to do is set each of a collection of particles inautonomous "continuous" motion and update the display accordingly to show where they are. Tocomply with standard applet conventions, these activities should begin when Applet.start isexternally invoked (normally from within a web browser), and should end when Applet.stop isinvoked. (We could also add buttons allowing users to start and stop the particle animationthemselves.)There are several ways to implement all this. Among the simplest is to associate an independent loopwith each particle and to run each looping action in a different thread.Actions to be performed within new threads must be defined in classes implementingjava.lang.Runnable . This interface lists only the single method run , taking no arguments,returning no results, and throwing no checked exceptions:public interface java.lang.Runnable {void run();}An interface encapsulates a coherent set of services and attributes (broadly, a role) withoutassigning this functionality to any particular object or code. Interfaces are more abstract than classessince they say nothing at all about representations or code. All they do is describe the signatures(names, arguments, result types, and exceptions) of public operations, without even pinning down theclasses of the objects that can perform them. The classes that can support Runnable typically havenothing in common except that they contain a run method.Each instance of the Thread class maintains the control state necessary to execute and manage thecall sequence comprising its action. The most commonly used constructor in class Thread accepts aRunnable object as an argument, which arranges to invoke the Runnable 's run method whenthe thread is started. While any class can implement Runnable , it often turns out to be bothconvenient and helpful to define a Runnable as an anonymous inner class.The ParticleApplet class uses threads in this way to put particles into motion, and cancelsthem when the applet is finished. This is done by overriding the standard Applet methods startand stop (which have the same names as, but are unrelated to, methods Thread.start andThread.stop ).The above interaction diagram shows the main message sequences during execution of the applet. Inaddition to the threads explicitly created, this applet interacts with the AWT event thread, described inmore detail in § 4.1.4. The producer-consumer relationship extending from the omitted right hand sideof the interaction diagram takes the approximate form:public class ParticleApplet extends Applet {protected Thread[] threads = null; // null when not runningprotected final ParticleCanvas canvas= new ParticleCanvas(100);public void init() { add(canvas); }protected Thread makeThread(final Particle p) { // utilityRunnable runloop = new Runnable() {public void run() {try {for(;;) {p.move();canvas.repaint();Thread.sleep(100); // 100msec is arbitrary}}catch (InterruptedException e) { return; }}};return new Thread(runloop);}public synchronized void start() {int n = 10; // just for demoif (threads == null) { // bypass if already startedParticle[] particles = new Particle[n];for (int i = 0; i < n; ++i)particles[i] = new Particle(50, 50);canvas.setParticles(particles);threads = new Thread[n];for (int i = 0; i < n; ++i) {threads[i] = makeThread(particles[i]);threads[i].start();}}}public synchronized void stop() {if (threads != null) { // bypass if already stoppedfor (int i = 0; i < threads.length; ++i)threads[i].interrupt();threads = null;}}}Notes:••••••The action in makeThread defines a "forever" loop (which some people prefer to writeequivalently as " while (true) ") that is broken only when the current thread isinterrupted. During each iteration, the particle moves, tells the canvas to repaint so the movewill be displayed, and then does nothing for a while, to slow things down to a human-viewable rate. Thread.sleep pauses the current thread. It is later resumed by a systemtimer.One reason that inner classes are convenient and useful is that they capture all appropriatecontext variables — here p and canvas — without the need to create a separate class withfields that record these values. This convenience comes at the price of one minorawkwardness: All captured method arguments and local variables must be declared asfinal , as a guarantee that the values can indeed be captured unambiguously. Otherwise, forexample, if p were reassigned after constructing the Runnable inside methodmakeThread , then it would be ambiguous whether to use the original or the assignedvalue when executing the Runnable .The call to canvas.repaint does not directly invoke canvas.paint . Therepaint method instead places an UpdateEvent on a java.awt.EventQueue .(This may be internally optimized and further manipulated to eliminate duplicate events.) Ajava.awt.EventDispatchThread asynchronously takes this event from the queueand dispatches it by (ultimately) invoking canvas.paint . This thread and possibly othersystem-created threads may exist even in nominally single-threaded programs.The activity represented by a constructed Thread object does not begin until invocation ofthe Thread.start method.As discussed in § 3.1.2, there are several ways to cause a thread's activity to stop. Thesimplest is just to have the run method terminate normally. But in infinitely loopingmethods, the best option is to use Thread.interrupt . An interrupted thread willautomatically abort (via an InterruptedException ) from the methodsObject.wait , Thread.join , and Thread.sleep . Callers can then catch thisexception and take any appropriate action to shut down. Here, the catch in runloop justcauses the run method to exit, which in turn causes the thread to terminate.The start and stop methods are synchronized to preclude concurrent starts orstops. Locking works out OK here even though these methods need to perform manyoperations (including calls to other objects) to achieve the required started-to-stopped orstopped-to-started state transitions. Nullness of variable threads is used as a convenientstate indicator.1.1.2 Thread MechanicsA thread is a call sequence that executes independently of others, while at the same time possiblysharing underlying system resources such as files, as well as accessing other objects constructedwithin the same program (see § 1.2.2). A java.lang.Thread object maintains bookkeeping andcontrol for this activity.Every program consists of at least one thread — the one that runs the main method of the classprovided as a startup argument to the Java virtual machine ("JVM"). Other internal backgroundthreads may also be started during JVM initialization. The number and nature of such threads varyacross JVM implementations. However, all user-level threads are explicitly constructed and startedfrom the main thread, or from any other threads that they in turn create.Here is a summary of the principal methods and properties of class Thread , as well as a few usagenotes. They are further discussed and illustrated throughout this book. The JavaTM LanguageSpecification ("JLS") and the published API documentation should be consulted for more detailed andauthoritative descriptions.1.1.2.1 ConstructionDifferent Thread constructors accept combinations of arguments supplying:•••A Runnable object, in which case a subsequent Thread.start invokes run of thesupplied Runnable object. If no Runnable is supplied, the default implementation ofThread.run returns immediately.A String that serves as an identifier for the Thread . This can be useful for tracing anddebugging, but plays no other role.The ThreadGroup in which the new Thread should be placed. If access to theThreadGroup is not allowed, a SecurityException is thrown.Class Thread itself implements Runnable . So, rather than supplying the code to be run in aRunnable and using it as an argument to a Thread constructor, you can create a subclass ofThread that overrides the run method to perform the desired actions. However, the best defaultstrategy is to define a Runnable as a separate class and supply it in a Thread constructor.Isolating code within a distinct class relieves you of worrying about any potential interactions ofsynchronized methods or blocks used in the Runnable with any that may be used bymethods of class Thread . More generally, this separation allows independent control over the natureof the action and the context in which it is run: The same Runnable can be supplied to threads thatare otherwise initialized in different ways, as well as to other lightweight executors (see § 4.1.4). Alsonote that subclassing Thread precludes a class from subclassing any other class.Thread objects also possess a daemon status attribute that cannot be set via any Threadconstructor, but may be set only before a Thread is started. The method setDaemon asserts thatthe JVM may exit, abruptly terminating the thread, so long as all other non-daemon threads in theprogram have terminated. The isDaemon method returns status. The utility of daemon status is verylimited. Even background threads often need to do some cleanup upon program exit. (The spelling ofdaemon, often pronounced as "day-mon", is a relic of systems programming tradition. Systemdaemons are continuous processes, for example print-queue managers, that are "always" present on asystem.)1.1.2.2 Starting threadsInvoking its start method causes an instance of class Thread to initiate its run method as anindependent activity. None of the synchronization locks held by the caller thread are held by the newthread (see § 2.2.1).A Thread terminates when its run method completes by either returning normally or throwing anunchecked exception (i.e., RuntimeException , Error , or one of their subclasses). Threadsare not restartable, even after they terminate. Invoking start more than once results in anInvalidThreadStateException .The method isAlive returns true if a thread has been started but has not terminated. It willreturn true if the thread is merely blocked in some way. JVM implementations have been known todiffer in the exact point at which isAlive returns false for threads that have been cancelled (see§ 3.1.2). There is no method that tells you whether a thread that is not isAlive has ever beenstarted. Also, one thread cannot readily determine which other thread started it, although it maydetermine the identities of other threads in its ThreadGroup (see § 1.1.2.6).1.1.2.3 PrioritiesTo make it possible to implement the Java virtual machine across diverse hardware platforms andoperating systems, the Java programming language makes no promises about scheduling or fairness,and does not even strictly guarantee that threads make forward progress (see § 3.4.1.5). But threads dosupport priority methods that heuristically influence schedulers:••••Each Thread has a priority, ranging between Thread.MIN_PRIORITY andThread.MAX_PRIORITY (defined as 1 and 10 respectively).By default, each new thread has the same priority as the thread that created it. The initialthread associated with a main by default has priority Thread.NORM_PRIORITY ( 5 ).The current priority of any thread can be accessed via method getPriority .The priority of any thread can be dynamically changed via method setPriority . Themaximum allowed priority for a thread is bounded by its ThreadGroup .When more runnable (see § 1.3.2) threads than available CPUs, a scheduler is generally biased toprefer running those with higher priorities. The exact policy may and does vary across platforms. Forexample, some JVM implementations always select the thread with the highest current priority (withties broken arbitrarily). Some JVM implementations map the ten Thread priorities into a smallernumber of system-supported categories, so threads with different priorities may be treated equally.And some mix declared priorities with aging schemes or other scheduling policies to ensure that evenlow-priority threads eventually get a chance to run. Also, setting priorities may, but need not, affectscheduling with respect to other programs running on the same computer system.Priorities have no other bearing on semantics or correctness (see § 1.3). In particular, prioritymanipulations cannot be used as a substitute for locking. Priorities can be used only to express therelative importance or urgency of different threads, where these priority indications would be useful totake into account when there is heavy contention among threads trying to get a chance to execute. Forexample, setting the priorities of the particle animation threads in ParticleApplet below that ofthe applet thread constructing them might on some systems improve responsiveness to mouse clicks,and would at least not hurt responsiveness on others. But programs should be designed to run correctly(although perhaps not as responsively) even if setPriority is defined as a no-op. (Similarremarks hold for yield ; see § 1.1.2.5.)The following table gives one set of general conventions for linking task categories to prioritysettings. In many concurrent applications, relatively few threads are actually runnable at any giventime (others are all blocked in some way), in which case there is little reason to manipulate priorities.In other cases, minor tweaks in priority settings may play a small part in the final tuning of aconcurrent system.Range107-94-62-3UseCrisis managementInteractive, event-drivenIO-boundBackground computation1Run only if nothing else can1.1.2.4 Control methodsOnly a few methods are available for communicating across threads:•••Each Thread has an associated boolean interruption status (see § 3.1.2). Invokingt.interrupt for some Thread t sets t 's interruption status to true , unlessThread t is engaged in Object.wait , Thread.sleep , or Thread.join ; inthis case interrupt causes these actions (in t ) to throw InterruptedException ,but t 's interruption status is set to false .The interruption status of any Thread can be inspected using method isInterrupted .This method returns true if the thread has been interrupted via the interrupt methodbut the status has not since been reset either by the thread invokingThread.interrupted (see § 1.1.2.5) or in the course of wait , sleep , or jointhrowing InterruptedException .Invoking t.join() for Thread t suspends the caller until the target Thread tcompletes: the call to t.join() returns when t.isAlive() is false (see § 4.3.2).A version with a (millisecond) time argument returns control even if the thread has notcompleted within the specified time limit. Because of how isAlive is defined, it makes nosense to invoke join on a thread that has not been started. For similar reasons, it is unwiseto try to join a Thread that you did not create.Originally, class Thread supported the additional control methods suspend , resume , stop ,and destroy . Methods suspend , resume , and stop have since been deprecated; methoddestroy has never been implemented in any release and probably never will be. The effects ofmethods suspend and resume can be obtained more safely and reliably using the waiting andnotification techniques discussed in § 3.2. The problems surrounding stop are discussed in § 3.1.2.3.1.1.2.5 Static methodsSome Thread class methods can be applied only to the thread that is currently running (i.e., thethread making the call to the Thread method). To enforce this, these methods are declared asstatic .•Thread.currentThread returns a reference to the current Thread . This referencemay then be used to invoke other (non-static) methods. For example,Thread.currentThread().getPriority() returns the priority of the threadmaking the call.•Thread.interrupted clears interruption status of the current Thread and returnsprevious status. (Thus, one Thread 's interruption status cannot be cleared from otherthreads.)••Thread.sleep(long msecs) causes the current thread to suspend for at leastmsecs milliseconds (see § 3.2.2).Thread.yield is a purely heuristic hint advising the JVM that if there are any otherrunnable but non-running threads, the scheduler should run one or more of these threadsrather than the current thread. The JVM may interpret this hint in any way it likes.Despite the lack of guarantees, yield can be pragmatically effective on some single-CPU JVMimplementations that do not use time-sliced pre-emptive scheduling (see § 1.2.2). In this case, threadsare rescheduled only when one blocks (for example on IO, or via sleep ). On these systems, threadsthat perform time-consuming non-blocking computations can tie up a CPU for extended periods,decreasing the responsiveness of an application. As a safeguard, methods performing non-blockingcomputations that might exceed acceptable response times for event handlers or other reactive threadscan insert yields (or perhaps even sleeps ) and, when desirable, also run at lower prioritysettings. To minimize unnecessary impact, you can arrange to invoke yield only occasionally; forexample, a loop might contain:if (Math.random() < 0.01) Thread.yield();On JVM implementations that employ pre-emptive scheduling policies, especially those onmultiprocessors, it is possible and even desirable that the scheduler will simply ignore this hintprovided by yield .1.1.2.6 ThreadGroupsEvery Thread is constructed as a member of a ThreadGroup , by default the same group as thatof the Thread issuing the constructor for it. ThreadGroups nest in a tree-like fashion. When anobject constructs a new ThreadGroup , it is nested under its current group. The methodgetThreadGroup returns the group of any thread. The ThreadGroup class in turn supportsmethods such as enumerate that indicate which threads are currently in the group.One purpose of class ThreadGroup is to support security policies that dynamically restrict accessto Thread operations; for example, to make it illegal to interrupt a thread that is not in yourgroup. This is one part of a set of protective measures against problems that could occur, for example,if an applet were to try to kill the main screen display update thread. ThreadGroups may alsoplace a ceiling on the maximum priority that any member thread can possess.ThreadGroups tend not to be used directly in thread-based programs. In most applications,normal collection classes (for example java.util.Vector ) are better choices for trackinggroups of Thread objects for application-dependent purposes.Among the few ThreadGroup methods that commonly come into play in concurrent programs ismethod uncaughtException , which is invoked when a thread in a group terminates due to anuncaught unchecked exception (for example a NullPointerException ). This methodnormally causes a stack trace to be printed.1.1.3 Further ReadingsThis book is not a reference manual on the Java programming language. (It is also not exclusively ahow-to tutorial guide, or an academic textbook on concurrency, or a report on experimental research,or a book on design methodology or design patterns or pattern languages, but includes discussions oneach of these facets of concurrency.) Most sections conclude with lists of resources that provide moreinformation on selected topics. If you do a lot of concurrent programming, you will want to read moreabout some of them.The JLS should be consulted for more authoritative accounts of the properties of Java programminglanguage constructs summarized in this book:Gosling, James, Bill Joy, and Guy Steele. The JavaTM Language Specification, Addison-Wesley,1996. As of this writing, a second edition of JLS is projected to contain clarifications and updates forthe Java 2 Platform.Introductory accounts include:Arnold, Ken, and James Gosling. The JavaTM Programming Language, Second Edition, Addison-Wesley, 1998.If you have never written a program using threads, you may find it useful to work through either theonline or book version of the Threads section of:Campione, Mary, and Kathy Walrath. The JavaTM Tutorial, Second Edition, Addison-Wesley, 1998.A concise guide to UML notation is:Fowler, Martin, with Kendall Scott. UML Distilled, Second Edition, Addison-Wesley, 1999. TheUML diagram keys on pages 3-4 of the present book are excerpted by permission.A more extensive account of UML is:Rumbaugh, James, Ivar Jacobson, and Grady Booch. The Unified Modeling Language ReferenceManual, Addison-Wesley, 1999.1.2 Objects and ConcurrencyThere are many ways to characterize objects, concurrency, and their relationships. This sectiondiscusses several different perspectives — definitional, system-based, stylistic, and modeling-based —that together help establish a conceptual basis for concurrent object-oriented programming.1.2.1 ConcurrencyLike most computing terms, "concurrency" is tricky to pin down. Informally, a concurrent program isone that does more than one thing at a time. For example, a web browser may be simultaneouslyperforming an HTTP GET request to get an HTML page, playing an audio clip, displaying the numberof bytes received of some image, and engaging in an advisory dialog with a user. However, thissimultaneity is sometimes an illusion. On some computer systems these different activities mightindeed be performed by different CPUs. But on other systems they are all performed by a single time-shared CPU that switches among different activities quickly enough that they appear to besimultaneous, or at least nondeterministically interleaved, to human observers.A more precise, though not very interesting definition of concurrent programming can be phrasedoperationally: A Java virtual machine and its underlying operating system (OS) provide mappingsfrom apparent simultaneity to physical parallelism (via multiple CPUs), or lack thereof, by allowingindependent activities to proceed in parallel when possible and desirable, and otherwise by time-sharing. Concurrent programming consists of using programming constructs that are mapped in thisway. Concurrent programming in the Java programming language entails using Java programminglanguage constructs to this effect, as opposed to system-level constructs that are used to create newoperating system processes. By convention, this notion is further restricted to constructs affecting asingle JVM, as opposed to distributed programming, for example using remote method invocation(RMI), that involves multiple JVMs residing on multiple computer systems.Concurrency and the reasons for employing it are better captured by considering the nature of a fewcommon types of concurrent applications:Web services. Most socket-based web services (for example, HTTP daemons, servlet engines, andapplication servers) are multithreaded. Usually, the main motivation for supporting multipleconcurrent connections is to ensure that new incoming connections do not need to wait out completionof others. This generally minimizes service latencies and improves availability.Number crunching. Many computation-intensive tasks can be parallelized, and thus execute morequickly if multiple CPUs are present. Here the goal is to maximize throughput by exploitingparallelism.I/O processing. Even on a nominally sequential computer, devices that perform reads and writes ondisks, wires, etc., operate independently of the CPU. Concurrent programs can use the time otherwisewasted waiting for slow I/O, and can thus make more efficient use of a computer's resources.Simulation. Concurrent programs can simulate physical objects with independent autonomousbehaviors that are hard to capture in purely sequential programs.GUI-based applications. Even though most user interfaces are intentionally single-threaded, theyoften establish or communicate with multithreaded services. Concurrency enables user controls to stayresponsive even during time-consuming actions.Component-based software. Large-granularity software components (for example those providingdesign tools such as layout editors) may internally construct threads in order to assist in bookkeeping,provide multimedia support, achieve greater autonomy, or improve performance.Mobile code. Frameworks such as the java.applet package execute downloaded code inseparate threads as one part of a set of policies that help to isolate, monitor, and control the effects ofunknown code.Embedded systems. Most programs running on small dedicated devices perform real-time control.Multiple components each continuously react to external inputs from sensors or other devices, andproduce external outputs in a timely manner. As defined in The JavaTM Language Specification, theJava platform does not support hard real-time control in which system correctness depends on actionsbeing performed by certain deadlines. Particular run-time systems may provide the strongerguarantees required in some safety-critical hard-real-time systems. But all JVM implementationssupport soft real-time control, in which timeliness and performance are considered quality-of-serviceissues rather than correctness issues (see § 1.3.3). This reflects portability goals that enable the JVM tobe implemented on modern opportunistic, multipurpose hardware and system software.1.2.2 Concurrent Execution ConstructsThreads are only one of several constructs available for concurrently executing code. The idea ofgenerating a new activity can be mapped to any of several abstractions along a granularity continuumreflecting trade-offs of autonomy versus overhead. Thread-based designs do not always provide thebest solution to a given concurrency problem. Selection of one of the alternatives discussed below canprovide either more or less security, protection, fault-tolerance, and administrative control, with eithermore or less associated overhead. Differences among these options (and their associated programmingsupport constructs) impact design strategies more than do any of the details surrounding each one.1.2.2.1 Computer systemsIf you had a large supply of computer systems, you might map each logical unit of execution to adifferent computer. Each computer system may be a uniprocessor, a multiprocessor, or even a clusterof machines administered as a single unit and sharing a common operating system. This providesunbounded autonomy and independence. Each system can be administered and controlled separatelyfrom all the others.However, constructing, locating, reclaiming, and passing messages among such entities can beexpensive, opportunities for sharing local resources are eliminated, and solutions to problemssurrounding naming, security, fault-tolerance, recovery, and reachability are all relatively heavy incomparison with those seen in concurrent programs. So this mapping choice is typically applied onlyfor those aspects of a system that intrinsically require a distributed solution. And even here, all but thetiniest embedded computer devices host more than one process.1.2.2.2 ProcessesA process is an operating-system abstraction that allows one computer system to support many unitsof execution. Each process typically represents a separate running program; for example, an executingJVM. Like the notion of a "computer system", a "process" is a logical abstraction, not a physical one.So, for example, bindings from processes to CPUs may vary dynamically.Operating systems guarantee some degree of independence, lack of interference, and security amongconcurrently executing processes. Processes are generally not allowed to access one another's storagelocations (although there are usually some exceptions), and must instead communicate viainterprocess communication facilities such as pipes. Most systems make at least best-effort promisesabout how processes will be created and scheduled. This nearly always entails pre-emptive time-slicing — suspending processes on a periodic basis to give other processes a chance to run.The overhead for creating, managing, and communicating among processes can be a lot lower than inper-machine solutions. However, since processes share underlying computational resources (CPUs,memory, IO channels, and so on), they are less autonomous. For example, a machine crash caused byone process kills all processes.1.2.2.3 ThreadsThread constructs of various forms make further trade-offs in autonomy, in part for the sake of loweroverhead. The main trade-offs are:Sharing. Threads may share access to the memory, open files, and other resources associated with asingle process. Threads in the Java programming language may share all such resources. Someoperating systems also support intermediate constructions, for example "lightweight processes" and"kernel threads" that share only some resources, do so only upon explicit request, or impose otherrestrictions.Scheduling. Independence guarantees may be weakened to support cheaper scheduling policies. Atone extreme, all threads can be treated together as a single-threaded process, in which case they maycooperatively contend with each other so that only one thread is running at a time, without giving anyother thread a chance to run until it blocks (see § 1.3.2). At the other extreme, the underlyingscheduler can allow all threads in a system to contend directly with each other via pre-emptivescheduling rules. Threads in the Java programming language may be scheduled using any policy lyingat or anywhere between these extremes.Communication. Systems interact via communication across wires or wireless channels, for exampleusing sockets. Processes may also communicate in this fashion, but may also use lighter mechanismssuch as pipes and interprocess signalling facilities. Threads can use all of these options, plus othercheaper strategies relying on access to memory locations accessible across multiple threads, andemploying memory-based synchronization facilities such as locks and waiting and notificationmechanisms. These constructs support more efficient communication, but sometimes incur theexpense of greater complexity and consequently greater potential for programming error.1.2.2.4 Tasks and lightweight executable frameworksThe trade-offs made in supporting threads cover a wide range of applications, but are not alwaysperfectly matched to the needs of a given activity. While performance details differ across platforms,the overhead in creating a thread is still significantly greater than the cheapest (but least independent)way to invoke a block of code — calling it directly in the current thread.When thread creation and management overhead become performance concerns, you may be able tomake additional trade-offs in autonomy by creating your own lighter-weight execution frameworksthat impose further restrictions on usage (for example by forbidding use of certain forms of blocking),or make fewer scheduling guarantees, or restrict synchronization and communication to a morelimited set of choices. As discussed in § 4.1.4, these tasks can then be mapped to threads in about thesame way that threads are mapped to processes and computer systems.The most familiar lightweight executable frameworks are event-based systems and subsystems (see §1.2.3, § 3.6.4, and § 4.1), in which calls triggering conceptually asynchronous activities aremaintained as events that may be queued and processed by background threads. Several additionallightweight executable frameworks are described in Chapter 4. When they apply, construction and useof such frameworks can improve both the structure and performance of concurrent programs. Theiruse reduces concerns (see § 1.3.3) that can otherwise inhibit the use of concurrent executiontechniques for expressing logically asynchronous activities and logically autonomous objects (see §1.2.4).1.2.3 Concurrency and OO ProgrammingObjects and concurrency have been linked since the earliest days of each. The first concurrent OOprogramming language (created circa 1966), Simula, was also the first OO language, and was amongthe first concurrent languages. Simula's initial OO and concurrency constructs were somewhatprimitive and awkward. For example, concurrency was based around coroutines — thread-likeconstructs requiring that programmers explicitly hand off control from one task to another. Severalother languages providing both concurrency and OO constructs followed — indeed, even some of theearliest prototype versions of C++ included a few concurrency-support library classes. And Ada(although, in its first versions, scarcely an OO language) helped bring concurrent programming outfrom the world of specialized, low-level languages and systems.OO design played no practical role in the multithreaded systems programming practices emerging inthe 1970s. And concurrency played no practical role in the wide-scale embrace of OO programmingthat began in the 1980s. But interest in OO concurrency stayed alive in research laboratories andadvanced development groups, and has re-emerged as an essential aspect of programming in part dueto the popularity and ubiquity of the Java platform.Concurrent OO programming shares most features with programming of any kind. But it differs incritical ways from the kinds of programming you may be most familiar with, as discussed below.1.2.3.1 Sequential OO programmingConcurrent OO programs are often structured using the same programming techniques and designpatterns as sequential OO programs (see for example § 1.4). But they are intrinsically more complex.When more than one activity can occur at a time, program execution is necessarily nondeterministic.Code may execute in surprising orders — any order that is not explicitly ruled out is allowed (see §2.2.7). So you cannot always understand concurrent programs by sequentially reading through theircode. For example, without further precautions, a field set to one value in one line of code may have adifferent value (due to the actions of some other concurrent activity) by the time the next line of codeis executed. Dealing with this and other forms of interference often introduces the need for a bit morerigor and a more conservative outlook on design.1.2.3.2 Event-based programmingSome concurrent programming techniques have much in common with those in event frameworksemployed in GUI toolkits supported by java.awt and javax.swing , and in other languagessuch as Tcl/Tk and Visual Basic. In GUI frameworks, events such as mouse clicks are encapsulated asEvent objects that are placed in a single EventQueue . These events are then dispatched andprocessed one-by-one in a single event loop, which normally runs as a separate thread. As discussed in§ 4.1, this design can be extended to support additional concurrency by (among other tactics) creatingmultiple event loop threads, each concurrently processing events, or even dispatching each event in aseparate thread. Again, this opens up new design possibilities, but also introduces new concerns aboutinterference and coordination among concurrent activities.1.2.3.3 Concurrent systems programmingObject-oriented concurrent programming differs from multithreaded systems programming inlanguages such as C mainly due to the encapsulation, modularity, extensibility, security, and safetyfeatures otherwise lacking in C. Additionally, concurrency support is built into the Java programminglanguage, rather than supplied by libraries. This eliminates the possibility of some common errors, andalso enables compilers to automatically and safely perform some optimizations that would need to beperformed manually in C.While concurrency support constructs in the Java programming language are generally similar to thosein the standard POSIX pthreads library and related packages typically used in C, there are someimportant differences, especially in the details of waiting and notification (see § 3.2.2). It is verypossible to use utility classes that act almost just like POSIX routines (see § 3.4.4). But it is oftenmore productive instead to make minor adjustments to exploit the versions that the language directlysupports.1.2.3.4 Other concurrent programming languagesEssentially all concurrent programming languages are, at some level, equivalent, if only in the sensethat all concurrent languages are widely believed not to have defined the right concurrency features.However, it is not all that hard to make programs in one language look almost equivalent to those inother languages or those using other constructs, by developing packages, classes, utilities, tools, andcoding conventions that mimic features built into others. In the course of this book, constructions areintroduced that provide the capabilities and programming styles of semaphore-based systems (§ 3.4.1),futures (§ 4.3.3), barrier-based parallelism (§ 4.4.3), CSP (§ 4.5.1) and others. It is a perfectly greatidea to write programs using only one of these styles, if this suits your needs. However, manyconcurrent designs, patterns, frameworks, and systems have eclectic heritages and steal good ideasfrom anywhere they can.1.2.4 Object Models and MappingsConceptions of objects often differ across sequential versus concurrent OO programming, and evenacross different styles of concurrent OO programming. Contemplation of the underlying object modelsand mappings can reveal the nature of differences among programming styles hinted at in the previoussection.Most people like to think of software objects as models of real objects, represented with somearbitrary degree of precision. The notion of "real" is of course in the eye of the beholder, and oftenincludes artifices that make sense only within the realm of computation.For a simple example, consider the skeletal UML class diagram and code sketch for classWaterTank :class WaterTank {final float capacity;float currentVolume = 0.0f;WaterTank overflow;// Code sketchWaterTank(float cap) { capacity = cap; ... }void addWater(float amount) throws OverflowException;void removeWater(float amount) throws UnderflowException;}The intent here is to represent, or simulate, a water tank with:•Attributes such as capacity and currentVolume , that are represented as fields ofWaterTank objects. We can choose only those attributes that we happen to care about insome set of usage contexts. For example, while all real water tanks have locations, shapes,colors, and so on, this class only deals with volumes.•••••Invariant state constraints, such as the facts that the currentVolume always remainsbetween zero and capacity , and that capacity is nonnegative and never changes afterconstruction.Operations describing behaviors such as those to addWater and removeWater . Thischoice of operations again reflects some implicit design decisions concerning accuracy,granularity and precision. For example, we could have chosen to model water tanks at thelevel of valves and switches, and could have modeled each water molecule as an object thatchanges location as the result of the associated operations.Connections (and potential connections) to other objects with which objects communicate,such as pipes or other tanks. For example, excess water encountered in an addWateroperation could be shunted to an overflow tank that is known by each tank.Preconditions and postconditions on the effects of operations, such as rules stating that it isimpossible to remove water from an empty tank, or to add water to a full tank that is notequipped with an available overflow tank.Protocols constraining when and how messages (operation requests) are processed. Forexample, we may impose a rule that at most one addWater or removeWater messageis processed at any given time or, alternatively, a rule stating that removeWater messagesare allowed in the midst of addWater operations.1.2.4.1 Object modelsThe WaterTank class uses objects to model reality. Object models provide rules and frameworksfor defining objects more generally, covering:Statics. The structure of each object is described (normally via a class) in terms of internal attributes(state), connections to other objects, local (internal) methods, and methods or ports for acceptingmessages from other objects.Encapsulation. Objects have membranes separating their insides and outsides. Internal state can bedirectly modified only by the object itself. (We ignore for now language features that allow this rule tobe broken.)Communication. Objects communicate only via message passing. Objects issue messages that triggeractions in other objects. The forms of these messages may range from simple procedural calls to thosetransported via arbitrary communication protocols.Identity. New objects can be constructed at any time (subject to system resource constraints) by anyobject (subject to access control). Once constructed, each object maintains a unique identity thatpersists over its lifetime.Connections. One object can send messages to others if it knows their identities. Some models rely onchannel identities rather than or in addition to object identities. Abstractly, a channel is a vehicle forpassing messages. Two objects that share a channel may pass messages through that channel withoutknowing each other's identities. Typical OO models and languages rely on object-based primitives fordirect method invocations, channel-based abstractions for IO and communication across wires, andconstructions such as event channels that may be viewed from either perspective.Computation. Objects may perform four basic kinds of computation:••••Accept a message.Update internal state.Send a message.Create a new object.This abstract characterization can be interpreted and refined in several ways. For example, one way toimplement a WaterTank object is to build a tiny special-purpose hardware device that onlymaintains the indicated states, instructions, and connections. But since this is not a book on hardwaredesign, we'll ignore such options and restrict attention to software-based alternatives.1.2.4.2 Sequential mappingsThe features of an ordinary general-purpose computer (a CPU, a bus, some memory, and some IOports) can be exploited so that this computer can pretend it is any object, for example aWaterTank . This can be arranged by loading a description of WaterTanks (via a .classfile) into a JVM. The JVM can then construct a passive representation of an instance and theninterpret the associated operations. This mapping strategy also applies at the level of the CPU whenoperations are compiled into native code rather than interpreted as bytecodes. It also extends toprograms involving many objects of different classes, each loaded and instantiated as needed, byhaving the JVM at all times record the identity (" this ") of the object it is currently simulating.In other words, the JVM is itself an object, although a very special one that can pretend it is any otherobject. (More formally, it serves as a Universal Turing Machine.) While similar remarks hold for themappings used in most other languages, Class objects and reflection make it simpler to characterizereflective objects that treat other objects as data.In a purely sequential environment, this is the end of the story. But before moving on, consider therestrictions on the generic object model imposed by this mapping. On a sequential JVM, it would beimpossible to directly simulate multiple concurrent interacting waterTank objects. And because allmessage-passing is performed via sequential procedural invocation, there is no need for rules aboutwhether multiple messages may be processed concurrently — they never are anyway. Thus, sequentialOO processing limits the kinds of high-level design concerns you are allowed to express.1.2.4.3 Active objectsAt the other end of the mapping spectrum are active object models (also known as actor models), inwhich every object is autonomous. Each may be as powerful as a sequential JVM. Internal class andobject representations may take the same forms as those used in passive frameworks. For examplehere, each waterTank could be mapped to a separate active object by loading in a description to aseparate JVM, and then forever allowing it to simulate the defined actions.Active object models form a common high-level view of objects in distributed object-orientedsystems: Different objects may reside on different machines, so the location and administrativedomain of an object are often important programming issues. All message passing is arranged viaremote communication (for example via sockets) that may obey any of a number of protocols,including oneway messaging (i.e., messages that do not intrinsically require replies), multicasts(simultaneously sending the same message to multiple recipients), and procedure-style request-replyexchanges.This model also serves as an object-oriented view of most operating-system-level processes, each ofwhich is as independent of, and shares as few resources with, other processes as possible (see § 1.2.2).1.2.4.4 Mixed modelsThe models and mappings underlying concurrency support in the Java programming language fallbetween the two extremes of passive and active models. A full JVM may be composed of multiplethreads, each of which acts in about the same way as a single sequential JVM. However, unlike pureactive objects, all of these threads may share access to the same set of underlying passiverepresentations.This style of mapping can simulate each of the extremes. Purely passive sequential models can beprogrammed using only one thread. Purely active models can be programmed by creating as manythreads as there are active objects, avoiding situations in which more than one thread can access agiven passive representation (see § 2.3), and using constructs that provide the same semantic effects asremote message passing (see § 4.1). However, most concurrent programs occupy a middle ground.Thread-based concurrent OO models conceptually separate "normal" passive objects from activeobjects (threads). But the passive objects typically display thread-awareness not seen in sequentialprogramming, for example by protecting themselves via locks. And the active objects are simpler thanthose seen in actor models, supporting only a few operations (such as run ). But the design ofconcurrent OO systems can be approached from either of these two directions — by smartening uppassive objects to live in a multithreaded environment, or by dumbing down active objects so they canbe expressed more easily using thread constructs.One reason for supporting this kind of object model is that it maps in a straightforward and efficientway to stock uniprocessor and shared-memory multiprocessor (SMP) hardware and operating systems:Threads can be bound to CPUs when possible and desirable, and otherwise time-shared; local threadstate maps to registers and CPUs; and shared object representations map to shared main memory.The degree of programmer control over these mappings is one distinction separating many forms ofparallel programming from concurrent programming. Classic parallel programming involves explicitdesign steps to map threads, tasks, or processes, as well as data, to physical processors and their localstores. Concurrent programming leaves most mapping decisions to the JVM (and the underlying OS).This enhances portability, at the expense of needing to accommodate differences in the quality ofimplementation of these mappings.Time-sharing is accomplished by applying the same kind of mapping strategy to threads themselves:Representations of Thread objects are maintained, and a scheduler arranges context switches inwhich the CPU state corresponding to one thread is saved in its associated storage representation andrestored from another.Several further refinements and extensions of such models and mappings are possible. For example,persistent object applications and systems typically rely on databases to maintain objectrepresentations rather than directly relying on main memory.1.2.5 Further ReadingsThere is a substantial literature on concurrency, ranging from works on theoretical foundations topractical guides for using particular concurrent applications.1.2.5.1 Concurrent programmingTextbooks presenting details on additional concurrent algorithms, programming strategies, and formalmethods not covered in this book include:Andrews, Gregory. Foundations of Multithreaded, Parallel, and Distributed Programming, Addison-Wesley, 1999. This is an expanded update of Andrews's Concurrent Programming: Principles andPractice, Benjamin Cummings, 1991.Ben-Ari, M. Principles of Concurrent and Distributed Programming, Prentice Hall, 1990.Bernstein, Arthur, and Philip Lewis. Concurrency in Programming and Database Systems, Jones andBartlett, 1993.Burns, Alan, and Geoff Davis. Concurrent Programming, Addison-Wesley, 1993.Bustard, David, John Elder, and Jim Welsh. Concurrent Program Structures, Prentice Hall, 1988.Schneider, Fred. On Concurrent Programming, Springer-Verlag, 1997.The concurrency constructs found in the Java programming language have their roots in similarconstructs first described by C. A. R. Hoare and Per Brinch Hansen. See papers by them and others infollowing collections:Dahl, Ole-Johan, Edsger Dijkstra, and C. A. R. Hoare (eds.). Structured Programming, AcademicPress, 1972.Gehani, Narain, and Andrew McGettrick (eds.). Concurrent Programming, Addison-Wesley, 1988.A comparative survey of how some of these constructs are defined and supported across differentlanguages and systems may be found in:Buhr, Peter, Michel Fortier, and Michael Coffin. "Monitor Classification", ACM Computing Surveys,1995.Concurrent object-oriented, object-based or module-based languages include Simula, Modula-3,Mesa, Ada, Orca, Sather, and Euclid. More information on these languages can be found in theirmanuals, as well as in:Birtwistle, Graham, Ole-Johan Dahl, Bjorn Myhrtag, and Kristen Nygaard. Simula Begin, AuerbachPress, 1973.Burns, Alan, and Andrew Wellings. Concurrency in Ada, Cambridge University Press, 1995.Holt, R. C. Concurrent Euclid, the Unix System, and Tunis, Addison-Wesley, 1983.Nelson, Greg (ed.). Systems Programming with Modula-3, Prentice Hall, 1991.Stoutamire, David, and Stephen Omohundro. The Sather/pSather 1.1 Specification, Technical Report,University of California at Berkeley, 1996.Books taking different approaches to concurrency in the Java programming language include:Hartley, Stephen. Concurrent Programming using Java, Oxford University Press, 1998. This takes anoperating systems approach to concurrency.Holub, Allen. Taming Java Threads, Apress, 1999. This collects the author's columns on threads inthe JavaWorld online magazine.Lewis, Bil. Multithreaded Programming in Java, Prentice Hall, 1999. This presents a somewhatlighter treatment of several topics discussed in this book, and provides closer tie-ins with POSIXthreads.Magee, Jeff, and Jeff Kramer. Concurrency: State Models and Java Programs, Wiley, 1999. Thisprovides a stronger emphasis on modeling and analysis.Most books, articles, and manuals on systems programming using threads concentrate on the details ofthose on particular operating systems or thread packages. See:Butenhof, David. Programming with POSIX Threads, Addison-Wesley, 1997. This provides the mostcomplete discussions of the POSIX thread library and how to use it.Lewis, Bil, and Daniel Berg. Multithreaded Programming with Pthreads, Prentice Hall, 1998.Norton, Scott, and Mark Dipasquale. Thread Time, Prentice Hall, 1997.Most texts on operating systems and systems programming describe the design and construction ofunderlying support mechanisms for language-level thread and synchronization constructs. See, forexample:Hanson, David. C Interfaces and Implementations, Addison-Wesley, 1996.Silberschatz, Avi and Peter Galvin. Operating Systems Concepts, Addison-Wesley, 1994.Tanenbaum, Andrew. Modern Operating Systems, Prentice Hall, 1992.1.2.5.2 ModelsGiven the diverse forms of concurrency seen in software, it's not surprising that there have been alarge number of approaches to the basic theory of concurrency. Theoretical accounts of processcalculi, event structures, linear logic, Petri nets, and temporal logic have potential relevance to theunderstanding of concurrent OO systems. For overviews of most approaches to the theory ofconcurrency, see:van Leeuwen, Jan (ed.). Handbook of Theoretical Computer Science, Volume B, MIT Press, 1990.An eclectic (and still fresh-sounding) presentation of models, associated programming techniques, anddesign patterns, illustrated using diverse languages and systems, is:Filman, Robert, and Daniel Friedman. Coordinated Computing. McGraw-Hill, 1984.There are several experimental concurrent OO languages based on active objects, most notably thefamily of Actor languages. See:Agha, Gul. ACTORS: A Model of Concurrent Computation in Distributed Systems, MIT Press, 1986.A more extensive survey of object-oriented approaches to concurrency can be found in:Briot, Jean-Pierre, Rachid Guerraoui, and Klaus-Peter Lohr. "Concurrency and Distribution in Object-Oriented Programming", Computing Surveys, 1998.Research papers on object-oriented models, systems and languages can be found in proceedings of OOconferences including ECOOP, OOPSLA, COOTS, TOOLS, and ISCOPE, as well as concurrencyconferences such as CONCUR and journals such as IEEE Concurrency. Also, the followingcollections contain chapters surveying many approaches and issues:Agha, Gul, Peter Wegner, and Aki Yonezawa (eds.). Research Directions in Concurrent Object-Oriented Programming, MIT Press, 1993.Briot, Jean-Pierre, Jean-Marc Geib and Akinori Yonezawa (eds.). Object Based Parallel andDistributed Computing, LNCS 1107, Springer Verlag, 1996.Guerraoui, Rachid, Oscar Nierstrasz, and Michel Riveill (eds.). Object-Based Distributed Processing,LNCS 791, Springer-Verlag, 1993.Nierstrasz, Oscar, and Dennis Tsichritzis (eds.). Object-Oriented Software Composition, Prentice Hall,1995.1.2.5.3 Distributed systemsTexts on distributed algorithms, protocols, and system design include:Barbosa, Valmir. An Introduction to Distributed Algorithms. Morgan Kaufman, 1996.Birman, Kenneth and Robbert von Renesse. Reliable Distributed Computing with the Isis Toolkit,IEEE Press, 1994.Coulouris, George, Jean Dollimore, and Tim Kindberg. Distributed Systems: Concepts and Design,Addison-Wesley, 1994.Lynch, Nancy. Distributed Algorithms, Morgan Kaufman, 1996.Mullender, Sape (ed.), Distributed Systems, Addison-Wesley, 1993.Raynal, Michel. Distributed Algorithms and Protocols, Wiley, 1988.For details about distributed programming using RMI, see:Arnold, Ken, Bryan O'Sullivan, Robert Scheifler, Jim Waldo, and Ann Wollrath. The JiniTMSpecification, Addison-Wesley, 1999.1.2.5.4 Real-time programmingMost texts on real-time programming focus on hard real-time systems in which, for the sake ofcorrectness, certain activities must be performed within certain time constraints. The Javaprogramming language does not supply primitives that provide such guarantees, so this book does notcover deadline scheduling, priority assignment algorithms, and related concerns. Sources on real-timedesign include:Burns, Alan, and Andy Wellings. Real-Time Systems and Programming Languages, Addison-Wesley,1997. This book illustrates real-time programming in Ada, occam, and C, and includes arecommended account of priority inversion problems and solutions.Gomaa, Hassan. Software Design Methods for Concurrent and Real-Time Systems, Addison-Wesley,1993.Levi, Shem-Tov and Ashok Agrawala. Real-Time System Design, McGraw-Hill, 1990.Selic, Bran, Garth Gullekson, and Paul Ward. Real-Time Object-Oriented Modeling, Wiley, 1995.1.3 Design ForcesThis section surveys design concerns that arise in concurrent software development, but play at bestminor roles in sequential programming. Most presentations of constructions and design patterns laterin this book include descriptions of how they resolve applicable forces discussed here (as well asothers that are less directly tied to concurrency, such as accuracy, testability, and so on).One can take two complementary views of any OO system, object-centric and activity-centric:Under an object-centric view, a system is a collection of interconnected objects. But it is a structuredcollection, not a random object soup. Objects cluster together in groups, for example the group ofobjects comprising a ParticleApplet , thus forming larger components and subsystems.Under an activity-centric view, a system is a collection of possibly concurrent activities. At the mostfine-grained level, these are just individual message sends (normally, method invocations). They inturn organize themselves into sets of call-chains, event sequences, tasks, sessions, transactions, andthreads. One logical activity (such as running the ParticleApplet ) may involve many threads.At a higher level, some of these activities represent system-wide use cases.Neither view alone provides a complete picture of a system, since a given object may be involved inmultiple activities, and conversely a given activity may span multiple objects. However, these twoviews give rise to two complementary sets of correctness concerns, one object-centric and the otheractivity-centric:Safety. Nothing bad ever happens to an object.Liveness. Something eventually happens within an activity.Safety failures lead to unintended behavior at run time — things just start going wrong. Livenessfailures lead to no behavior — things just stop running. Sadly enough, some of the easiest things youcan do to improve liveness properties can destroy safety properties, and vice versa. Getting them bothright can be a challenge.You have to balance the relative effects of different kinds of failure in your own programs. But it is astandard engineering (not just software engineering) practice to place primary design emphasis onsafety. The more your code actually matters, the better it is to ensure that a program does nothing at allrather than something that leads to random, even dangerous behavior.On the other hand, most of the time spent tuning concurrent designs in practice usually surroundsliveness and liveness-related efficiency issues. And there are sometimes good, conscientious reasonsfor selectively sacrificing safety for liveness. For example, it may be acceptable for visual displays totransiently show utter nonsense due to uncoordinated concurrent execution— drawing stray pixels,incorrect progress indicators, or images that bear no relation to their intended forms — if you areconfident that this state of affairs will soon be corrected.Safety and liveness issues may be further extended to encompass two categories of quality concerns,one mainly object-centric and the other mainly activity-centric, that are also sometimes in directopposition:Reusability. The utility of objects and classes across multiple contexts.Performance. The extent to which activities execute soon and quickly.The remainder of this section looks more closely at safety, liveness, performance, and reusability inconcurrent programs. It presents basic terms and definitions, along with brief introductions to coreissues and tactics that are revisited and amplified throughout the course of this book.1.3.1 SafetySafe concurrent programming practices are generalizations of safe and secure sequential programmingpractices. Safety in concurrent designs adds a temporal dimension to common notions of type safety.A type-checked program might not be correct, but at least it doesn't do dangerous things likemisinterpret the bits representing a float as if they were an object reference. Similarly, a safeconcurrent design might not have the intended effect, but at least it never encounters errors due tocorruption of representations by contending threads.One practical difference between type safety and multithreaded safety is that most type-safety matterscan be checked automatically by compilers. A program that fails to pass compile-time checks cannoteven be run. Most multithreaded safety matters, however, cannot be checked automatically, and somust rely on programmer discipline. Methods for proving designs to be safe fall outside the scope ofthis book (see the Further Readings). The techniques for ensuring safety described here rely on carefulengineering practices (including several with roots in formalisms) rather than formal methodsthemselves.Multithreaded safety also adds a temporal dimension to design and programming techniquessurrounding security. Secure programming practices disable access to certain operations on objectsand resources from certain callers, applications, or principals. Concurrency control introducestransient disabling of access based on consideration of the actions currently being performed by otherthreads.The main goal in safety preservation is ensuring that all objects in a system maintain consistent states:states in which all fields, and all fields of other objects on which they depend, possess legal,meaningful values. It sometimes takes hard work to nail down exactly what "legal" and "meaningful"mean in a particular class. One path is first to establish conceptual-level invariants, for example therule that water tank volumes must always be between zero and their capacities. These can usually berecast in terms of relationships among field values in the associated concrete classes.An object is consistent if all fields obey their invariants. Every public method in every class shouldlead an object from one consistent state to another. Safe objects may occasionally enter transientlyinconsistent states in the midst of methods, but they never attempt to initiate new actions when theyare in inconsistent states. If every object is designed to perform actions only when it is logically ableto do so, and if all the mechanics are properly implemented, then you can be sure that an applicationusing these objects will not encounter any errors due to object inconsistency.One reason for being more careful about invariants in concurrent programs is that it is much easier tobreak them inadvertently than in most sequential programs. The need for protection against the effectsof inconsistency arises even in sequential contexts, for example when processing exceptions andcallbacks, and when making self-calls from one method in a class to another. However, these issuesbecome much more central in concurrent programs. As discussed in § 2.2, the most common ways ofensuring consistency employ exclusion techniques to guarantee the atomicity of public actions — thateach action runs to completion without interference from others. Without such protection,inconsistencies in concurrent programs may stem from race conditions producing storage conflicts atthe level of raw memory cells:Read/Write conflicts. One thread reads a value of a field while another writes to it. The value seen bythe reading thread is difficult to predict — it depends on which thread won the "race" to access thefield first. As discussed in § 2.2, the value read need not even be a value that was ever written by anythread.Write/Write conflicts. Two threads both try to write to the same field. The value seen upon the nextread is again difficult or impossible to predict.It is equally impossible to predict the consequences of actions that are attempted when objects are ininconsistent states. Examples include:••••A graphical representation (for example of a Particle ) is displayed at a location that theobject never actually occupied.A bank account balance is incorrect after an attempt to withdraw money in the midst of anautomatic transfer.Following the next pointer of a linked list leads to a node that is not even in the list.Two concurrent sensor updates cause a real-time controller to perform an incorrect effectoraction.1.3.1.1 Attributes and constraintsSafe programming techniques rely on clear understanding of required properties and constraintssurrounding object representations. Developers who are not aware of these properties rarely do a verygood job at preserving them. Many formalisms are available for precisely stating predicates describingrequirements (as discussed in most of the texts on concurrent design methods listed in the FurtherReadings). These can be very useful, but here we will maintain sufficient precision withoutintroducing formalisms.Consistency requirements sometimes stem from definitions of high-level conceptual attributes madeduring the initial design of classes. These constraints typically hold regardless of how the attributesare concretely represented and accessed via fields and methods. This was seen for example in thedevelopment of the WaterTank and Particle classes earlier in this chapter. Here are someother examples, most of which are revisited in more detail in the course of this book:••••••••••A BankAccount has a balance that is equal to the sum of all deposits and interest minuswithdrawals and service charges.A Packet has a destination that must be a legal IP address.A Counter has a nonnegative integral count value.An Invoice has a paymentDue that reflects the rules of a payment system.A Thermostat has a temperature equal to the most recent sensor reading.A Shape has a location, dimension, and color that all obey a set of stylistic guidelines for agiven GUI toolkit.A BoundedBuffer has an elementCount that is always between zero and a capacity.A Stack has a size and, when not empty, a top element.A Window has a propertySet maintaining current mappings of fonts, background color, etc.An Interval has a startDate that is no later than its endDate.While such attributes essentially always somehow map to object fields, the correspondences need notbe direct. For example, the top of a Stack is typically not held in a variable, but instead in an arrayelement or linked list node. Also, some attributes can be computed ("derived") via others; for example,the boolean attribute overdrawn of a BankAccount might be computed by comparing thebalance to zero.1.3.1.2 Representational constraintsFurther constraints and invariants typically emerge as additional implementation decisions are madefor a given class. Fields declared for the sake of maintaining a particular data structure, for improvingperformance, or for other internal bookkeeping purposes often need to respect sets of invariants.Broad categories of fields and constraints include the following:Direct value representations. Fields needed to implement concrete attributes. For example, aBuffer might have a putIndex field holding the array index position to use when inserting thenext added element.Cached value representations. Fields used to eliminate or minimize the need for computations ormethod invocations. For example, rather than computing the value of overdrawn every time it isneeded, a BankAccount might maintain an overdrawn field that is true if and only if thecurrent balance is less than zero.Logical state representations. Reflections of logical control state. For example, aBankCardReader might have a card field representing the card currently being read, and avalidPIN field recording whether the PIN access code was verified. The CardReadervalidPIN field may be used to track the point in a protocol in which the card has been successfullyread in and validated. Some state representations take the form of role variables, controlling responsesto all of a related set of methods (sometimes those declared in a single interface). For example, agame-playing object may alternate between active and passive roles depending on the value of awhoseTurn field.Execution state variables. Fields recording the fine-grained dynamic state of an object, for example,the fact that a certain operation is in progress. Execution state variables can represent the fact that agiven message has been received, that the corresponding action has been initiated, that the action hasterminated, and that a reply to the message has been issued. An execution state variable is often anenumerated type with values having names ending in -ing; for example, CONNECTING ,UPDATING , WAITING . Another common kind of execution state variable is a counter that recordsthe number of entries or exits of some method. As discussed in § 3.2, objects in concurrent programstend to require more such variables than do those in sequential contexts, to help track and manage theprogress of methods that proceed asynchronously.History variables. Representations of the history or past states of an object. The most extensiverepresentation is a history log, recording all messages ever received and sent, along with allcorresponding internal actions and state changes that have been initiated and completed. Lessextensive subsets are much more common. For example, a BankAccount class could maintain alastSavedBalance field that holds the last checkpointed value and is used when revertingcancelled transactions.Version tracking variables. An integer, time-stamp, object reference, signature code, or otherrepresentation indicating the time, ordering, or nature of the last state change made by an object. Forexample, a Thermostat may increment a readingNumber or record thelastReadingTime when updating its temperature .References to acquaintances. Fields pointing to other objects that the host interacts with, but that donot themselves comprise the host's logical state: For example, a callback target of anEventDispatcher , or a requestHandler delegated to by a WebServer .References to representation objects. Attributes that are conceptually held by a host object but areactually managed by other helper objects. Reference fields may point to other objects that assist inrepresenting the state of the host object. So, the logical state of any object may include the states ofobjects that it holds references to. Additionally, the reference fields themselves form part of theconcrete state of the host object (see § 2.3.3). Any attempts to ensure safety must take theserelationships into account. For example:••••A Stack might have a headOfLinkedList field recording the first node of a listrepresenting the stack.A Person object might maintain a homePageURL field maintained as ajava.net.URL object.The balance of a BankAccount might be maintained in a central repository, in which casethe BankAccount would instead maintain a a field referring to the repository (in order toask it about the current balance). In this case, some of the logical state of theBankAccount is actually managed by the repository.An object might know of its attributes only via access to property lists maintained by otherobjects.1.3.2 LivenessOne way to build a guaranteed safe system is to arrange that no objects ever execute any methods, andthus can never encounter any conflicts. But this is not a very productive form of programming. Safetyconcerns must be balanced by liveness [1] concerns.[1]Some "liveness" properties may be construed as safety properties of sets of thread objects. For example,deadlock-freedom may be defined as avoiding the bad state in which a set of threads endlessly wait for eachother.In live systems, every activity eventually progresses toward completion; every invoked methodeventually executes. But an activity may (perhaps only transiently) fail to make progress for any ofseveral interrelated reasons:Locking. A synchronized method blocks one thread because another thread holds the lock.Waiting. A method blocks (via Object.wait or its derivatives) waiting for an event, message, orcondition that has yet to be produced within another thread.Input. An IO-based method waits for input that has not yet arrived from another process or device.CPU contention. A thread fails to run even though it is in a runnable state because other threads, oreven completely separate programs running on the same computer, are occupying CPU or othercomputational resources.Failure. A method running in a thread encounters a premature exception, error, or fault.Momentary blockages in thread progress are usually acceptable. In fact, frequent short-lived blockingis intrinsic to many styles of concurrent programming.The lifecycle of a typical thread may include a number of transient blockages and reschedulings:However, permanent or unbounded lack of progress is usually a serious problem. Examples ofpotentially permanent liveness failures described in more depth elsewhere in this book include:Deadlock. Circular dependencies among locks. In the most common case, thread A holds a lock forobject X and then tries to acquire the lock for object Y . Simultaneously, thread B already holds thelock for object Y and tries to acquire the lock for object X . Neither thread can ever make furtherprogress (see § 2.2.5).Missed signals. A thread remains dormant because it started waiting after a notification to wake it upwas produced (see § 3.2.2).Nested monitor lockouts. A waiting thread holds a lock that would be needed by any other threadattempting to wake it up (see § 3.3.4).Livelock. A continuously retried action continuously fails (see § 2.4.4.2).Starvation. The JVM/OS fails ever to allocate CPU time to a thread. This may be due to schedulingpolicies or even hostile denial-of-service attacks on the host computer (see § 1.1.2.3 and § 3.4.1.5).Resource exhaustion. A group of threads together hold all of a finite number of resources. One ofthem needs additional resources, but no other thread will give one up (see § 4.5.1).Distributed failure. A remote machine connected by a socket serving as an InputStream crashesor becomes inaccessible (see § 3.1).1.3.3 PerformancePerformance-based forces extend liveness concerns. In addition to demanding that every invokedmethod eventually execute, performance goals require them to execute soon and quickly. While we donot consider in this book hard real-time systems in which failure to execute within a given timeinterval can lead to catastrophic system errors, nearly all concurrent programs have implicit or explicitperformance goals.Meaningful performance requirements are stated in terms of measurable qualities, including thefollowing metrics. Goals may be expressed for central tendencies (e.g., mean, median) ofmeasurements, as well as their variability (e.g., range, standard deviation).Throughput. The number of operations performed per unit time. The operations of interest may rangefrom individual methods to entire program runs. Most often, throughput is reported not as a rate, butinstead as the time taken to perform one operation.Latency. The time elapsed between issuing a message (via for example a mouse click, methodinvocation, or incoming socket connection) and servicing it. In contexts where operations are uniform,single-threaded, and "continuously" requested, latency is just the inverse of throughput. But moretypically, the latencies of interest reflect response times — the delays until something happens, notnecessarily full completion of a method or service.Capacity. The number of simultaneous activities that can be supported for a given target minimumthroughput or maximum latency. Especially in networking applications, this can serve as a usefulindicator of overall availability, since it reflects the number of clients that can be serviced withoutdropping connections due to time-outs or network queue overflows.Efficiency. Throughput divided by the amount of computational resources (for example CPUs,memory, and IO devices) needed to obtain this throughput.Scalability. The rate at which latency or throughput improves when resources (again, usually CPUs,memory, or devices) are added to a system. Related measures include utilization — the percentage ofavailable resources that are applied to a task of interest.Degradation. The rate at which latency or throughput worsens as more clients, activities, or operationsare added without adding resources.Most multithreaded designs implicitly accept a small trade-off of poorer computational efficiency toobtain better latency and scalability. Concurrency support introduces the following kinds of overheadand contention that can slow down programs:Locks. A synchronized method typically requires greater call overhead than an unsynchronizedmethod. Also, methods that frequently block waiting for locks (or for any other reason) proceed moreslowly than those that do not.Monitors. Object.wait , Object.notify , Object.notifyAll , and the methodsderived from them (such as Thread.join ) can be more expensive than other basic JVM run-timesupport operations.Threads. Creating and starting a Thread is typically more expensive than creating an ordinaryobject and invoking a method on it.Context-switching. The mapping of threads to CPUs encounters context-switch overhead when aJVM/OS saves the CPU state associated with one thread, selects another thread to run, and loads theassociated CPU state.Scheduling. Computations and underlying policies that select which eligible thread to run addoverhead. These may further interact with other system chores such as processing asynchronousevents and garbage collection.Locality. On multiprocessors, when multiple threads running on different CPUs share access to thesame objects, cache consistency hardware and low-level system software must communicate theassociated values across processors.Algorithmics. Some efficient sequential algorithms do not apply in concurrent settings. For example,some data structures that rely on caching work only if it is known that exactly one thread performs alloperations. However, there are also efficient alternative concurrent algorithms for many problems,including those that open up the possibility of further speedups via parallelism.The overheads associated with concurrency constructs steadily decrease as JVMs improve. Forexample, as of this writing, the overhead cost of a single uncontended synchronized method callwith a no-op body on recent JVMs is on the order of a few unsynchronized no-op calls. (Sincedifferent kinds of calls, for example of static versus instance methods, can take different times andinteract with other optimizations, it is not worth making this more precise.)However, these overheads tend to degrade nonlinearly. For example, using one lock that is frequentlycontended by ten threads is likely to lead to much poorer overall performance than having each threadpass through ten uncontended locks. Also, because concurrency support entails underlying systemresource management that is often optimized for given target loads, performance can dramaticallydegrade when too many locks, monitor operations, or threads are used.Subsequent chapters include discussions of minimizing use of the associated constructs whennecessary. However, bear in mind that performance problems of any kind can be remedied only afterthey are measured and isolated. Without empirical evidence, most guesses at the nature and source ofperformance problems are wrong. The most useful measurements are comparative, showingdifferences or trends under different designs, loads, or configurations.1.3.4 ReusabilityA class or object is reusable to the extent that it can be readily employed across different contexts,either as a black-box component or as the basis of white-box extension via subclassing and relatedtechniques.The interplay between safety and liveness concerns can significantly impact reusability. It is usuallypossible to design components to be safe across all possible contexts. For example, asynchronized method that refuses to commence until it possesses the synchronization lock willdo this no matter how it is used. But in some of these contexts, programs using this safe componentmight encounter liveness failures (for example, deadlock). Conversely, the functionality surrounding acomponent using only unsynchronized methods will always be live (at least with respect to locking),but may encounter safety violations when multiple concurrent executions are allowed to occur.The dualities of safety and liveness are reflected in some extreme views of design methodology. Sometop-down design strategies take a pure safety-first approach: Ensure that each class and object is safe,and then later try to improve liveness as an optimization measure. An opposite, bottom-up approach issometimes adopted in multithreaded systems programming: Ensure that code is live, and then try tolayer on safety features, for example by adding locks. Neither extreme is especially successful inpractice. It is too easy for top-down approaches to result in slow, deadlock-prone systems, and forbottom-up approaches to result in buggy code with unanticipated safety violations.It is usually more productive to proceed with the understanding that some very useful and efficientcomponents are not, and need not be, absolutely safe, and that useful services supported by somecomponents are not absolutely live. Instead, they operate correctly only within certain restricted usagecontexts. Therefore, establishing, documenting, advertising, and exploiting these contexts becomecentral issues in concurrent software design.There are two general approaches (and a range of intermediate choices) for dealing with contextdependence: (1) Minimize uncertainty by closing off parts of systems, and (2) Establish policies andprotocols that enable components to become or remain open. Many practical design efforts involvesome of each.1.3.4.1 Closed subsystemsAn ideally closed system is one for which you have perfect static (design time) knowledge about allpossible behaviors. This is typically both unattainable and undesirable. However, it is often stillpossible to close off parts of systems, in units ranging from individual classes to product-levelcomponents, by employing possibly extreme versions of OO encapsulation techniques:Restricted external communication. All interactions, both inward and outward, occur through anarrow interface. In the most tractable case, the subsystem is communication-closed, never internallyinvoking methods on objects outside the subsystem.Deterministic internal structure. The concrete nature (and ideally, number) of all objects and threadscomprising the subsystem are statically known. The final and private keywords can be used tohelp enforce this.In at least some such systems, you can in principle prove — informally, formally, or evenmechanically — that no internal safety or liveness violations are possible within a closed component.Or, if they are possible, you can continue to refine designs and implementations until a component isprovably correct. In the best cases, you can then apply this knowledge compositionally to analyzeother parts of a system that rely on this component.Perfect static information about objects, threads and interactions tells you not only what can happen,but also what cannot happen. For example, it may be the case that, even though twosynchronized methods in two objects contain calls to each other, they can never be accessedsimultaneously by different threads within the subsystem, so deadlock will never occur.Closure may also provide further opportunities for manual or compiler-driven optimization; forexample removing synchronization from methods that would ordinarily require it, or employing cleverspecial-purpose algorithms that can be made to apply only by eliminating the possibility of unwantedinteraction. Embedded systems are often composed as collections of closed modules, in part toimprove predictability, schedulability, and related performance analyses.While closed subsystems are tractable, they can also be brittle. When the constraints and assumptionsgoverning their internal structure change, these components are often thrown away and redevelopedfrom scratch.1.3.4.2 Open systemsAn ideal open system is infinitely extensible, across several dimensions. It may load unknown classesdynamically, allow subclasses to override just about any method, employ callbacks across objectswithin different subsystems, share common resources across threads, use reflection to discover andinvoke methods on otherwise unknown objects, and so on. Unbounded openness is usually asunattainable and undesirable as complete closedness: If everything can change, then you cannotprogram anything. But most systems require at least some of this flexibility.Full static analysis of open systems is not even possible since their nature and structure evolve acrosstime. Instead, open systems must rely on documented policies and protocols that every componentadheres to.The Internet is among the best examples of an open system. It continually evolves, for example byadding new hosts, web pages, and services, requiring only that all participants obey a few networkpolicies and protocols. As with other open systems, adherence to Internet policies and protocols issometimes difficult to enforce. However, JVMs themselves arrange that non-conforming componentscannot catastrophically damage system integrity.Policy-driven design can work well at the much smaller level of typical concurrent systems, wherepolicies and protocols often take the form of design rules. Examples of policy domains explored inmore depth in subsequent chapters include:Flow. For example, a rule of the form: Components of type A send messages to those of type B, butnever vice versa.Blocking. For example, a rule of the form: Methods of type A always immediately throw exceptions ifresource R is not available, rather than blocking until it is available.Notifications. For example, a rule of the form: Objects of type A always send change notifications totheir listeners whenever updated.Adoption of a relatively small number of policies simplifies design by minimizing the possibility ofinconsistent case-by-case decisions. Component authors, perhaps with the help of code reviews andtools, need check only that they are obeying the relevant design rules, and can otherwise focusattention on the tasks at hand. Developers can think locally while still acting globally.However, policy-driven design can become unmanageable when the number of policies grows largeand the programming obligations they induce overwhelm developers. When even simple methodssuch as updating an account balance or printing "Hello, world" require dozens of lines of awkward,error-prone code to conform to design policies, it is time to take some kind of remedial action:Simplify or reduce the number of policies; or create tools that help automate code generation and/orcheck for conformance; or create domain-specific languages that enforce a given discipline; or createframeworks and utility libraries that reduce the need for so much support code to be written insideeach method.Policy choices need not be in any sense "optimal" to be effective, but they must be conformed to andbelieved in, the more fervently the better. Such policy choices form the basis of several frameworksand design patterns described throughout this book. It is likely that some of them will be inapplicableto your software projects, and may even strike you as wrong-headed ("I'd never do that!") because theunderlying policies clash with others you have adopted.While inducing greater closedness allows you to optimize for performance, inducing greater opennessallows you to optimize for future change. These two kinds of tunings and refactorings are oftenequally challenging to carry out, but have opposite effects. Optimizing for performance usually entailsexploiting special cases by hard-wiring design decisions. Optimizing for extensibility entails removinghard-wired decisions and instead allowing them to vary, for example by encapsulating them asoverridable methods, supporting callback hooks, or abstracting functionality via interfaces thatcan be re-implemented in completely different ways by dynamically loaded components.Because concurrent programs tend to include more in-the-small policy decisions than sequential ones,and because they tend to rely more heavily on invariants surrounding particular representationchoices, classes involving concurrency constructs often turn out to require special attention in order tobe readily extensible. This phenomenon is widespread enough to have been given a name, theinheritance anomaly, and is described in more detail in § 3.3.3.3.However, some other programming techniques needlessly restrict extensibility for the sake ofperformance. These tactics become more questionable as compilers and JVMs improve. For example,dynamic compilation allows many extensible components to be treated as if they are closed at class-loading time, leading to optimizations and specializations that exploit particular run-time contextsmore effectively than any programmer could.1.3.4.3 DocumentationWhen compositionality is context-dependent, it is vital for intended usage contexts and restrictionssurrounding components to be well understood and well documented. When this information is notprovided, use, reuse, maintenance, testing, configuration management, system evolution, and relatedsoftware-engineering concerns are made much more difficult.Documentation may be used to improve understandability by any of several audiences — otherdevelopers using a class as a black-box component, subclass authors, developers who later maintain,modify, or repair code, testers and code reviewers, and system users. Across these audiences, the firstgoal is to eliminate the need for extensive documentation by minimizing the unexpected, and thusreducing conceptual complexity via:Standardization. Using common policies, protocols, and interfaces. For example:••••Adopting standard design patterns, and referencing books, web pages, or design documentsthat describe them more fully.Employing standard utility libraries and frameworks.Using standard coding idioms and naming conventions.Clearing against standard review checklists that enumerate common errors.Clarity. Using the simplest, most self-evident code expressions. For example:•••Using exceptions to advertise checked conditions.Expressing internal restrictions via access qualifiers (such as private ).Adopting common default naming and signature conventions, for example that, unlessspecified otherwise, methods that can block declare that they throwInterruptedException .Auxiliary code. Supplying code that demonstrates intended usages. For example:•••Including sample or recommended usage examples.Providing code snippets that achieve non-obvious effects.Including methods designed to serve as self-tests.After eliminating the need to explain the obvious via documentation, more useful forms ofdocumentation can be used to clarify design decisions. The most critical details can be expressed in asystematic fashion, using semiformal annotations of the forms listed in the following table, which areused and further explained as needed throughout this book.PREPrecondition (not necessarily checked)./** PRE: Caller holds synch lock ...WHEN Guard condition (always checked)./** WHEN: not empty return oldest ...POST Postcondition (normally unchecked)./** POST: Resource r is released...OUT Guaranteed message send (for example a callback)./** OUT: c.process(buff) called after read...RELY Required (normally unchecked) property of other objects or methods./** RELY: Must be awakened by x.signal()...INV An object constraint true at the start and end of every public method./** INV:x,y are valid screen coordinates...INIT An object constraint that must hold upon construction./** INIT: bufferCapacity greater than zero...Additional, less structured documentation can be used to explain non-obvious constraints, contextuallimitations, assumptions, and design decisions that impact use in a concurrent environment. It isimpossible to provide a complete listing of constructions requiring this kind of documentation, buttypical cases include:••••High-level design information about state and method constraints.Known safety limitations due to lack of locking in situations that would require it.The fact that a method may indefinitely block waiting for a condition, event, or resource.Methods designed to be called only from other methods, perhaps those in other classes.This book, like most others, cannot serve as an especially good model for such documentationpractices since most of these matters are discussed in the text rather than as sample codedocumentation.1.3.5 Further ReadingsAccounts of high-level object-oriented software analysis and design that cover at least someconcurrency issues include:Atkinson, Colin. Object-Oriented Reuse, Concurrency and Distribution, Addison-Wesley, 1991.Booch, Grady. Object Oriented Analysis and Design, Benjamin Cummings, 1994.Buhr, Ray J. A., and Ronald Casselman. Use Case Maps for Object-Oriented Systems, Prentice Hall,1996. Buhr and Casselman generalize timethread diagrams similar to those used in this book to UseCase Maps.Cook, Steve, and John Daniels. Designing Object Systems: Object-Oriented Modelling With Syntropy,Prentice Hall, 1994.de Champeaux, Dennis, Doug Lea, and Penelope Faure. Object Oriented System Development,Addison-Wesley, 1993.D'Souza, Desmond, and Alan Wills. Objects, Components, and Frameworks with UML, Addison-Wesley, 1999.Reenskaug, Trygve. Working with Objects, Prentice Hall, 1995.Rumbaugh, James, Michael Blaha, William Premerlani, Frederick Eddy, and William Lorensen.Object-Oriented Modeling and Design, Prentice Hall, 1991.Accounts of concurrent software specification, analysis, design, and verification include:Apt, Krzysztof and Ernst-Rudiger Olderog. Verification of Sequential and Concurrent Programs,Springer-Verlag, 1997.Carriero, Nicholas, and David Gelernter. How to Write Parallel Programs, MIT Press, 1990.Chandy, K. Mani, and Jayedev Misra. Parallel Program Design, Addison-Wesley, 1989.Jackson, Michael. Principles of Program Design, Academic Press, 1975.Jensen, Kurt, and Grzegorz Rozenberg (eds.). High-level Petri Nets: Theory and Application,Springer-Verlag, 1991.Lamport, Leslie. The Temporal Logic of Actions, SRC Research Report 79, Digital Equipment Corp,1991.Leveson, Nancy. Safeware: System Safety and Computers, Addison-Wesley, 1995.Manna, Zohar, and Amir Pneuli. The Temporal Logic of Reactive and Concurrent Systems, Springer-Verlag, 1991.Several specialized fields of software development rely heavily on concurrency. For example, manysimulation systems, telecommunications systems, and multimedia systems are highly multithreaded.While basic concurrency techniques form much of the basis for the design of such systems, this bookstops short of describing large-scale software architectures or specialized programming techniquesassociated with particular concurrent applications. See, for example:Fishwick, Paul. Simulation Model Design and Execution, Prentice Hall, 1995.Gibbs. Simon and Dennis Tsichritzis. Multimedia Programming, Addison-Wesley, 1994.Watkins, Kevin. Discrete Event Simulation in C, McGraw-Hill, 1993.Technical issues are only one aspect of concurrent software development, which also entails testing,organization, management, human factors, maintenance, tools, and engineering discipline. For anintroduction to basic engineering methods that can be applied to both everyday programming andlarger efforts, see:Humphrey, Watts. A Discipline for Software Engineering, Addison-Wesley, 1995.For a completely different perspective, see:Beck, Kent. Extreme Programming Explained: Embrace Change, Addison-Wesley, 1999.For more information about integrating performance concerns into software engineering efforts, seefor example:Jain, Raj. The Art of Computer Systems Performance Analysis, Wiley, 1991.Further distinctions between open and closed systems are discussed in:Wegner, Peter. "Why Interaction Is More Powerful Than Algorithms", Communications of the ACM,May 1997.1.4 Before/After PatternsMany concurrent designs are best described as patterns. A pattern encapsulates a successful andcommon design form, usually an object structure (also known as a micro-architecture) consisting ofone or more interfaces, classes, and/or objects that obey certain static and dynamic constraints andrelationships. Patterns are an ideal vehicle for characterizing designs and techniques that need not beimplemented in exactly the same way across different contexts, and thus cannot be usefullyencapsulated as reusable components. Reusable components and frameworks can play a central role inconcurrent software development. But much of concurrent OO programming entails the reuse,adaptation, and extension of recurring design forms and practices rather than of particular classes.Unlike those in the pioneering Design Patterns book by Gamma, Helm, Johnson, and Vlissides (seeFurther Readings in § 1.4.5), the patterns here are embedded within chapters discussing sets of relatedcontexts and software design principles that generate the main forces and constraints resolved in thepatterns. Many of these patterns are minor extensions or variants of other common OO layering andcomposition patterns. This section reviews some that are relied on heavily in subsequent chapters.Others are briefly described upon first encounter.1.4.1 LayeringLayering policy control over mechanism is a common structuring principle in systems of all sorts.Many OO layering and composition techniques rely on sandwiching some method call or body ofcode between a given before-action and an after-action. All forms of before/after control arrange thata given ground method, say method , is intercepted so as always to execute in the sequence:before(); method(); after();Or, to ensure that after-actions are performed even if the ground methods encounter exceptions:before();try { method(); }finally { after(); }Most examples in this book of course revolve around concurrency control. For example, asynchronized method acquires a lock before executing the code inside the method, and releasesthe lock after the method otherwise completes. But the basic ideas of before/after patterns can beillustrated in conjunction with another useful practice in OO programming, self-checking code: Thefields of any object should preserve all invariants whenever the object is not engaged in a publicmethod (see § 1.3.1). Invariants should be maintained even if these methods throw any of theirdeclared exceptions, unless these exceptions denote corruption or program failure (as may be true forRuntimeExceptions and Errors ).Conformance to computable invariants can be tested dynamically by creating classes that check themboth on entry to and on exit from every public method. Similar techniques apply to preconditions andpostconditions, but for simplicity, we'll illustrate only with invariants.As an example, suppose we'd like to create water tank classes that contain a self-check on theinvariant that the volume is always between zero and the capacity. To do this, we can define acheckVolumeInvariant method and use it as both the before and after operation. We can firstdefine an exception to throw if the invariant fails:class AssertionError extends java.lang.Error {public AssertionError() { super(); }public AssertionError(String message) { super(message); }}It can be disruptive to insert these checks manually inside each method. Instead, one of threebefore/after design patterns can be used to separate the checks from the ground methods: adapterclasses, subclass-based designs, and method adapter classes.In all cases, the best way to set this up is to define an interface describing the basic functionality.Interfaces are almost always necessary when you need to give yourself enough room to varyimplementations. Conversely, the lack of existing interfaces limits options when retrospectivelyapplying before/after patterns.Here is an interface describing a minor variant of the water tank class discussed in § 1.2.4.Before/after techniques may be applied to check invariants around the transferWater operation.interface Tank {float getCapacity();float getVolume();void transferWater(float amount)throws OverflowException, UnderflowException;}1.4.2 AdaptersWhen standardized interfaces are defined after designing one or more concrete classes, these classesoften do not quite implement the desired interface. For example, the names of their methods might beslightly different from those defined in the interface. If you cannot modify these concrete classes to fixsuch problems, you can still obtain the desired effect by building an Adapter class that translates awaythe incompatibilities.Say you have a Performer class that supports method perform and meets all the qualificationsof being usable as a Runnable except for the name mismatch. You can build an Adapter so it canbe used in a thread by some other class:class AdaptedPerformer implements Runnable {private final Performer adaptee;public AdaptedPerformer(Performer p) { adaptee = p; }public void run() { adaptee.perform(); }}This is only one of many common contexts for building Adapters, which also form the basis of severalrelated patterns presented in the Design Patterns book. A Proxy is an Adapter with the same interfaceas its delegate. A Composite maintains a collection of delegates, all supporting the same interface.In this delegation-based style of composition, the publicly accessible host class forwards all methodsto one or more delegates and relays back replies, perhaps doing some light translation (name changes,parameter coercion, result filtering, etc.) surrounding the delegate calls.Adapters can be used to provide before/after control merely by wrapping the delegated call within thecontrol actions. For example, assuming that we have an implementation class, say TankImpl , wecan write the following AdaptedTank class. This class can be used instead of the original in someapplication by replacing all occurrences of:new TankImpl(...)with:new AdaptedTank(new TankImpl(...)).class AdaptedTank implements Tank {protected final Tank delegate;public AdaptedTank(Tank t) { delegate = t; }public float getCapacity() { return delegate.getCapacity(); }public float getVolume() { return delegate.getVolume(); }protected void checkVolumeInvariant() throws AssertionError {float v = getVolume();float c = getCapacity();if ( !(v >= 0.0 && v <= c) )throw new AssertionError();}public synchronized void transferWater(float amount)throws OverflowException, UnderflowException {checkVolumeInvariant();// before-checktry {delegate.transferWater(amount);}// The re-throws will be postponed until after-check//in the finally clausecatch (OverflowException ex) { throw ex; }catch (UnderflowException ex) { throw ex; }}}finally {checkVolumeInvariant(); // after-check}1.4.3 SubclassingIn the normal case, when the intercepted before/after versions of methods have the same names andusages as base versions, subclassing can be a simpler alternative to the use of Adapters. Subclassversions of methods can interpose checks around calls to their super versions. For example:class SubclassedTank extends TankImpl {protected void checkVolumeInvariant() throws AssertionError {// ... identical to AdaptedTank version ...}public synchronized void transferWater(float amount)throws OverflowException, UnderflowException {// identical to AdaptedTank version except for inner call:// ...try {super.transferWater(amount);}}// ...}Some choices between subclassing and Adapters are just a matter of style. Others reflect differencesbetween delegation and inheritance.Adapters permit manipulations that escape subclassing rules. For example, you cannot override apublic method as private in a subclass in order to disable access, but you can simply fail torelay the method in an Adapter. Various forms of delegation can even be used as a substitute of sortsfor subclassing by having each "sub" class (Adapter) hold a reference to an instance of its "super"class (Adaptee), forwarding it all "inherited" operations. Such Adapters often have exactly the sameinterfaces as their delegates, in which case they are considered to be simple kinds of Proxies.Delegation can also be more flexible than subclassing, since "sub" objects can even change their"supers" (by reassigning the delegate reference) dynamically.Delegation can also be used to obtain the effects of multiple code inheritance. For example, if a classmust implement two unrelated interfaces, say Tank andjava.awt.event.ActionListener , and there are two available superclasses providing theneeded functionality, then one of these may be subclassed and the other delegated.However, delegation is less powerful than subclassing in some other respects. For example, self-callsin "superclasses" are not automatically bound to the versions of methods that have been "overridden"in delegation-based "subclasses". Adapter designs can also run into snags revolving around the factthat the Adaptee and Adapter objects are different objects. For example, object reference equality testsmust be performed more carefully since a test to see if you have the Adaptee version of an object failsif you have the Adapter version, and vice versa.Most of these problems can be avoided via the extreme measure of declaring all methods in Adapteeclasses to take an "apparent self" argument referring to the Adapter, and always using it instead ofthis , even for self-calls and identity checks (for example by overriding Object.equals ).Some people reserve the term delegation for objects and classes written in this style rather than theforwarding techniques that are almost always used to implement simple Adapters.1.4.3.1 Template methodsWhen you are pretty sure that you are going to rely on before/after control in a set of related classes,you can create an abstract class that automates the control sequence via an application of the TemplateMethod pattern (which has nothing to do with C++ generic types).An abstract class supporting template methods sets up a framework facilitating construction ofsubclasses that may override the ground-level actions, the before/after methods, or both:•••Basic ground-level action code is defined in non-public methods. (By convention, we namethe non-public version of any method method as doMethod .) Somewhat less flexibly,these methods need not be declared non-public if they are instead designed to be overriddenin subclasses.Before and after operations are also defined as non-public methods.Public methods invoke the ground methods between the before and after methods.Applying this to the Tank example leads to:abstract class AbstractTank implements Tank {protected void checkVolumeInvariant() throws AssertionError {// ... identical to AdaptedTank version ...}protected abstract void doTransferWater(float amount)throws OverflowException, UnderflowException;public synchronized void transferWater(float amount)throws OverflowException, UnderflowException {// identical to AdaptedTank version except for inner call:}// ...try {doTransferWater(amount);}// ...}class ConcreteTank extends AbstractTank {protected final float capacity;protected float volume;// ...public float getVolume() { return volume; }public float getCapacity() { return capacity; }protected void doTransferWater(float amount)throws OverflowException, UnderflowException {// ... implementation code ...}}1.4.4 Method AdaptersThe most flexible, but sometimes most awkward approach to before/after control is to define a classwhose entire purpose is to invoke a particular method on a particular object. In the Command Objectpattern and its many variants, instances of such classes can then be passed around, manipulated, andultimately executed (here, between before/after operations).Because of static typing rules, there must be a different kind of adapter class for each kind of methodbeing wrapped. To avoid proliferation of all these types, most applications restrict attention to onlyone or a small set of generic interfaces, each defining a single method. For example, the Threadclass and most other execution frameworks accept only instances of interface Runnable in order toinvoke their argumentless, resultless, exceptionless run methods. Similarly, in § 4.3.3.1, we defineand use interface Callable containing only a method call that accepts one Object argument,returns an Object , and may throw any Exception .In more focused applications, you can define any suitable single-method interface, instantiate animplementation — almost always via an anonymous inner class — and then pass it around for laterexecution. This technique is used extensively in the java.awt and javax.swing packages,which define interfaces and abstract classes associated with different kinds of event-handling methods.(In some other languages, function pointers and closures are defined and used to achieve some ofthese effects.)We can apply a version of before/after layering based on method adapters here by first defining aTankOp interface:interface TankOp {void op() throws OverflowException, UnderflowException;}In the following sample code, uncharacteristically, all uses of method adapters are local to theTankWithMethodAdapter class. Also, in this tiny example, there is only one wrappablemethod. However, the same scaffolding could be used for any other Tank methods defined in thisclass or its subclasses. Method adapters are much more common in applications where instances mustbe registered and/or passed around among multiple objects before being executed, which justifies theextra setup costs and programming obligations.class TankWithMethodAdapter {// ...protected void checkVolumeInvariant() throws AssertionError {// ... identical to AdaptedTank version ...}protected void runWithinBeforeAfterChecks(TankOp cmd)throws OverflowException, UnderflowException {// identical to AdaptedTank.transferWater//except for inner call:}// ...try {cmd.op();}// ...protected void doTransferWater(float amount)throws OverflowException, UnderflowException {// ... implementation code ...}public synchronized void transferWater(final float amount)throws OverflowException, UnderflowException {runWithinBeforeAfterChecks(new TankOp() {public void op()throws OverflowException, UnderflowException {doTransferWater(amount);}});}}Some applications of method adapters can be partially automated by using reflection facilities. Ageneric constructor can probe a class for a particular java.lang.reflect.Method , set uparguments for it, invoke it, and transfer back results. This comes at the price of weaker staticguarantees, greater overhead, and the need to deal with the many exceptions that can arise. So this isgenerally only worthwhile when dealing with unknown dynamically loaded code.More extreme and exotic reflective interception techniques are available if you escape the confines ofthe language. For example, it is possible to create and apply tools that splice bytecodes representingbefore and after actions into compiled class representations or do so upon class-loading.1.4.5 Further ReadingsThere are many useful design patterns besides those that are particular to concurrent programming,and surely many others relating to concurrency that are not included in this book. Other bookspresenting patterns and pattern-related aspects of software design include:Buschmann, Frank, Regine Meunier, Hans Rohnert, Peter Sommerlad, and Michael Stal. Pattern-Oriented Software Architecture: A System of Patterns, Wiley, 1996.Coplien, James. Advanced C++: Programming Styles and Idioms, Addison-Wesley, 1992.Fowler, Martin. Analysis Patterns, Addison-Wesley, 1997Gamma, Erich, Richard Helm, Ralph Johnson, and John Vlissides. Design Patterns, Addison-Wesley,1994. (The "Gang of Four" book.)Rising, Linda. The Patterns Handbook, Cambridge University Press, 1998.Shaw, Mary, and David Garlan. Software Architecture, Prentice Hall, 1996.(Various editors) Pattern Languages of Program Design, Addison-Wesley. This series incorporatespatterns presented at the annual Pattern Languages of Programming (PLoP) conference.The OO language Self is among the few that directly support a pure delegation-based style ofprogramming without requiring explicit message forwarding. See:Ungar, David. "The Self Papers", Lisp and Symbolic Computation, 1991.Reflective before/after techniques are often seen in Lisp, Scheme and CLOS (the Common LispObject System). See, for example:Abelson, Harold, and Gerald Sussman. Structure and Interpretation of Computer Programs, MITPress, 1996.Kiczales, Gregor, Jim des Rivieres, and Daniel Bobrow. The Art of the Metaobject Protocol, MITPress, 1993.Additional layered synchronization design patterns are discussed in:Rito Silva, António, João Pereira and José Alves Marques. "Object Synchronizer", in Neil Harrison,Brian Foote and Hans Rohnert (eds.), Pattern Languages of Program Design, Volume 4, Addison-Wesley, 1999.A compositional approach to layering concurrency control is described in:Holmes, David. Synchronisation Rings: Composable Synchronisation for Concurrent Object OrientedSystems, PhD Thesis, Macquarie University, 1999.Composition of collections of before/after methods that deal with different aspects of functionality(for example, mixing synchronization control with persis tence control) may require more elaborateframeworks than discussed here. One approach is to construct a metaclass framework that partiallyautomates the interception and wrapping of methods by class objects. For an extensive analysis anddiscussion of the resulting composition techniques, see:Forman, Ira, and Scott Danforth. Putting Metaclasses to Work, Addison-Wesley, 1999.Aspect-oriented programming replaces layered before/after techniques with tools that weave togethercode dealing with different aspects of control. Reports on the language AspectJ include someexamples from this book expressed in an aspect-oriented fashion. See:Kiczales, Gregor, John Lamping, Anurag Mendhekar, Chris Maeda, Cristina Videira Lopes, Jean-Marc Loingtier, and John Irwin. "Aspect-Oriented Programming", Proceedings of the EuropeanConference on Object-Oriented Programming (ECOOP), 1997.Several tools are available for partially automating invariant tests. See, for example:Beck, Kent, and Erich Gamma. "Test Infected: Programmers Love Writing Tests", The Java Report,July 1998.Chapter 2. ExclusionIn a safe system, every object protects itself from integrity violations. This sometimes requires thecooperation of other objects and their methods.Exclusion techniques preserve object invariants and avoid effects that would result from acting uponeven momentarily inconsistent state representations. Programming techniques and design patternsachieve exclusion by preventing multiple threads from concurrently modifying or acting upon objectrepresentations. All approaches rely on one or more of three basic strategies:Eliminating the need for some or all exclusion control by ensuring that methods never modify anobject's representation, so that the object cannot enter inconsistent states.Dynamically ensuring that only one thread at a time can access object state, by protecting objects withlocks and related constructs.Structurally ensuring that only one thread (or only one thread at a time) can ever use a given object,by hiding or restricting access to it.The first three sections of this chapter describe the central features and usage patterns surroundingeach of these approaches — immutability (§ 2.1), synchronization (§ 2.2), and confinement (§ 2.3).Section § 2.4 discusses some ways to combine these different approaches to improve safety, liveness,performance, and/or semantic guarantees. Section § 2.5 shows how to use utility classes to obtaineffects that are otherwise difficult to arrange using built-in constructs. Additionally, several of theclasses, techniques, and utilities described in Chapter 3 can be used to ensure exclusion (see especially§ 3.3.2).The mandatory use of these techniques represents an important difference between sequential andconcurrent programming practices. To guarantee safety in a concurrent system, you must ensure thatall objects accessible from multiple threads either are immutable or employ appropriatesynchronization, and also must ensure that no other object ever becomes concurrently accessible byleaking out of its ownership domain. While the techniques that help maintain these guarantees are inmany ways just extensions of other OO development practices, concurrent programs are typically lesstolerant of error.As discussed in § 1.3.1, most of these matters cannot by nature be enforced by compilers or run-timesystems. Analysis and testing tools may be helpful in detecting some kinds of failure, but the mainresponsibility for ensuring the safety of each class, component, subsystem, application, and systemfalls on its developers. Additionally, exclusion-related policies and design rules must be explicit andwell advertised.Much caution is needed when using code that was not designed to operate in multithreadedenvironments. Most classes in the java.* packages are designed to be thread-safe when applied intheir intended usage contexts. (Some exceptions are noted as they arise in this book. Other limitationsappear in class API documentation.) However, when constructing multithreaded applications, it isoften necessary to rework or wrap (see § 2.3.3.1) your own classes and packages that were originallydesigned only for use in single-threaded contexts.2.1 ImmutabilityIf an object cannot change state, then it can never encounter conflicts or inconsistencies when multipleactivities attempt to change its state in incompatible ways.Programs are much simpler to understand if existing objects are never changed, but instead new onesare continually created during the course of any computation. Unfortunately, such programs aregenerally unable to handle interaction via user interfaces, cooperating threads, and so on. However,selective use of immutability is a basic tool in concurrent OO programming.The simplest immutable objects have no internal fields at all. Their methods are intrinsically stateless— they do not rely on any assignable fields of any object. For example, all possible uses of thefollowing StatelessAdder class and its add method are obviously always safe and live:class StatelessAdder {public int add(int a, int b) { return a + b; }}The same safety and liveness properties hold in classes possessing only final fields. Instances ofimmutable classes cannot experience low-level read-write or write-write conflicts (see § 1.3.1),because values are never written. And as long as their initial values are established in a consistent,legal fashion, these objects cannot experience higher-level invariant failures. For example:class ImmutableAdder {private final int offset;public ImmutableAdder(int a) { offset = a; }public int addOffset(int b) { return offset + b; }}2.1.1 ApplicationsIt is of course possible to create immutable objects that contain more interesting structure andfunctionality than seen in ImmutableAdder . Applications include abstract data types, valuecontainers, and shared state representations.2.1.1.1 Abstract Data Types (ADTs)Immutable objects can serve as instances of simple abstract data types representing values. Somecommon ones are already defined in the java.* packages. These include java.awt.Color ,java.lang.Integer , java.math.BigDecimal , java.lang.String , andothers [1] . It is easy to define your own ADT classes, for example, Fraction , Interval ,ComplexFloat , and so on. Instances of such classes never alter their constructed field values, butmay provide methods that create objects representing new values. For example:[1]Note, however, that some other ADT-style classes in the java.* packages are not immutable, forexample java.awt.Point .class Fraction {protected final long numerator;protected final long denominator;// Fragmentspublic Fraction(long num, long den) {// normalize:boolean sameSign = (num >= 0) == (den >= 0);long n = (num >= 0)? num : -num;long d = (den >= 0)? den : -den;long g = gcd(n, d);numerator = (sameSign)? n / g : -n / g;denominator = d / g;}static long gcd(long a, long b) {// ...compute greatest common divisor ...}public Fraction plus(Fraction f) {return new Fraction(numerator * f.denominator +f.numerator * denominator,denominator * f.denominator);}public boolean equals(Object other) { // override defaultif (! (other instanceof Fraction) ) return false;Fraction f = (Fraction)(other);return numerator * f.denominator ==denominator * f.numerator;}public int hashCode() {// override defaultreturn (int) (numerator ^ denominator);}}Classes that represent immutable data abstractions have instances that serve only to encapsulatevalues, so their identities are not important. For example, two java.awt.Color objects that bothrepresent black (via RGB value 0) are typically intended to be treated as equivalent. This is one reasonwhy ADT-style classes should normally override methods Object.equals andObject.hashCode to reflect equality of abstract value, as illustrated in the Fraction class.The default implementations of these methods rely on the identities of objects maintaining thesevalues. Masking identity by overriding equals enables multiple ADT objects to represent the samevalues and/or perform the same functionality without clients needing to know or care exactly whichADT object is being used at any given time.You don't always have to commit to immutable representations of ADTs across an entire program. Itis sometimes helpful to define different classes, supporting different usages, for the immutable versusupdatable versions of some concept. For example, class java.lang.String is immutable,while class java.lang.StringBuffer is updatable, relying on synchronized methods.2.1.1.2 Value containersImmutable objects can be used when it is necessary or convenient to establish some consistent stateonce and then rely on it forever more. For example, an immutable ProgramConfigurationobject may reflect all of the settings to be used during the execution of a given program.Immutable value containers can also be useful whenever creating different variants, versions, or statesof an object by creating new ones through partial copying is relatively rare or cheap. In these cases,the expense of copying may be outweighed by the benefits of never needing to synchronize statechanges (see § 2.4.4). The analog of a state change for an immutable object is to produce a newimmutable object that differs from the original in some specified way.2.1.1.3 SharingImmutability is a useful technical device when you would like to share objects for space efficiency,and still provide efficient access to these objects. One immutable object can be referenced by anynumber of other objects without concern for synchronization or access restriction. For example, manyindividual character (or glyph) objects may all share references to the same immutable font object.This is one application of the Flyweight pattern described in the Design Patterns book. MostFlyweights designs are simplest to establish by ensuring the immutability of shared representations.Instances of many utility classes used in concurrent settings are intrinsically immutable and are sharedby many other objects. For example:class Relay {protected final Server server;Relay(Server s) { server = s; }void doIt() { server.doIt(); }}While purely immutable objects are simple, convenient, prevalent, and useful, many concurrent OOprograms also rely on partial immutability — constancy for only some fields, or only after executionof a particular method, or only over some period of interest. Exploitation of immutability is a usefulstrategy for producing designs that would be difficult at best to realize using updatable objects. Anumber of such designs are presented in the course of this book, especially in § 2.4.2.1.2 ConstructionTo be effective, all design decisions relying on immutability must be enforced via appropriate use ofthe final keyword. Additionally, some care is required when initializing immutable objects (see §2.2.7). In particular, it is counterproductive to make an immutable object available to others before ithas been fully initialized. As a general rule holding for any kind of class:•Do not allow fields to be accessed until construction is complete.This can be harder to ensure in concurrent settings than in sequential programs. Constructors shouldperform only actions directly related to field initialization. They should not invoke any other methodswhose effects may rely on the object being fully constructed. Constructors should avoid recording areference to the object being constructed in fields or tables accessible by others, avoid making calls toother methods with this as an argument, and more generally, avoid allowing the reference to thisto escape (see § 2.3). Without such precautions, other objects and methods running in other threadscould instead access the default-initialized zeros (for scalar fields) or nulls (for reference fields) set bythe JVM for each Object before its constructor is executed.In some cases, the values of conceptually immutable fields cannot be fully initialized in constructors,for example, when they are incrementally initialized from files, or when there are interdependenciesamong multiple objects being constructed at the same time. Further care is needed to ensure that theseobjects are not made available for use by others until values are stable. This almost always requiresuse of synchronization (see for example § 2.2.4 and § 3.4.2).2.2 SynchronizationLocking protects against low-level storage conflicts and corresponding high-level invariant failures.For example, consider the following class:class Even {// Do not useprivate int n = 0;public int next(){ // POST?: next is always even++n;++n;return n;}}Without locking, the desired postcondition may fail due to a storage conflict when two or morethreads execute the next method of the same Even object. Here is one possible execution trace,showing only the reads and writes to variable n that would result from the putfields andgetfields in compiled bytecode.Thread AThread Bread 0write 1read 2write 3return 3read 1write 2read 2write 3return 3As is typical in concurrent programs, most traces of two threads concurrently executingEven.next do not display this safety violation. Programs using this version of Even are likely topass some tests but are almost sure to break eventually. Such safety violations can be rare and difficultto test for, yet can have devastating effects. This motivates the careful, conservative design practicesseen in reliable concurrent programs.Declaring the next method as synchronized would preclude such conflicting traces. Lockingserializes the execution of synchronized methods. So here, either thread A 's next methodwould execute in full before thread B 's, or vice versa.2.2.1 MechanicsAs a preliminary to further discussions of design strategies based on locking, here is a summary ofmechanics, as well as some usage notes surrounding the synchronized keyword.2.2.1.1 Objects and locksEvery instance of class Object and its subclasses possesses a lock. Scalars of type int , float ,etc., are not Objects . Scalar fields can be locked only via their enclosing objects. Individual fieldscannot be marked as synchronized . Locking may be applied only to the use of fields withinmethods. However, as described in § 2.2.7.4, fields can be declared as volatile , which affectsatomicity, visibility, and ordering properties surrounding their use.Similarly, array objects holding scalar elements possess locks, but their individual scalar elements donot. (Further, there is no way to declare array elements as volatile .) Locking an array ofObjects does not automatically lock all its elements. There are no constructs for simultaneouslylocking multiple objects in a single atomic operation.Class instances are Objects . As described below, the locks associated with Class objects areused in static synchronized methods.2.2.1.2 Synchronized methods and blocksThere are two syntactic forms based on the synchronized keyword, blocks and methods. Blocksynchronization takes an argument of which object to lock. This allows any method to lock any object.The most common argument to synchronized blocks is this .Block synchronization is considered more fundamental than method synchronization. A declaration:synchronized void f() { /* body */ }is equivalent to:void f() { synchronized(this) { /* body */ } }The synchronized keyword is not considered to be part of a method's signature. So thesynchronized modifier is not automatically inherited when subclasses override superclassmethods, and methods in interfaces cannot be declared as synchronized . Also,constructors cannot be qualified as synchronized (although block synchronization can be usedwithin constructors).Synchronized instance methods in subclasses employ the same lock as those in their superclasses. Butsynchronization in an inner class method is independent of its outer class. However, a non-static innerclass method can lock its containing class, say OuterClass , via code blocks using:synchronized(OuterClass.this) { /* body */ }.2.2.1.3 Acquiring and releasing locksLocking obeys a built-in acquire-release protocol controlled only by use of the synchronizedkeyword. All locking is block-structured. A lock is acquired on entry to a synchronized methodor block, and released on exit, even if the exit occurs due to an exception. You cannot forget to releasea lock.Locks operate on a per-thread, not per-invocation basis. A thread hitting synchronized passes ifthe lock is free or the thread already possess the lock, and otherwise blocks. (This reentrant orrecursive locking differs from the default policy used for example in POSIX threads.) Among othereffects, this allows one synchronized method to make a self-call to another synchronizedmethod on the same object without freezing up.A synchronized method or block obeys the acquire-release protocol only with respect to othersynchronized methods and blocks on the same target object. Methods that are notsynchronized may still execute at any time, even if a synchronized method is in progress.In other words, synchronized is not equivalent to atomic, but synchronization can be used toachieve atomicity.When one thread releases a lock, another thread may acquire it (perhaps the same thread, if it hitsanother synchronized method). But there is no guarantee about which of any blocked threadswill acquire the lock next or when they will do so. (In particular, there are no fairness guarantees —see § 3.4.1.5.) There is no mechanism to discover whether a given lock is being held by some thread.As discussed in § 2.2.7, in addition to controlling locking, synchronized also has the side-effectof synchronizing the underlying memory system.2.2.1.4 StaticsLocking an object does not automatically protect access to static fields of that object's class or anyof its superclasses. Access to static fields is instead protected via synchronized staticmethods and blocks. Static synchronization employs the lock possessed by the Class objectassociated with the class the static methods are declared in. The static lock for class C can also beaccessed inside instance methods via:synchronized(C.class) { /* body */ }The static lock associated with each class is unrelated to that of any other class, including itssuperclasses. It is not effective to add a new static synchronized method in a subclass thatattempts to protect static fields declared in a superclass. Use the explicit block version instead.It is also poor practice to use constructions of the form:synchronized(getClass()) { /* body */ }// Do not useThis locks the actual class, which might be different from (a subclass of) the class defining thestatic fields that need protecting.The JVM internally obtains and releases the locks for Class objects during class loading andinitialization. Unless you are writing a special ClassLoader or holding multiple locks duringstatic initialization sequences, these internal mechanics cannot interfere with the use of ordinarymethods and blocks synchronized on Class objects. No other internal JVM actions independentlyacquire any locks for any objects of classes that you create and use. However, if you subclassjava.* classes, you should be aware of the locking policies used in these classes.2.2.2 Fully Synchronized ObjectsA lock is the most basic kind of message acceptance control mechanism. Locks may be used to blockclients attempting to invoke a method on an object while another method or code block (running in adifferent thread) is in progress.The safest (but not always the best) concurrent OO design strategy based on locking is to restrictattention to fully synchronized objects (also known as atomic objects) in which:•••••All methods are synchronized .There are no public fields or other encapsulation violations.All methods are finite (no infinite loops or unbounded recursion), and so eventually releaselocks.All fields are initialized to a consistent state in constructors.The state of the object is consistent (obeys invariants) at both the beginning and end of eachmethod, even in the presence of exceptions.For example, consider the following ExpandableArray class, a simplified variant ofjava.util.Vector .class ExpandableArray {protected Object[] data; // the elementsprotected int size = 0;// the number of array slots used// INV: 0 <= size <= data.lengthpublic ExpandableArray(int cap) {data = new Object[cap];}public synchronized int size() {return size;}public synchronized Object get(int i) // subscripted accessthrows NoSuchElementException {if (i < 0 || i >= size )throw new NoSuchElementException();return data[i];}public synchronized void add(Object x) { // add at endif (size == data.length) {// need a bigger arrayObject[] olddata = data;data = new Object[3 * (size + 1) / 2];System.arraycopy(olddata, 0, data, 0, olddata.length);}data[size++] = x;}public synchronized void removeLast()throws NoSuchElementException {if (size == 0)throw new NoSuchElementException();}}data[--size] = null;Without synchronization, an instance of this class could not be used reliably in concurrent settings.For example, it could encounter a read/write conflict if processing the accessor at while in the midstof a removeLast operation. And it could encounter a write/write conflict if concurrentlyperforming two add operations, in which case the state of the data array would be very difficult topredict.2.2.3 TraversalIn fully synchronized classes, you can add another atomic operation just by encasing it in asynchronized method. For the sake of reusability and convenience, it is often a good idea to addsmall suites of such operations to general-purpose classes or their subclasses. This avoids makingclients go through contortions trying to construct atomic versions of commonly used operations out ofsmaller components. For example, it would be useful to define synchronized versions ofremoveFirst , prepend , and similar methods to ExpandableArray , as found injava.util.Vector and other collection classes.However, this strategy doesn't work for another common usage of collections, traversal. A traversaliterates through all elements of a collection and performs some operation on or using each element.Since there are an unbounded number of operations clients might want to apply to the elements of acollection, it is pointless to try to code all of them as synchronized methods.There are three common solutions to this design problem, aggregate operations, indexed traversal, andversioned iterators, each of which reflect different design trade-offs. (See § 2.4.1.3, § 2.4.4, and §2.5.1.4 for additional strategies that apply to other kinds of collection classes.) The issues and trade-offs encountered in each approach are seen more generally in the design of many classes using locks.2.2.3.1 Synchronized aggregate operationsOne way to secure traversal is to abstract out the operation being applied to each element so that it canbe sent as an argument to a single synchronized applyToAll method. For example:interface Procedure {void apply(Object obj);}class ExpandableArrayWithApply extends ExpandableArray {public ExpandableArrayWithApply(int cap) { super(cap); }synchronized void applyToAll(Procedure p) {for (int i = 0; i < size; ++i)p.apply(data[i]);}}This could be used, for example, to print all elements in collection v :v.applyToAll(new Procedure() {public void apply(Object obj) {System.out.println(obj)}} );This approach eliminates potential interference that could occur if other threads attempted to add orremove elements during traversal, but at the expense of possibly holding the lock on the collection forprolonged periods. While this is often acceptable, it may lead to the kinds of liveness and performanceproblems that motivated the default rule in § 1.1.1.1 saying to release locks when making method calls(here, to apply ).2.2.3.2 Indexed traversal and client-side lockingA second traversal strategy available with ExpandableArray is to require clients to use theindexed accessor methods for traversal; for example:for (int i = 0; i < v.size(); ++i)System.out.println(v.get(i));// Do not useThis avoids holding the lock on v while performing each element operation, but at the expense of twosynchronized operations ( size and at ) per element. More importantly, the loop must be rewritten tohandle a potential interference problem resulting from the finer locking granularity: It is possible forthe check of i < v.size() to succeed but for another thread to remove the current last elementbefore the call to v.get(i) . One way to deal with this is to employ client-side locking to preserveatomicity across the size check and access:for (int i = 0; true; ++i) {// Limited utility}Object obj = null;synchronized(v) {if (i < v.size())obj = v.get(i);elsebreak;}System.out.println(obj);However, even this can be problematic. For example, if the ExpandableArray class supportedmethods to rearrange elements, this loop could print the same element twice if v were modifiedbetween iterations.As a more extreme measure, clients can surround the entire traversal with synchronized(v) .Again, this is often acceptable but can induce the long-term locking problems seen insynchronized aggregate methods. If the operations on elements are time-consuming, the clientcan instead first make a copy of the array for traversal purposes:Object[] snapshot;synchronized(v) {snapshot = new Object[v.size()];for (int i = 0; i < snapshot.length, ++i)snapshot[i] = v.get(i);}for (int i = 0; snapshot.length; ++i) {System.out.println(snapshot[i]);}Client-side locking tends to be used more extensively in non-object-oriented approaches tomultithreaded programming. This style is sometimes more flexible, and can be useful in OO systemswhen instances of a class are designed to be embedded within others (see § 2.4.5) and so must give upinternal responsibility for synchronization decisions.But client-side locking avoids potential interference problems at the expense of encapsulationbreakdown. Correctness here relies on special knowledge of the inner workings of theExpandableArray class that may fail to hold if the class is later modified. Still, this may beacceptable in closed subsystems. Client-side locking can also be a reasonable option when classesdocument these usages as sanctioned. This also constrains all future modifications and subclasses tosupport them as well.2.2.3.3 Versioned iteratorsA third approach to traversal is for a collection class to support fast-fail iterators that throw anexception if the collection is modified in the midst of a traversal. The simplest way to arrange this is tomaintain a version number that is incremented upon each update to the collection. The iterator canthen check this value whenever asked for the next element and throw an exception if it has changed.The version number field should be wide enough that it can never wrap around while a traversal is inprogress. An int normally suffices.This strategy is used in the java.util.Iterator classes in the collections framework. We canapply it here to a subclass of ExpandableArray that updates version numbers as an after-action(see § 1.4.3):class ExpandableArrayWithIterator extends ExpandableArray {protected int version = 0;public ExpandableArrayWithIterator(int cap) { super(cap); }public synchronized void removeLast()throws NoSuchElementException {super.removeLast();++version;// advertise update}public synchronized void add(Object x) {super.add(x);++version;}public synchronized Iterator iterator() {return new EAIterator();}protected class EAIterator implements Iterator {protected final int currentVersion;protected int currentIndex = 0;EAIterator() { currentVersion = version; }public Object next() {synchronized(ExpandableArrayWithIterator.this) {if (currentVersion != version)throw new ConcurrentModificationException();else if (currentIndex == size)throw new NoSuchElementException();elsereturn data[currentIndex++];}}public boolean hasNext() {synchronized(ExpandableArrayWithIterator.this) {return (currentIndex < size);}}public void remove() {// similar}}}Here, the print loop would be expressed as:for (Iterator it = v.iterator(); it.hasNext();) {try {System.out.println(it.next());}catch (NoSuchElementException ex) { /* ... fail ... */ }catch (ConcurrentModificationException ex) {/* ... fail ... */}}Even here, choices for dealing with failures are often very limited. AConcurrentModificationException often signifies unplanned, unwanted interactionsamong threads that should be remedied rather than patched over.The versioned iterator approach encapsulates the design choices underlying the data structure, at theprice of occasionally undue conservatism. For example, an interleaved add operation would notinterfere with the required semantics of a typical traversal, yet would cause an exception to be thrownhere. Versioned iterators are still a good default choice for collection classes, in part because it isrelatively easy to layer aggregate traversal or client-side locking on top of these iterators, but not viceversa.2.2.3.4 VisitorsThe Visitor pattern described in the Design Patterns book extends the notion of iterators to providesupport for clients performing operations on sets of objects connected in arbitrary ways, thus formingthe nodes of some kind of tree or graph rather than the sequential list seen in ExpandableArray .(Less relevantly here, the Visitor pattern also supports polymorphic operations on each node.)The options and concerns for visitors and other extended senses of traversal are similar to, and cansometimes be reduced to, those seen in simple iterators. For example, you might first create a list of allnodes to traverse and then apply any of the above techniques for traversing the list. However, lockshere would lock only the list, not the nodes themselves. This is usually the best policy. But if you needto ensure that all of the nodes are locked during the entire traversal, consider forms of confinement(see § 2.3.3) or containment locking (see § 2.4.5).Conversely, if traversal is arranged by every node supporting a nextNode method, and you do notwant to end up simultaneously holding all locks to all nodes encountered during traversal,synchronization of each node must be released before proceeding to the next node, as described in §2.4.1 and § 2.5.1.4.2.2.4 Statics and SingletonsAs described in the Design Patterns book, a Singleton class intentionally supports only one instance.It is convenient to declare that single instance as a static , in which case both class and instancemethods may use the same lock.Here is one way to define a fully synchronized singleton class that postpones construction of theinstance until it is first accessed via the instance method. This class represents a counter thatcould be used to assign global sequence numbers to objects, transactions, messages, etc., acrossdifferent classes in an application. (Just to illustrate computation during initialization, the initial valueis set to a randomly chosen number with at least 2 62 positive successors.)class LazySingletonCounter {private final long initial;private long count;private LazySingletonCounter() {initial = Math.abs(new java.util.Random().nextLong() / 2);count = initial;}private static LazySingletonCounter s = null;private static final Object classLock =LazySingletonCounter.class;public static LazySingletonCounter instance() {synchronized(classLock) {if (s == null)s = new LazySingletonCounter();return s;}}public long next() {synchronized(classLock) { return count++; }}public void reset() {synchronized(classLock) { count = initial; }}}The locking mechanics seen here (or any of several minor variants) prevent situations in which twodifferent threads invoke the instance method at about the same time, causing two instances to becreated. Only one of these instances would be bound to s and returned the next time instance isinvoked. As discussed in § 2.4.1, in a few cases this and other intentional semantic weakenings mightbe acceptable; in most cases, however, this would be a serious error.An easier way to avoid this kind of error is to avoid lazy initialization. Because JVMs performdynamic loading of classes, there is usually no need to support lazy initialization of singletons. Astatic field is not initialized until the class is loaded at runtime. While there are no guaranteesabout exactly when a class will be loaded (beyond that it will be loaded by the time it is accessed byexecuting code), full initialization of statics is less likely to impose significant start-up overhead thanin most other languages. So, unless initialization is both very expensive and rarely needed, it is usuallypreferable to take the simpler approach of declaring a singleton as a static final field. Forexample:class EagerSingletonCounter {private final long initial;private long count;private EagerSingletonCounter() {initial = Math.abs(new java.util.Random().nextLong() / 2);count = initial;}private static final EagerSingletonCounter s =new EagerSingletonCounter();public static EagerSingletonCounter instance() { return s; }public synchronized long next() { return count++; }public synchronized void reset() { count = initial; }}Simpler yet, if there is no compelling reason to rely on instances, you can instead define and use aversion with all static methods, as in:class StaticCounter {private static final long initial =Math.abs(new java.util.Random().nextLong() / 2);private static long count = initial;private StaticCounter() { } // disable instance constructionpublic static synchronized long next() { return count++; }public static synchronized void reset() { count = initial; }}Also, consider using ThreadLocal (see § 2.3.2) rather than a Singleton in situations where it ismore appropriate to create one instance of a class per thread than one instance per program.2.2.5 DeadlockAlthough fully synchronized atomic objects are always safe, threads using them are not always live.Consider for example a Cell class containing a method that swaps values with another Cell :class Cell {// Do not useprivate long value;synchronized long getValue() { return value; }synchronized void setValue(long v) { value = v; }synchronized void swapValue(Cell other) {long t = getValue();long v = other.getValue();setValue(v);other.setValue(t);}}SwapValue is a synchronized multiparty action — one that intrinsically acquires locks on multipleobjects. Without further precautions, it is possible for two different threads, one runninga.swapValue(b) , and the other running b.swapValue(a) , to deadlock when encounteringthe following trace:Thread 1acquire lock for a on enteringa.swapValue(b)pass lock for a (since already held) onentering t = getValue()block waiting for lock for b on entering v =other.getValue()Thread 2acquire lock for b on enteringb.swapValue(a)pass lock for b (since already held) onentering t = getValue()block waiting for lock for a on entering v =other.getValue()At this point both threads block forever.More generally, deadlock is possible when two or more objects are mutually accessible from two ormore threads, and each thread holds one lock while trying to obtain another lock already held byanother thread.2.2.6 Resource OrderingThe need to preclude or recover from deadlocks and other liveness failures motivates the use of otherexclusion techniques presented in this chapter. However, one simple technique, resource ordering canbe applied to classes such as Cell without otherwise altering their structure.The idea behind resource ordering is to associate a numerical (or any other strictly orderable datatype) tag with each object that can be held in a nested synchronized block or method. Ifsynchronization is always performed in least-first order with respect to object tags, then situations cannever arise in which one thread has the synchronization lock for x while waiting for y and another hasthe lock for y while waiting for x . Instead, they will both obtain the locks in the same order, thusavoiding this form of deadlock. More generally, resource ordering can be used whenever there is aneed to arbitrarily break symmetry or force precedence in a concurrent design.In some contexts (see for example § 2.4.5), there may be reasons to impose some specific orderingrules surrounding a set of locks. But in others, you can use any convenient tag for lock-orderingpurposes. For example, you may be able to use the value returned bySystem.identityHashCode . This method always returns the default implementation ofObject. hashCode , even if a class overrides the hashCode method. While there is no guaranteethat identityHashCode is unique, in practice run-time systems rely on codes to be distinct witha very high probability. To be even safer about it, you could override method hashCode orintroduce another tag method to ensure uniqueness in any classes employing resource ordering. Forexample, you could assign each object a sequence number using one of the classes in § 2.2.4.One further check, alias detection, can be applied in methods using nested synchronization to handlecases in which two (or more) of the references are actually bound to the same object. For example, inswapValue , you can check whether a Cell is being asked to swap with itself. This kind of checkis strictly optional here (but see § 2.5.1). Synchronization lock access is per-thread, not per-invocation.Additional attempts to synchronize on already held objects will still work. However, routine alias-checking is a useful way to forestall downstream functionality, efficiency, and synchronization-basedcomplications. It may be applied before using synchronization surrounding two or more objects unlessthey are of distinct, unrelated types. (Two references of two unrelated declared types cannot possiblybe referring to the same object anyway, so there is no reason to check.)A better version of swapValue , applying both resource ordering and alias detection, can be writtenas:public void swapValue(Cell other) {if (other == this) // alias checkreturn;else if (System.identityHashCode(this) <System.identityHashCode(other))this.doSwapValue(other);elseother.doSwapValue(this);}protected synchronized void doSwapValue(Cell other) {// same as original public version:long t = getValue();long v = other.getValue();setValue(v);other.setValue(t);}As a minor efficiency tweak, we could further streamline the code inside doSwapValue first toacquire the necessary locks, and then directly access the value fields. This avoids a self-call to asynchronized method while already holding the required lock, at the minor expense of addinglines of code that would need to be changed if the nature of the fields were ever modified:// slightly faster versionprotected synchronized void doSwapValue(Cell other) {synchronized(other) {long t = value;value = other.value;other.value = t;}}Note that the lock for this is obtained via the synchronized method qualifier, but the lock forother is explicitly acquired. A further, very tiny (perhaps nonexistent) performance improvementmight be obtained by folding the code in doSwapValue into swapValue , remembering toacquire both locks explicitly.Lock-ordering problems are by no means restricted to methods using nested synchronization. Theissue arises in any code sequence in which a synchronized method holding the lock on one object inturn calls a synchronized method on another object. However, there is less opportunity to applyresource ordering in cascaded calls: In the general case, one object cannot know for sure which otherobjects will be involved in downstream calls and whether they require synchronization. This is onereason that deadlock can be such a hard problem in open systems (see § 2.5) when you cannot releasesynchronization during calls (see § 2.4.1).2.2.7 The Java Memory ModelConsider the tiny class, defined without any synchronization:final class SetCheck {private int a = 0;private long b = 0;void set() {a = 1;b = -1;}boolean check() {return ((b == 0) ||(b == -1 && a == 1));}}In a purely sequential language, the method check could never return false . This holds eventhough compilers, run-time systems, and hardware might process this code in a way that you mightnot intuitively expect. For example, any of the following might apply to the execution of methodset :•The compiler may rearrange the order of the statements, so b may be assigned before a . Ifthe method is inlined, the compiler may further rearrange the orders with respect to yet otherstatements.••••The processor may rearrange the execution order of machine instructions corresponding to thestatements, or even execute them at the same time.The memory system (as governed by cache control units) may rearrange the order in whichwrites are committed to memory cells corresponding to the variables. These writes mayoverlap with other computations and memory actions.The compiler, processor, and/or memory system may interleave the machine-level effects ofthe two statements. For example on a 32-bit machine, the high-order word of b may bewritten first, followed by the write to a , followed by the write to the low-order word of b .The compiler, processor, and/or memory system may cause the memory cells representing thevariables not to be updated until sometime after (if ever) a subsequent check is called, butinstead to maintain the corresponding values (for example in CPU registers) in such a waythat the code still has the intended effect.In a sequential language, none of this can matter so long as program execution obeys as-if-serialsemantics [2] . Sequential programs cannot depend on the internal processing details of statementswithin simple code blocks, so they are free to be manipulated in all these ways. This provides essentialflexibility for compilers and machines. Exploitation of such opportunities (via pipelined superscalarCPUs, multilevel caches, load/store balancing, interprocedural register allocation, and so on) isresponsible for a significant amount of the massive improvements in execution speed seen incomputing over the past decade. The as-if-serial property of these manipulations shields sequentialprogrammers from needing to know if or how they take place. Programmers who never create theirown threads are almost never impacted by these issues.[2]Somewhat more precisely, as-if-serial (also known as program order) semantics can be defined as anyexecution traversal of the graph formed by ordering only those operations that have value or controldependencies with respect to each other under a language's base expression and statement semantics.Things are different in concurrent programming. Here, it is entirely possible for check to be calledin one thread while set is being executed in another, in which case the check might be "spying" onthe optimized execution of set . And if any of the above manipulations occur, it is possible forcheck to return false . For example, as detailed below, check could read a value for the longb that is neither 0 nor -1 , but instead a half-written in-between value. Also, out-of-order execution ofthe statements in set may cause check to read b as -1 but then read a as still 0 .In other words, not only may concurrent executions be interleaved, but they may also be reordered andotherwise manipulated in an optimized form that bears little resemblance to their source code. Ascompiler and run-time technology matures and multiprocessors become more prevalent, suchphenomena become more common. They can lead to surprising results for programmers withbackgrounds in sequential programming (in other words, just about all programmers) who have neverbeen exposed to the underlying execution properties of allegedly sequential code. This can be thesource of subtle concurrent programming errors.In almost all cases, there is an obvious, simple way to avoid contemplation of all the complexitiesarising in concurrent programs due to optimized execution mechanics: Use synchronization. Forexample, if both methods in class SetCheck are declared as synchronized , then you can besure that no internal processing details can affect the intended outcome of this code.But sometimes you cannot or do not want to use synchronization. Or perhaps you must reason aboutsomeone else's code that does not use it. In these cases you must rely on the minimal guarantees aboutresulting semantics spelled out by the Java Memory Model. This model allows the kinds ofmanipulations listed above, but bounds their potential effects on execution semantics and additionallypoints to some techniques programmers can use to control some aspects of these semantics (most ofwhich are discussed in § 2.4).The Java Memory Model is part of The JavaTM Language Specification, described primarily in JLSchapter 17. Here, we discuss only the basic motivation, properties, and programming consequences ofthe model. The treatment here reflects a few clarifications and updates that are missing from the firstedition of JLS [3] .[3]As of this writing, the memory model and other relevant sections of JLS are still being updated to coverthe Java 2 Platform. Please check the online supplement for any changes that impact the material in thissection.The assumptions underlying the model can be viewed as an idealization of a standard SMP machine ofthe sort described in § 1.2.4:For purposes of the model, every thread can be thought of as running on a different CPU from anyother thread. Even on multiprocessors, this is infrequent in practice, but the fact that this CPU-per-thread mapping is among the legal ways to implement threads accounts for some of the model'sinitially surprising properties. For example, because CPUs hold registers that cannot be directlyaccessed by other CPUs, the model must allow for cases in which one thread does not know aboutvalues being manipulated by another thread. However, the impact of the model is by no meansrestricted to multiprocessors. The actions of compilers and processors can lead to identical concernseven on single-CPU systems.The model does not specifically address whether the kinds of execution tactics discussed above areperformed by compilers, CPUs, cache controllers, or any other mechanism. It does not even discussthem in terms of classes, objects, and methods familiar to programmers. Instead, the model defines anabstract relation between threads and main memory. Every thread is defined to have a workingmemory (an abstraction of caches and registers) in which to store values. The model guarantees a fewproperties surrounding the interactions of instruction sequences corresponding to methods andmemory cells corresponding to fields. Most rules are phrased in terms of when values must betransferred between the main memory and per-thread working memory. The rules address threeintertwined issues:Atomicity. Which instructions must have indivisible effects. For purposes of the model, these rulesneed to be stated only for simple reads and writes of memory cells representing fields — instance andstatic variables, also including array elements, but not including local variables inside methods.Visibility. Under what conditions the effects of one thread are visible to another. The effects of interesthere are writes to fields, as seen via reads of those fields.Ordering. Under what conditions the effects of operations can appear out of order to any given thread.The main ordering issues surround reads and writes associated with sequences of assignmentstatements.When synchronization is used consistently, each of these properties has a simple characterization: Allchanges made in one synchronized method or block are atomic and visible with respect to othersynchronized methods and blocks employing the same lock, and processing ofsynchronized methods or blocks within any given thread is in program-specified order. Eventhough processing of statements within blocks may be out of order, t his cannot matter to other threadsemploying synchronization.When synchronization is not used or is used inconsistently, answers become more complex. Theguarantees made by the memory model are weaker than most programmers intuitively expect, and arealso weaker than those typically provided on any given JVM implementation. This imposes additionalobligations on programmers attempting to ensure the object consistency relations that lie at the heartof exclusion practices: Objects must maintain invariants as seen by all threads that rely on them, notjust by the thread performing any given state modification.The most important rules and properties specified by the model are discussed below.2.2.7.1 AtomicityAccesses and updates to the memory cells corresponding to fields of any type except long ordouble are guaranteed to be atomic. This includes fields serving as references to other objects.Additionally, atomicity extends to volatile long and double . (Even though non-volatilelongs and doubles are not guaranteed atomic, they are of course allowed to be.)Atomicity guarantees ensure that when a non- long/double field is used in an expression, youwill obtain either its initial value or some value that was written by some thread, but not some jumbleof bits resulting from two or more threads both trying to write values at the same time. However, asseen below, atomicity alone does not guarantee that you will get the value most recently written byany thread. For this reason, atomicity guarantees per se normally have little impact on concurrentprogram design.2.2.7.2 VisibilityChanges to fields made by one thread are guaranteed to be visible to other threads only under thefollowing conditions:1. A writing thread releases a synchronization lock and a reading thread subsequently acquiresthat same synchronization lock.In essence, releasing a lock forces a flush of all writes from working memory employed bythe thread, and acquiring a lock forces a (re)load of the values of accessible fields. While lockactions provide exclusion only for the operations performed within a synchronizedmethod or block, these memory effects are defined to cover all fields used by the threadperforming the action.Note the double meaning of synchronized : it deals with locks that permit higher-levelsynchronization protocols, while at the same time dealing with the memory system(sometimes via low-level memory barrier machine instructions) to keep value representationsin synch across threads. This reflects one way in which concurrent programming bears moresimilarity to distributed programming than to sequential programming. The latter sense ofsynchronized may be viewed as a mechanism by which a method running in one threadindicates that it is willing to send and/or receive changes to variables to and from methodsrunning in other threads. From this point of view, using locks and passing messages might beseen merely as syntactic variants of each other.2. If a field is declared as volatile , any value written to it is flushed and made visible bythe writer thread before the writer thread performs any further memory operation (i.e., for thepurposes at hand it is flushed immediately). Reader threads must reload the values ofvolatile fields upon each access.3. The first time a thread accesses a field of an object, it sees either the initial value [4] of the fieldor a value since written by some other thread.[4]As of this writing, the JLS does not yet clearly state that the visible initial value read for aninitialized final field is the value assigned in its initializer or constructor. However, thisanticipated clarification is assumed throughout this book. The visible initial default values of non-final fields are zero for scalars and null for references.Among other consequences, it is bad practice to make available the reference to anincompletely constructed object (see § 2.1.2). It can also be risky to start new threads inside aconstructor, especially in a class that may be subclassed. Thread.start has the samememory effects as a lock release by the thread calling start , followed by a lock acquire bythe started thread. If a Runnable superclass invokes new Thread(this).start()before subclass constructors execute, then the object might not be fully initialized when therun method executes. Similarly, if you create and start a new thread T and then create anobject X used by thread T , you cannot be sure that the fields of X will be visible to T unlessyou employ synchronization surrounding all references to object X . Or, when applicable, youcan create X before starting T .4. As a thread terminates, all written variables are flushed to main memory.For example, if one thread synchronizes on the termination of another thread usingThread.join , then it is guaranteed to see the effects made by that thread (see § 4.3.2).Note that visibility problems never arise when passing references to objects across methods in thesame thread.The memory model guarantees that, given the eventual occurrence of the above operations, aparticular update to a particular field made by one thread will eventually be visible to another. Buteventually can be an arbitrarily long time. Long stretches of code in threads that use nosynchronization can be hopelessly out of synch with other threads with respect to values of fields. Inparticular, it is always wrong to write loops waiting for values written by other threads unless thefields are volatile or accessed via synchronization (see § 3.2.6).The model also allows inconsistent visibility in the absence of synchronization. For example, it ispossible to obtain a fresh value for one field of an object, but a stale value for another. Similarly, it ispossible to read a fresh, updated value of a reference variable, but a stale value of one of the fields ofthe object now being referenced.However, the rules do not require visibility failures across threads, they merely allow these failures tooccur. This is one aspect of the fact that not using synchronization in multithreaded code doesn'tguarantee safety violations, it just allows them. On most current JVM implementations and platforms,even those employing multiple processors, detectable visibility failures rarely occur. The use ofcommon caches across threads sharing a CPU, the lack of aggressive compiler-based optimizations,and the presence of strong cache consistency hardware often cause values to act as if they propagateimmediately among threads. This makes testing for freedom from visibility-based errors impractical,since such errors might occur extremely rarely, or only on platforms you do not have access to, oronly on those that have not even been built yet. These same comments apply to multithreaded safetyfailures more generally. Concurrent programs that do not use synchronization fail for many reasons,including memory consistency problems.2.2.7.3 OrderingOrdering rules fall under two cases, within-thread and between-thread:••From the point of view of the thread performing the actions in a method, instructions proceedin the normal as-if-serial manner that applies in sequential programming languages.From the point of view of other threads that might be "spying" on this thread by concurrentlyrunning unsynchronized methods, almost anything can happen. The only useful constraint isthat the relative orderings of synchronized methods and blocks, as well as operations onvolatile fields, are always preserved.Again, these are only the minimal guaranteed properties. In any given program or platform, you mayfind stricter orderings. But you cannot rely on them, and you may find it difficult to test for code thatwould fail on JVM implementations that have different properties but still conform to the rules.Note that the within-thread point of view is implicitly adopted in all other discussions of semantics inJLS. For example, arithmetic expression evaluation is performed in left-to-right order (JLS section15.6) as viewed by the thread performing the operations, but not necessarily as viewed by otherthreads.The within-thread as-if-serial property is helpful only when only one thread at a time is manipulatingvariables, due to synchronization, structural exclusion, or pure chance. When multiple threads are allrunning unsynchronized code that reads and writes common fields, then arbitrary interleavings,atomicity failures, race conditions, and visibility failures may result in execution patterns that makethe notion of as-if-serial just about meaningless with respect to any given thread.Even though JLS addresses some particular legal and illegal reorderings that can occur, interactionswith these other issues reduce practical guarantees to saying that the results may reflect just about anypossible interleaving of just about any possible reordering. So there is no point in trying to reasonabout the ordering properties of such code.2.2.7.4 VolatileIn terms of atomicity, visibility, and ordering, declaring a field as volatile is nearly identical ineffect to using a little fully synchronized class protecting only that field via get/set methods, as in:final class VFloat {private float value;final synchronized void set(float f) { value = f; }final synchronized float get(){ return value; }}Declaring a field as volatile differs only in that no locking is involved. In particular, compositeread/write operations such as the " ++ '' operation on volatile variables are not performedatomically.Also, ordering and visibility effects surround only the single access or update to the volatile fielditself. Declaring a reference field as volatile does not ensure visibility of non- volatile fieldsthat are accessed via this reference. Similarly, declaring an array field as volatile does not ensurevisibility of its elements. Volatility cannot be manually propagated for arrays because array elementsthemselves cannot be declared as volatile .Because no locking is involved, declaring fields as volatile is likely to be cheaper than usingsynchronization, or at least no more expensive. However, if volatile fields are accessedfrequently inside methods, their use is likely to lead to slower performance than would locking theentire methods.Declaring fields as volatile can be useful when you do not need locking for any other reason, yetvalues must be accurately accessible across multiple threads. This may occur when:••••The field need not obey any invariants with respect to others.Writes to the field do not depend on its current value.No thread ever writes an illegal value with respect to intended semantics.The actions of readers do not depend on values of other non-volatile fields.Using volatile fields can make sense when it is somehow known that only one thread can changea field, but many other threads are allowed to read it at any time. For example, a Thermometerclass might declare its temperature field as volatile . As discussed in § 3.4.2, avolatile can be useful as a completion flag. Additional examples are illustrated in § 4.4, wherethe use of lightweight executable frameworks automates some aspects of synchronization, butvolatile declarations are needed to ensure that result field values are visible across tasks.2.2.8 Further ReadingsFeatures of computer architectures that impact multithreaded programs are described in:Schimmel, Curt. UNIX Systems for Modern Architectures Symmetric Multiprocessing and Caching forKernel Programmers, Addison-Wesley, 1994.Patterson, David, and John Hennessy. Computer Organization and Design: The Hardware/SoftwareInterface, Morgan Kaufmann, 1997. See also its online supplement with links to further resources onspecific machine architectures.Memory consistency models are the subject of increasing attention as both multiprocessors andmultithreaded programs become more common and their interactions become more of a concern. Atleast with respect to locking, the Java memory model is closest to the family of release consistencymodels. For an overview, see:Adve, Sarita and K. Gharachorloo. "Shared Memory Consistency Models: A Tutorial", IEEEComputer, December 1996, 66-76. See also follow-ups, including: "Recent Advances in MemoryConsistency Models for Hardware Shared-Memory Systems" Proceedings of the IEEE, special issueon distributed shared memory, 1999.2.3 ConfinementConfinement employs encapsulation techniques to structurally guarantee that at most one activity at atime can possibly access a given object. This statically ensures that the accessibility of a given objectis unique to a single thread without needing to rely on dynamic locking on each access. The maintactic is to define methods and classes that establish leak-proof ownership domains guaranteeing thatonly one thread, or one thread at a time, can ever access a confined object.Confinement practices are similar to other security measures that guarantee that no sensitiveinformation ever escapes from a domain. The information leakage of interest here is access to objects,almost always via references to these objects. This issue poses the same kinds of challenges seen inother aspects of security: It is sometimes difficult to demonstrate that not even one leak is possible, yetconfinement cannot be relied on unless a design is proven leak-proof. However, this task is lesscritical than in some other aspects of security, since there are backup strategies. Thus, when youcannot ensure confinement, you can employ other exclusion techniques described in this chapter.Confinement relies on the scoping, access control, and security features of a given language thatsupport data hiding and encapsulation. However, the senses of confinement needed to ensureuniqueness cannot be completely enforced by language mechanisms. There are four categories tocheck to see if a reference r to an object x can escape from a method m executing within someactivity:••••m passes r as an argument in a method invocation or object constructor.m passes r as the return value from a method invocation.m records r in some field that is accessible from another activity (in the most flagrant case,static fields that are accessible anywhere).m releases (in any of the above ways) another reference that can in turn be traversed to accessr .Selected leakages can sometimes be tolerated if you can somehow guarantee that escapes are allowedonly to methods that cannot cause state changes (field assignments) in the objects of interest (see §2.4.3).In some closed classes and subsystems (see § 1.3.4), these matters can be exhaustively checked. Inopen systems, most constraints can only be maintained as design rules, as assisted by tools andreviews.This section discusses four sorts of confinement. The first and simplest, method confinement, involvesordinary programming practices surrounding local variables. The second, thread confinement,introduces techniques for restricting access within threads. The third, object confinement, uses OOencapsulation techniques to provide the stronger guarantees needed to ensure uniqueness of access formethods entering objects. The fourth, group confinement, extends these techniques to collaboratingsets of objects operating across multiple threads.2.3.1 Confinement Across MethodsIf a given method invocation creates an object and does not let it escape, then it can be sure that noother threads will interfere with (or even know about) its use of that object. Hiding access within localscopes is a common encapsulation tactic in all forms of programming.With only a modicum of care, these techniques can be extended to sequences of method invocations.For example, consider the following class that uses java.awt.Point . This Point class isdefined as a simple record-style class with public x and y fields, so it would be unwise to shareinstances across threads.class Plotter {// ...// Fragmentspublic void showNextPoint() {Point p = new Point();p.x = computeX();p.y = computeY();display(p);}protected void display(Point p) {// somehow arrange to show p.}}Here the showNextPoint method creates a local Point . It allows the Point to escape intodisplay(p) only in a tail call, after showNextPoint is sure never to access it again, even ifthe Point is later accessed from another thread. (Access from another thread could occur here:Essentially all graphics-based programs somehow rely on the AWT event thread — see § 1.1.1.3 and§ 4.1.4 — although it is unlikely that the thread would modify the Point object.)This is an example of a hand-off protocol that ensures that, at any given time, at most one activelyexecuting method can access an object. This tail-call version is the simplest and usually best form.Similar usages are seen in factory methods that construct and initialize an object and finally return it,as seen for example in the ParticleApplet.makeThread method in § 1.1.1.3.2.3.1.1 SessionsMany hand-off sequences are structured as sessions in which some public entry method constructsobjects that will be confined to a sequence of operations comprising a service. This entry methodshould also be responsible for any cleanup operations required upon completion of the sequence. Forexample:class SessionBasedService {// Fragments// ...public void service() {OutputStream output = null;try {output = new FileOutputStream("...");doService(output);}catch (IOException e) {handleIOFailure();}finally {try { if (output != null) output.close(); }catch (IOException ignore) {} // ignore exception in close}}void doService(OutputStream s) throws IOException {s.write(...);// ... possibly more handoffs ...}}When you have a choice between them, it is almost always preferable to perform cleanup infinally clauses rather than relying on finalization (i.e., overriding Object.finalize ). Useof finally provides a stronger guarantee about when cleanup will take place, which helpsconserve possibly scarce resources such as files. In contrast, finalizers generally triggerasynchronously as a result of garbage collection, if ever.2.3.1.2 Alternative protocolsTail-call hand-offs do not apply if a method must access an object after a call or must make multiplecalls. Additional design rules are needed to cover cases such as a revised Plotter class withmethod:public void showNextPointV2() {Point p = new Point();p.x = computeX();p.y = computeY();display(p);recordDistance(p); // added}Options include:Caller copies. When the objects being passed around represent data values such as points in whichobject identity does not matter, then the caller can make a copy of the object for use by the receiver.Here, for example,display(p);would be replaced by:display(new Point(p.x, p.y));Receiver copies. If a method knows nothing about the usage constraints surrounding an objectreference sent as an argument (and again, if object identity does not matter), it can conservativelymake a copy for its own local use. Here for example, the display method could have as its firstline:Point localPoint = new Point(p.x, p.y);Using scalar arguments. Uncertainties about caller and receiver responsibilities can be eliminated bynot sending references at all, but instead sending scalar arguments providing enough information forthe receiver to construct an object if desired. Here, for example, we could reparameterize displayto:protected void display(int xcoord, int ycoord) { ... }and the call to:display(p.x, p.y);Trust. A receiver (or rather its author) may promise not to modify or transmit objects accessible viareference arguments. It must in turn ensure lack of unwanted access in any downstream calls.If none of these can be arranged, then pure confinement is not guaranteed to succeed, and othersolutions described in this chapter should be applied. For example, if use of java.awt.Pointwere not required here, you could instead use an ImmutablePoint class to ensure lack ofmodification (see § 2.4.4).2.3.2 Confinement Within ThreadsThread-based confinement techniques [5] extend those for method sequences. In fact, the simplest andoften best technique is to use a thread-per-session design (see § 4.1) that is otherwise identical tosession-based confinement. For example, you can initialize hand-offs in the base of a run method:[5]Even though this section presupposes only knowledge of the basic Thread usages presented in Chapter1, you may find a cursory glance through Chapter 4 helpful.class ThreadPerSessionBasedService { // fragments// ...public void service() {Runnable r = new Runnable() {public void run() {OutputStream output = null;try {output = new FileOutputStream("...");doService(output);}catch (IOException e) {handleIOFailure();}finally {try { if (output != null) output.close(); }catch (IOException ignore) {}}}};new Thread(r).start();}void doService(OutputStream s) throws IOException {s.write(...);// ... possibly more hand-offs ...}}Some approaches to concurrent software design (such as CSP — see § 4.5.1) arrange or require thatall fields accessible within a thread be strictly confined to that thread. This mimics the enforcedisolation of address spaces seen in process — versus thread — based concurrent programming (see §1.2.2).However, note that it is generally impossible to confine access to every object used in a given thread.All threads running on a given JVM must ultimately share access to at least some underlyingresources, for example those controlled via methods in the java.lang.System class.2.3.2.1 Thread-specific fieldsIn addition to receiving confined references along call chains, the method invocations executingwithin a single thread can access the Thread object representing the thread they are running in, andany further information traversable from there. The static method Thread.currentThread()can be called from any method and returns the Thread object of the caller.You can exploit this by adding fields to Thread subclasses and supplying methods to access themonly from within the current thread. For example:class ThreadWithOutputStream extends Thread {private OutputStream output;ThreadWithOutputStream(Runnable r, OutputStream s) {super(r);output = s;}static ThreadWithOutputStream current()throws ClassCastException {return (ThreadWithOutputStream) (currentThread());}static OutputStream getOutput() { return current().output; }static void setOutput(OutputStream s) { current().output =s;}}This class could be used, for example, in:class ServiceUsingThreadWithOutputStream {// Fragments// ...public void service() throws IOException {OutputStream output = new FileOutputStream("...");Runnable r = new Runnable() {public void run() {try { doService(); } catch (IOException e) { ... }}};new ThreadWithOutputStream(r, output).start();}void doService() throws IOException {ThreadWithOutputStream.current().getOutput().write(...);// ...}}2.3.2.2 ThreadLocalThe java.lang.ThreadLocal utility class removes one obstacle to using thread-specifictechniques, their reliance on special Thread subclasses. This class allows thread-specific variablesto be added in an ad-hoc fashion to just about any code.The ThreadLocal class internally maintains a table associating data ( Object references) withThread instances. ThreadLocal supports set and get methods to access data held by thecurrent Thread . The java.lang.InheritableThreadLocal class extendsThreadLocal to automatically propagate per-thread variables to any threads that are in turncreated by the current thread.Most designs employing ThreadLocal may be seen as extensions of the Singleton (see § 2.2.4)pattern. Rather than constructing one instance of a resource per program, most applications ofThreadLocals construct one instance per thread. ThreadLocal variables are normallydeclared as static , and usually have package-scoped visibility so they may be accessed by any of aset of methods running in a given thread.A ThreadLocal could be used in our running example as follows:class ServiceUsingThreadLocal {// Fragmentsstatic ThreadLocal output = new ThreadLocal();public void service() {try {final OutputStream s = new FileOutputStream("...");Runnable r = new Runnable() {public void run() {output.set(s);try { doService(); }catch (IOException e) { ... }finally {try { s.close(); }catch (IOException ignore) {}}}};new Thread(r).start();}catch (IOException e) { ...}}void doService() throws IOException {((OutputStream)(output.get())).write(...);// ...}}2.3.2.3 Applications and consequencesThreadLocals and Thread subclasses holding thread-specific fields are typically used onlywhen there is no other good option available. Advantages and disadvantages compared to otherapproaches such as session-based designs include:•Housing object references in (or associated with) Thread objects allows methods runningin the same thread to share them freely without needing to pass them explicitly as parameters.This can be a good option for maintaining contextual information such as theAccessControlContext of the current thread (as is done in the java.securitypackages) or the current working directory to be used for opening a set of related files.ThreadLocal can also be useful for constructing per-thread resource pools (see §3.4.1.2).••••••The use of thread-specific variables tends to hide parameters that influence behavior and canmake it harder to check for errors or leakage. In this sense, thread-specific variables presentthe same, although less extreme, traceability problems as static global variables.It is simple to guarantee that a status change to a thread-specific variable (for example,closing one output file and opening another) affects all relevant code. On the other hand, itcan be difficult to guarantee that all such changes are properly coordinated.No synchronization is necessary for either reads or writes to thread-specific fields from withinthe thread. However, the access paths via currentThread or internal ThreadLocaltables are not likely to be any cheaper than uncontended synchronized method calls. Sothe use of thread-specific techniques generally improves performance only when objectswould otherwise need to be shared and heavily contended for across threads.Use of thread-specific variables can detract from reusability by increasing code dependencies.This is a more serious problem under the Thread subclass approach. For example, thedoService method is unusable unless run within a ThreadWithOutputStream .Any attempted use outside this context will result in a ClassCastException wheninvoking method current .Adding context information via ThreadLocal is sometimes the only way to letcomponents work with existing code that does not propagate required information along callsequences (see § 3.6.2).It is difficult to associate data with execution contexts when using lightweight executableframeworks that are only indirectly based upon class Thread , in particular, worker threadpools (see § 4.1.4).2.3.3 Confinement Within ObjectsEven when you cannot confine access to an object within a particular method or thread, and so mustuse dynamic locking, you can confine all accesses internal to that object so that no additional lockingis necessary once a thread enters one of its methods. In this way, the exclusion control for the outerHost container object automatically propagates to its internal Parts. For this to work, references to theParts must not be leaked. (See § 2.4.5 for strategies that may apply when leakage from containerscannot be precluded.)Object confinement is seen in OO programs of all kinds. The main added requirement in concurrentcontexts is to ensure synchronization at all entry points into the Host object. This employs the sametechniques used when building fully synchronized objects (§ 2.2.2) holding instances of primitivescalar types such as double . But here they are applied to classes holding references to other objects.In confinement-based designs, the Host object may be thought of as owning the inner Parts.Conversely, the Part objects may be thought of as being "physically" contained in their Host:••••The Host object constructs new instances of each Part object upon its own construction,assigning references to non-public fields. Fresh construction guarantees that references to thePart objects are not shared by any other object. Alternatively, the constructor can act as ahand-off point.As in any confinement technique, the Host object must never leak references to any Partobject: It must never pass the references as arguments or return values of any method, andmust ensure that the fields holding the references are inaccessible. Additionally, the Partobjects must not leak their own identities, for example by sending this as a callbackargument (see § 4.3.1) to an external method. This guarantees that the Part objects areexternally accessible only via methods on the Host object.In the most conservative variant, fixed containment, the Host object never reassigns referencefields pointing to the inner Part objects. This avoids the need for synchronization surroundingfield updates in the Host object. Fixed containment implements the main sense ofaggregation discussed in the Design Patterns book and denoted by UML diamond symbols.Unless the Host object is in turn confined within another, all appropriate methods of the hostobject are synchronized. (See § 2.3.3.2 for one approach to defining both synchronized andunsynchronized versions of classes.) This guarantees that all accesses to the Parts (and allobjects recursively constructed within them) maintain exclusion. Note that the Partsrecursively held in a single confinement domain can invoke methods on one another withoutemploying synchronization; only external accesses require synchronization.Despite the demanding (and sometimes difficult to check) constraints that they must fulfill, objectconfinement techniques are very common, in part due to their utility in constructing Adapters andother delegation-based designs.2.3.3.1 AdaptersAdapters (see § 1.4.2) can be used to wrap bare unsynchronized ground objects within fullysynchronized host objects. This leads to the simplest possible delegation-style designs: those in whichthe Adapters just forward all messages on to their delegates. Synchronized Adapters can be used toenclose "legacy" code originally written for sequential settings, as well as dynamically loaded codethat you do not trust to be safe in multithreaded contexts.An Adapter can also provide a single safe entry point into a heavily optimized (perhaps even intonative code), computationally intensive set of functionality that, for the sake of efficiency,performs no internal concurrency control. Note, however, that no amount of wrapping can deal withnative code that internally accesses fields unsafely across different threads.Given one or more unprotected ground classes, you can define a synchronized Adapter class with afield, say delegate , holding a reference to a ground object, to which it forwards requests andrelays replies. (Note that if any ground method contains a reply of the form return this , it shouldbe translated as return this in the Adapter.) Delegate references need not be final , but if theyare assignable, care must be taken that the Adapter obtains exclusive access. For example, an Adaptermight occasionally assign the reference to a new internally constructed delegate.As mentioned in § 1.4, when it is important to ensure that Adapters are treated as identical to theirinternally held ground objects, you can override the equals and hashCode methods accordingly.However, there is no reason to do so in confinement-based designs since the internal objects are neverleaked out, so will never be compared.As one simple application, synchronized Adapters can be used to place synchronized access andupdate methods around a class containing public instance variables, such as a wide-open pointclass:class BarePoint {public double x;public double y;}class SynchedPoint {protected final BarePoint delegate = new BarePoint();publicpublicpublicpublic}synchronizedsynchronizedsynchronizedsynchronizeddouble getX() { return delegate.x;}double getY() { return delegate.y; }void setX(double v) { delegate.x = v; }void setY(double v) { delegate.y = v; }The java.util.Collection framework uses an Adapter-based scheme to allow layeredsynchronization of collection classes. Except for Vector and Hashtable , the basic collectionclasses (such as java.util.ArrayList ) are unsynchronized. However, anonymoussynchronized Adapter classes can be constructed around the basic classes using for example:List l = Collections.synchronizedList(new ArrayList());2.3.3.2 SubclassingWhen instances of a given class are always intended to be confined within others, there is no reason tosynchronize their methods. But when some instances are confined and some are not, the safest practiceis to synchronize them appropriately, even though locking is not required in all usage contexts. (See,however, § 2.4.5 and § 3.3.4 for situations in which other tactics may apply.)As compilers, tools, and run-time systems continue to improve, they are increasingly able to optimizeaway or minimize the overhead of superfluous locking. However, when necessary or desirable, youcan arrange this manually by defining multiple versions of a class and then instantiating theappropriate version for a given usage context. Among the simplest options is subclassing (see § 1.4.3):creating an unprotected base class and then overriding each method m as a synchronized methodcalling super.m . For example:class Address {protected String street;protected String city;// Fragmentspublic String getStreet() { return street; }public void setStreet(String s) { street = s; }// ...public void printLabel(OutputStream s) { ... }}class SynchronizedAddress extends Address {// ...public synchronized String getStreet() {return super.getStreet();}public synchronized void setStreet(String s) {super.setStreet(s);}public synchronized void printLabel(OutputStream s) {super.printLabel(s);}}2.3.4 Confinement Within GroupsGroups of objects accessible across multiple threads can together ensure that only one of them at atime can access a given resource object. Here each resource is always owned by only one object, butownership may change hands over time. Protocols for maintaining exclusive ownership are similar tothose for handing off references across method invocations discussed in § 2.3.1, but require morestructure to manage conformance across groups of objects and threads.Exclusively held resources are analogs of physical objects in the sense that:••••If you have one, then you can do something (with it) that you couldn't do otherwise.If you have it, then no one else has it.If you give it to someone else, then you no longer have it.If you destroy it, then no one will ever have it.Any kind of object can be viewed as a resource if it is used in this manner. A more concrete way ofcharacterizing this policy is that at most one field of one object refers to any exclusive resource at anygiven time. This fact can be exploited to ensure confinement within any given activity, thus reducingthe need for dynamic synchronization on resource objects.In some contexts and senses, protocols involving exclusive resources have been termed tokens,batons, linear objects, capabilities, and sometimes just resources. Several concurrent and distributedalgorithms hinge on the idea that only one object at a time possesses a token. For a hardware-basedexample, token-ring networks maintain a single token that is continually circulated among the nodes.Each node may send messages only when it has the token.While most transfer protocols are very simple, implementation can be error-prone: Fields containingreferences to objects just don't act much like physical objects when it comes to the notion ofpossession. For example, statements of the form x.r = y.s . do not cause owner y containingfield s to lose possession after completion of the operation. The assignment instead results in both rand s still being bound. (This state of affairs is analogous to real-life problems in dealing withintellectual property rights and other forms of permission that do not intrinsically entail physicaltransfer operations.) This problem has led to a vast array of solutions, ranging from informalconventions to arbitrarily heavy legal apparatus.To improve reliability, you can encapsulate protocols in methods performing the following operations,for distinct Resource objects r and s , and Owner objects x and y that may hold them in fieldref . For emphasis, required locks are shown using synchronized blocks:Acquire. Owner x establishes initial possession of r . This is usually the result of constructing orotherwise initializing r and setting:synchronized(this) { ref = r; }Forget. Owner x causes Resource r not to be possessed by any Owner . This is usuallyaccomplished by the current Owner performing:synchronized(this) { ref = null; }Put (give). Owner y sends Owner x a message containing a reference to Resource r as anargument, after which y no longer has possession of r but x does.xyvoid put(Resource s) {synchronized(this) {ref = s;}}void anAction(Owner x) { //...Resource s;synchronized(this) {s = ref;ref = null;}x.put(s);}Take. Owner y requests a Resource from Owner x , which then sends r as the return value,relinquishing possession.xyResource take() {synchronized(this) {Resource r = ref;ref = null;return r;}}void anAction(Owner x) { //...Resource r = x.take();synchronized(this) {ref = r;}}Exchange. Owner y trades its Resource s for Owner x 's Resource r . This operation can also beused to perform a take via s = exchange(null) , or a put via exchange(r) ,ignoring theresult.xResource exchange(Resource s){synchronized(this) {Resource r = ref;ref = s;return r;}}yvoid anAction(Owner x) { //...synchronized(this) {ref = x.exchange(ref);}}One application of such protocols arises when one object, say an OutputStream , is almostcompletely confined within its host object, but must be used occasionally by other clients. In thesecases, you can allow clients to take the internal object, operate on it, then put it back. In themeantime the host object will be temporarily crippled, but at least you are sure not to encounterintegrity violations.2.3.4.1 RingsIn the general case, resource management may involve maintaining pools (see § 3.4.1), usingmessage-passing networks that adopt particular exchange (see § 3.4.3) or flow (see § 4.2) policies, oradopting protocols that help avoid deadlock and resource exhaustion (see § 4.5.1). But simpler transferprotocols can be used when you just need to ensure that an interconnected group of cooperatingobjects together strictly confines a resource. One way to implement this is to arrange a set of peerobjects in a ring in which each node communicates only with a single neighbor.As an unrealistically simplified example, consider a set of PrintService objects arranged asnodes in a ring, passing around rights to use a Printer . If a node is asked to print but does notcurrently have access, it tries to take it from its neighbor. This request cascades down to a node thathas a printer. Defining the relevant methods as synchronized ensures that nodes do not give upthe printer until they are finished with it. Here is a snapshot of one possible configuration.This design produces the desired effects only if all nodes obey the transfer protocol, the connectionsare set up appropriately, and at least one node has a printer. A sample start-up method shows one wayto establish the required structure. Many additional extensions would be needed to allow dynamicconnections of new PrintService objects, to support more than one Printer , and to dealwith situations in which no Printer at all is available.class Printer {public void printDocument(byte[] doc) { /* ... */ }// ...}class PrintService {protected PrintService neighbor = null; // node to take fromprotected Printer printer = null;public synchronized void print(byte[] doc) {getPrinter().printDocument(doc);}protected Printer getPrinter() {// PRE: synch lock heldif (printer == null) // need to take from neighborprinter = neighbor.takePrinter();return printer;}synchronized Printer takePrinter() { // called from othersif (printer != null) {Printer p = printer; // implement take protocolprinter = null;return p;}elsereturn neighbor.takePrinter(); // propagate}// initialization methods called only during start-upsynchronized void setNeighbor(PrintService n) {neighbor = n;}synchronized void givePrinter(Printer p) {printer = p;}// Sample code to initialize a ring of new servicespublic static void startUpServices(int nServices, Printer p)throws IllegalArgumentException {if (nServices <= 0 || p == null)throw new IllegalArgumentException();PrintService first = new PrintService();PrintService pred = first;for (int i = 1; i < nServices; ++i) {PrintService s = new PrintService();s.setNeighbor(pred);pred = s;}first.setNeighbor(pred);first.givePrinter(p);}}2.3.5 Further ReadingsThe Hermes programming language pioneered several language constructs and techniques forstructuring concurrent and distributed programs, including reference transfer as a primitive. See:Strom, Robert, David Bacon, Arthur Goldberg, Andy Lowry, Daniel Yellin, and Shaula Yemini.Hermes: A Language for Distributed Computing, Prentice Hall, 1991.The Spring operating system interface definition language embedded hand-off policies as argumentqualifiers for methods. See:A Spring Collection, SunSoft Press, 1994.Techniques based on unique references have also played roles in other OO design and analysismethods. See, for example:Hogg, John, Doug Lea, R. C. Holt, Alan Wills, and Dennis de Champeaux. "The Geneva Conventionon the Treatment of Object Aliasing", OOPS Messenger, April 1992.For a formal approach to confinement in distributed systems, see:Cardelli, Luca, and Andrew Gordon. "Mobile Ambients", in Maurice Nivat (ed.), Foundations ofSoftware Science and Computational Structures, Springer LNCS 1378, 1998.2.4 Structuring and Refactoring ClassesIt can be difficult to balance the design forces surrounding exclusive access control during initial classdesign. Most classes used in concurrent programs undergo iterative refactorings to address concernssuch as:•••••Using only a few entry-point locks, as seen in most confinement-based designs, tends to workwell when there are few threads, due to reduced overhead. But performance can quicklydegrade under contention, especially on multiprocessors. When many threads all contend forthe same entry-point lock, most threads will spend most of their time waiting for the lock,increasing latencies and limiting opportunities for parallelism. Most systems evolve to usefiner-granularity locks as they grow. The best known cases are operating systems that onceused a single giant lock as the entry point to a kernel, but increasingly use narrowly-scoped,briefly-held locks, in part for better support of multiprocessing.Using too many locks can add overhead and increase the chances of unanticipated livenessfailures.Using one lock to protect more than one aspect of functionality can result in unnecessarycontention.Holding locks for long periods invites liveness and performance problems, and complicatesexception processing.Locking individual methods does not always maintain intended semantics. For example whentwo related attributes are obtained by calling two different locked accessors, the valuesobtained might not obey intended relationships if a state transition occurs between calls.There is no single optimal strategy. However, several techniques and patterns can be used to providebetter balance among such forces. This section describes strategies for removing unnecessarysynchronization, splitting synchronization to match functionality, exporting read-only operations viaadapters, isolating state representations to reduce access costs or improve potential parallelism, andgrouping objects to use common locks so as to mirror layered designs. While any of these could beused during the initial design of classes, several of them rely on technical manipulations that aredifficult (and sometimes unwise) to exploit during early design efforts.2.4.1 Reducing SynchronizationWhen locking presents liveness or performance problems for a given class or program, usually thebest solution is to refactor the design to use one or more of the other approaches presented in thischapter. However, there are cases where the basic logic of a synchronization-based design can bemaintained even when some of the synchronized method qualifiers or blocks are removed,although sometimes at the expense of weakened semantic guarantees.2.4.1.1 AccessorsSynchronizing a field accessor method sometimes (but by no means always) adds noticeable overheadto programs. Two considerations enter into any decision about whether synchronization of an accessormethod can be removed:Legality. The value of the underlying field never assumes an illegal value; that is, you can ensure thatthe field never, even momentarily, breaks invariants. (This by definition excludes fields of type longand double .)Staleness. Clients do not necessarily require the most recently updated value of a field, but can livewith possibly stale values (see § 2.2.7).If a field is not always legal, then the choices are:•••Synchronize the accessor (as well as all update methods).Ensure somehow that clients realize when they have obtained an illegal value and takeevasive action (for example via double-checks — see § 2.4.1.2).Omit the accessor method. This applies surprisingly often. Ask yourself why any client wouldwant to know the value of a field and what they could do with this value. Because objectattributes can change asynchronously in concurrent programs, a value obtained by a client inone line of code may have changed before the next line of code is executed. Thus, accessormethods are not frequently useful in concurrent programs. Moreover, because they are notfrequently useful, synchronization is unlikely to be a performance concern even if you do notremove the accessor methods in such cases.If a field is always legal but staleness is not acceptable, then you have the additional choice:•Remove synchronization from the accessor, and qualify the instance variable as volatile .However, this works as expected only for scalar types, not references to arrays or Objectsthat help maintain object representations: accessing a volatile reference does notautomatically ensure visibility of the fields or elements accessible from that reference. (In thecase of Object references, you can if necessary further ensure that the accessed fields arethemselves volatile .) The main disadvantage of this approach is that volatiledeclarations impede compiler optimizations of methods using these fields, and so can lead toa net performance loss.If a field is always legal and staleness is acceptable, then you also have the choices:••Remove synchronization from the accessor without any further alteration.If you like to live dangerously, just make the field public .As an example, consider the size() method of the ExpandableArray class (§ 2.2.2), thatreturns the value of the size field. Inspection of all methods reveals that the value of the size fieldis always legal — it never assumes a value outside the range 0..data.length . (This would notbe true if, for example, size were temporarily set to -1 as a resize indicator flag inside the addmethod.) Assuming that this constraint is documented as an internal requirement for all subclasses andfuture modifications, then synchronization can be removed from the accessor.The decision about staleness and need for volatile is a matter of judgment about possible usagecontexts that here interacts with (among other issues) choice of traversal strategies. If clients mainlytraverse elements using indexed loops:for (int i = 0; i < v.size(); ++i)System.out.println(v.get(i));// questionablethen obtaining stale values of size is not likely to be acceptable. For example, a client might obtainthe value zero even when there are many elements in the array, thus skipping the loop entirely. Notethat if the loop ran at all, the synchronization performed in the first invocation of method get wouldforce a fresher value of size to be returned on the second and subsequent calls to size() . (Alsorecall from § 2.2.3 that clients must in any case be prepared for the size to change between the indexcheck and the element access, so this traversal style is problematic at best anyway.)However, if either aggregates or iterators are used, each performing internal synchronization, then youcould make an argument for leaving the size() method unsynchronized and the size field non-volatile, and advertising the method as only a heuristic estimate of the current number of elements.Still, this is unlikely to be acceptable to clients of a general-purpose class such asExpandableArray . But similar reasoning may be invoked when it is acceptable for clients toobtain values that are guaranteed to be only as recent as the last synchronization points of reading andwriting threads.2.4.1.2 Double-checkIf callers of unsynchronized field accessors can somehow realize when they have just read an illegalvalue, they can sometimes take evasive action. One such action is to re-access the field undersynchronization, determine its most current value, and then take appropriate action. This is the essenceof the double-check idiom.Double-check and its variants (including looping versions sometimes called test-and-test-and-set) areseen in latches (see § 3.4.2), spin locks (see § 3.2.6), and caching protocols. But the most commonapplication of double-check is to conditionally relax synchronization surrounding initialization checks.When an uninitialized value (for scalars, a default zero value) is encountered, the accessing methodacquires a lock, rechecks to see if initialization is really necessary (as opposed to having read a stalevalue), and if so performs the initialization while still under the synchronization lock, to preventmultiple instantiations. For example:class AnimationApplet extends Applet {// Fragments// ...int framesPerSecond; // default zero is illegal valuevoid animate() {// ...if (framesPerSecond == 0) { // the unsynchronized checksynchronized(this) {if (framesPerSecond == 0) { // the double-checkString param = getParameter("fps");framesPerSecond = Integer.parseInt(param);}}}}}// ... actions using framesPerSecond ...While there are several legitimate uses, double-check is extremely delicate:••It is generally unwise to use double-check for fields containing references to objects or arrays.Visibility of a reference read without synchronization does not guarantee visibility of non-volatile fields accessible from the reference (see § 2.2.7). Even if such a reference isnon-null, fields accessed via the reference without synchronization may obtain stale values.It is difficult at best to use a single flag field as an indicator that a whole set of fields must beinitialized. The as-if-serial reorderings discussed in § 2.2.7 may cause the flag to be visiblyset before the other fields are visibly initialized.Remedies to both of these problems almost always require some sort of locking. So, theseconsiderations usually lead to avoidance of double-checked lazy initialization, and adoption ofschemes that instead either eagerly initialize or rely on fully synchronized checks (as seen for examplein the Singleton classes in § 2.2.4).However, in a few other cases you may be able to use an even weaker technique, single-check. Here,the check, initialization, and field binding are all performed without synchronization, and thus dependon the vagaries of unsynchronized field access. This opens up the possibility for multipleinstantiations. This is a plausible option only if initialization is side-effect-free and need not otherwiseentail synchronization, and use of multiple threads is rare.2.4.1.3 Open callsAs discussed in § 2.1, a method is stateless if it does not access or rely on any mutable object fields.Methods on fully immutable objects are by necessity stateless, but stateless methods can occur inother kinds of classes as well, for example in purely computational utility methods and during methodinvocations made to acquaintances (as opposed to representational support objects — see § 1.3.1.2).You do not need to synchronize stateless parts of methods. This allows other calls tosynchronized methods to execute during unsynchronized sections, improving performance andreducing lock interference. However, synchronization can be split only when the different parts of themethod are not in any way dependent, so that it is acceptable for other methods to "see" and use theobject before full method completion.To illustrate, consider the following generic server class. If helper.operation takes a longtime, then calls to synchronized methods such as getState might block for an unacceptabletime waiting for the method to be available.class ServerWithStateUpdate {protected double state;protected final Helper helper = new Helper();public synchronized void service() {state = ...; // set to some new valuehelper.operation();}public synchronized double getState() { return state; }}If helper represents some aspect of the host's state, or the call to helper.operation relieson or modifies host state, then the entire service method must employ synchronization. However,if helper.operation is otherwise independent of the host, then the service method can bestructured in the form suggested by the default rules in § 1.1.1.1:••First, update state (holding locks).Then, send messages (without holding locks).Messages sent without holding locks are also known as open calls. As discussed in § 4.1 and § 4.2,classes with methods of this form are among the most well-behaved and readily composablecomponents in concurrent and event-based systems. For example, assuming thathelper.operation meets our criteria, the above class can be rewritten as:class ServerWithOpenCall {protected double state;protected final Helper helper = new Helper();protected synchronized void updateState() {state =...; // set to some new value}public void service() {updateState();helper.operation();}}It is still possible to use open calls here even if the helper reference field is mutable; for example,using block synchronization:class ServerWithAssignableHelper {protected double state;protected Helper helper = new Helper();synchronized void setHelper(Helper h) { helper = h; }public void service() {Helper h;synchronized(this) {state = ...h = helper;}h.operation();}public synchronized void synchedService() { // see belowservice();}}The synchedService method here reveals a weakness in any technique involving open calls.The call to service from within synchedService results in the lock being held throughoutthe duration of service , including the call to h.operation . This defeats the purpose of themethod restructurings. Avoiding such problems requires documentation of the intentional lack ofsynchronization in classes used in concurrent settings.Data structures that are linked via immutable references are often amenable to these kinds ofmanipulations. For example, consider a LinkedCell class in which each cell contains a referenceto a successor cell, and for which we require that successor cell references be fixed upon construction.This is a common requirement for cells serving as Lisp-style lists. Methods and sections of methodssolely involving the successor need not be synchronized, which speeds up traversal. For clarity andemphasis, the methods here use recursion; in practice you would probably use iteration instead:class LinkedCell {protected int value;protected final LinkedCell next;public LinkedCell(int v, LinkedCell t) {value = v;next = t;}public synchronized int value() { return value; }public synchronized void setValue(int v) { value = v; }public int sum() {// add up all element valuesreturn (next == null) ? value() : value() + next.sum();}public boolean includes(int x) { // search for xreturn (value() == x) ? true:(next == null)? false : next.includes(x);}}Again note that an object remains locked when a synchronized method calls an unsynchronizedone. So it would not avoid synchronization to write sum as:synchronized int ineffectivelyUnsynchedSum() {// bad ideareturn value + nextSum();// synch still held on call}int nextSum() { return (next == null)? 0: next.sum(); }2.4.2 Splitting SynchronizationWhen the representations and behavior of one class can be partitioned into independent, non-interacting, or just non-conflicting subsets, it is almost always worth refactoring the class to usedistinct finer-granularity helper objects whose actions are delegated by the host.This rule of thumb holds in object-oriented design generally. But it carries much more force inconcurrent OO programming. A set of synchronized operations might deadlock or present otherliveness or lock-based performance problems if they were all waiting for the single synchronizationlock associated with a single object. But they might be deadlock-free and/or run more efficiently ifthey are waiting on multiple distinct locks. As a general rule, the more finely you can subdivide theinternal synchronization of a given class, the better will be its liveness properties across a wider rangeof contexts. However, this sometimes comes at the expense of greater complexity and potential forerror.2.4.2.1 Splitting classesConsider a simplified Shape class that maintains both location and dimension information, alongwith time-consuming methods adjustLocation and adjustDimensions thatindependently alter them:class Shape {protected doubleprotected doubleprotected doubleprotected doublepublicpublicpublicpublic// Incompletex = 0.0;y = 0.0;width = 0.0;height = 0.0;synchronizedsynchronizedsynchronizedsynchronizeddoubledoubledoubledoublex(){y(){width()height()return x;}return y; }{ return width;}{ return height; }public synchronized void adjustLocation() {x = longCalculation1();y = longCalculation2();}public synchronized void adjustDimensions() {width = longCalculation3();height = longCalculation4();}// ...}Under the assumptions that adjustLocation never deals with dimension information andadjustDimensions never deals with location, better performance could be obtained by revisingthis class so that callers of adjustLocation need not wait for those callingadjustDimensions and vice versa.Splitting classes to reduce granularity is a straightforward exercise in class refactoring:•••Partition some functionality of a Host class into another class, say Helper .In the Host class, declare a final unique field referencing a helper that is initialized to anew Helper in the constructor. (In other words, strictly confine each helper in its host.)In the Host class, forward all appropriate methods to the Helper as open calls, usingunsynchronized methods. This works because the methods are stateless with respect to theHost class.The most extreme result of these steps is a Pass-Through Host design in which all messages arerelayed as open calls via simple unsynchronized methods:For example, here is a pass-through version of the Shape class:class PassThroughShape {protected final AdjustableLoc loc = new AdjustableLoc(0, 0);protected final AdjustableDim dim = new AdjustableDim(0, 0);public double x()public double y() { return loc.x(); }{ return loc.y(); }public double width()public double height() { return dim.width(); }{ return dim.height(); }public void adjustLocation(){ loc.adjust(); }public void adjustDimensions() { dim.adjust(); }}class AdjustableLoc {protected double x;protected double y;public AdjustableLoc(double initX, double initY) {x = initX;y = initY;}public synchronized double x() { return x;}public synchronized double y() { return y; }public synchronized void adjust() {x = longCalculation1();y = longCalculation2();}protected double longCalculation1() { /* ... */ }protected double longCalculation2() { /* ... */ }}class AdjustableDim {protected double width;protected double height;public AdjustableDim(double initW, double initH) {width = initW;height = initH;}public synchronized double width() { return width;}public synchronized double height() { return height; }public synchronized void adjust() {width = longCalculation3();height = longCalculation4();}protected double longCalculation3() {/* ... */}protected double longCalculation4() {/* ... */}}2.4.2.2 Splitting locksEven if you do not want to or cannot split a class, you can still split the synchronization locksassociated with each subset of functionality. This technique is equivalent to one in which you firstsplit a class into helpers and then fold all representations and methods of the helpers except theirsynchronization locks back into the host class. However, there is no need to proceed in exactly thisway.Stripped of all but its synchronization lock, any class is reduced to just java.lang.Object .This fact accounts for the idiomatic practice of using instances of class Object as synchronizationaids.To recover the underlying design whenever you see an Object used for a synchronization lock, youmight ask yourself what kind of helper object a particular lock is a stand-in for. In the case of lock-splitting, each Object controls access to a subset of methods, so each method in each subset isblock-synchronized on a common lock object.The basic steps for splitting locks are similar to those for splitting objects:••For each independent subset of functionality, declare a final object, say lock , initializedin the constructor for the Host class and never reassigned:o The lock object can be of any subclass of class Object . If it will not be used forany other purpose, it might as well be of class Object itself.o If a subset is uniquely associated with some existing object uniquely referenced froma field, you may use that object as the lock.o One of these locks can be associated with the Host object ( this ) itself.Declare all methods corresponding to each subset as unsynchronized, but surround all codewith synchronized(lock) { ... } .Among the applications of lock splitting are fixed-size hash tables, in which each bin of the tablepossesses its own lock. (This strategy cannot easily be applied to dynamically resizable hash tablessuch as those used in java.util.Hashtable , since they cannot rely on immutability of thelock objects.) Lock splitting is also seen in classes that carefully manage waiting and notificationoperations, as discussed in § 3.7.2. For a simpler example, here is a split version of the Shape class:class LockSplitShape {protected double x = 0.0;protected double y = 0.0;protected double width = 0.0;protected double height = 0.0;// Incompleteprotected final Object locationLock = new Object();protected final Object dimensionLock = new Object();public double x() {synchronized(locationLock) {return x;}}public double y() {synchronized(locationLock) {return y;}}public void adjustLocation() {synchronized(locationLock) {x = longCalculation1();y = longCalculation2();}}// and so on}2.4.2.3 Isolating fieldsSome classes manage sets of independent properties and attributes, each of which can be manipulatedin isolation of the others. For example, a Person class may have age , income andisMarried fields that can be changed regardless of any other actions being performed on thePerson object as a whole. The decision about whether this is acceptable of course rests on theintended usage semantics of a given class.You cannot just declare such fields as volatile if you need synchronization protection to avoidconflicts among concurrent attempts to update them. However, you can use a simple form of splittingto offload synchronization protection to objects used solely to protect basic operations on basic types.Such classes play a similar role as classes java.lang.Double and java.lang.Integer ,except that instead of promising immutability, they promise atomicity. For example, you can create aclass such as:class SynchronizedInt {private int value;public SynchronizedInt(int v) { value = v; }public synchronized int get() { return value; }public synchronized int set(int v) { // returns previousvalueint oldValue = value;value = v;return oldValue;}public synchronized int increment() { return ++value; }// and so on}(The util.concurrent package available from the online supplement contains a set of suchclasses, one for each basic type, that also support other utility operations such as the commit methoddescribed in § 2.4.4.2.)These classes could be used, for example, in:class Person {// ...// Fragmentsprotected final SynchronizedInt age = new SynchronizedInt(0);protected final SynchronizedBoolean isMarried =new SynchronizedBoolean(false);protected final SynchronizedDouble income =new SynchronizedDouble(0.0);public int getAge() { return age.get(); }public void birthday() { age.increment(); }// ...}2.4.2.4 Linked data structuresLock-splitting techniques can minimize access contention to objects serving as entry points into linkeddata structures, by finding a middle ground between the extreme strategies of fully synchronizing theentry classes (which can limit concurrency) and fully synchronizing all the linked node objects beingcontrolled (which can be inefficient and can lead to liveness problems).As with all lock-splitting techniques, the main goal is to associate different locks with differentmethods. But in the case of linked structures, this often leads to further adjustments in the datastructures and algorithms themselves. There are no universally applicable recipes for splittingsynchronization in classes controlling access to linked structures, but the following class illustratessome common tactics.The following LinkedQueue class can serve as a generic unbounded first-in-first-out (FIFO)queue. It maintains separate synchronization for put and poll . The putLock lock ensures thatonly one put operation at a time can proceed. The pollLock lock similarly ensures that only onepoll operation at a time can proceed. A head node always exists in this implementation so that aput and a poll can normally proceed independently. After each poll , the previous first nodebecomes the new head. Additionally, the accessed nodes themselves must be locked to preventconflicts when a put and a poll are both simultaneously executing on a queue that was previouslyempty or is about to become empty, in which case head and last both refer to the same headernode.class LinkedQueue {protected Node head = new Node(null);protected Node last = head;protected final Object pollLock = new Object();protected final Object putLock = new Object();public void put(Object x) {Node node = new Node(x);synchronized (putLock) {// insert at end of listsynchronized (last) {last.next = node;// extend listlast = node;}}}public Object poll() {// returns null if emptysynchronized (pollLock) {synchronized (head) {Object x = null;Node first = head.next; // get to first real nodeif (first != null) {x = first.object;first.object = null; // forget old objecthead = first;// first becomes new head}return x;}}}static class Node {Object object;Node next = null;// local node class for queueNode(Object x) { object = x; }}}The online supplement includes queue classes that further refine, extend, and optimize this basicdesign.2.4.3. Read-Only AdaptersIn confinement-based designs (see § 2.3.3), a Host object cannot reveal the identity of any of its Partobjects. This eliminates the choice of returning references to parts in any accessor or propertyinspection method.One alternative is instead to return a copy of the Part. For example, class SynchedPoint (§ 2.3.3)could add a method:public synchronized BarePoint getPoint() {return new BarePoint(delegate.x, delegate.y);}When Parts are instances of classes known to implement an appropriate clone method, you caninstead return part.clone() . And, when you need to return arbitrary sets of values, you can usean ad-hoc array, for example:public synchronized double[] getXY() {return new double[] { delegate.x, delegate.y } ;}However, copying can be too expensive when dealing with some objects, and does not make sensewhen dealing with others; for example, objects that maintain references to files, threads or otherresources that should not themselves be copied. In many cases you can instead selectively permitsome leakage by constructing and returning an Adapter object surrounding the part that exposes onlythose operations that clients may use without introducing any potential interference — generally, read-only operations. Unless these methods deal only with immutable state, they require synchronization.The most secure version of this scheme takes a bit of work to set up:•••Define a base interface describing some non-mutative functionality.Optionally, define a subinterface that supports additional update methods used in the normalmutable implementation class.Define a read-only adapter that forwards only the exported operations. For added security,declare that the immutable class is final . The use of final means that when you thinkyou have an immutable object, you really do — it's not of some subclass that supportsmutable operations as well.These steps can be applied to the following simple Account class. Even though accounts in thisexample are held only by AccountHolders , the general-purpose mutableUpdatableAccount implementation employs synchronization.class InsufficientFunds extends Exception {}interface Account {long balance();}interface UpdatableAccount extends Account {void credit(long amount) throws InsufficientFunds;void debit(long amount) throws InsufficientFunds;}// Sample implementation of updatable versionclass UpdatableAccountImpl implements UpdatableAccount {private long currentBalance;public UpdatableAccountImpl(long initialBalance) {currentBalance = initialBalance;}public synchronized long balance() {return currentBalance;}public synchronized void credit(long amount)throws InsufficientFunds {if (amount >= 0 || currentBalance >= -amount)currentBalance += amount;elsethrow new InsufficientFunds();}public synchronized void debit(long amount)throws InsufficientFunds {credit(-amount);}}final class ImmutableAccount implements Account {private Account delegate;public ImmutableAccount(long initialBalance) {delegate = new UpdatableAccountImpl(initialBalance);}ImmutableAccount(Account acct) { delegate = acct; }public long balance() { // forward the immutable methodreturn delegate.balance();}}These classes could be used, for example, in:class AccountRecorder { // A logging facilitypublic void recordBalance(Account a) {System.out.println(a.balance()); // or record in file}}class AccountHolder {private UpdatableAccount acct = new UpdatableAccountImpl(0);private AccountRecorder recorder;public AccountHolder(AccountRecorder r) {recorder = r;}public synchronized void acceptMoney(long amount) {try {acct.credit(amount);recorder.recordBalance(new ImmutableAccount(acct));//(*)}catch (InsufficientFunds ex) {System.out.println("Cannot accept negative amount.");}}}Use of a read-only wrapper at line (*) might seem an unnecessary precaution. But it guards againstwhat might happen if someone were to write the following subclass and use it in conjunction withAccountHolder :class EvilAccountRecorder extends AccountRecorder {private long embezzlement;// ...public void recordBalance(Account a) {super.recordBalance(a);if (a instanceof UpdatableAccount) {UpdatableAccount u = (UpdatableAccount)a;try {u.debit(10);embezzlement += 10;}catch (InsufficientFunds quietlyignore) {}}}}The java.util.Collection framework uses a variant of this scheme. Rather than declaring aseparate immutable interface, the main Collection interface permits mutative methods to throwUnsupportedOperationExceptions . Anonymous read-only adapter classes throw theseexceptions on all attempted update operations. They can be constructed via, for example:List l = new ArrayList();// ...untrustedObject.use(Collections.unmodifiableList(l));2.4.4 Copy-on-WriteWhen a set of fields comprising the state of an object must maintain a set of interrelated invariants,you can isolate these fields in another object that preserves the intended semantic guarantees.A good way to go about this is to rely on immutable representation objects that at all times maintainconsistent snapshots of legal object states. Relying on immutability eliminates the need to otherwisecoordinate separate readings of related attributes. It also normally eliminates the need to hide theserepresentations from clients.For example, in § 1.1.1.1, we had to take special precautions involving block synchronization in orderto guarantee that consistent (x, y) coordinates of Particles were always displayed correctly. Andthe Shape classes described in § 2.4.2 do not even provide a mechanism for doing this. One solutionis to employ a separate ImmutablePoint class that maintains location information that is at alltimes consistent:class ImmutablePoint {private final int x;private final int y;public ImmutablePoint(int initX, int initY) {x = initX;y = initY;}public int x() { return x; }public int y() { return y; }}ImmutablePoints could be used in the following Dot class that is otherwise similar to theParticle class in § 1.1.1.1. This class illustrates the general techniques surrounding copy-on-writeupdates, in which state changes do not directly update fields, but instead construct and attach newrepresentation objects.Note that synchronization of some form is required here. Even though the point representation objectsare immutable, the loc reference is mutable. While synchronization of the accessor methodlocation might be loosened in accord with the considerations in § 2.4.1, the shiftX methodmust be synchronized (or perhaps otherwise modified) in order to preclude multiple concurrentexecutions in which different versions of loc are obtained when accessing l oc.x() andloc.y() .class Dot {protected ImmutablePoint loc;public Dot(int x, int y) {loc = new ImmutablePoint(x, y);}public synchronized ImmutablePoint location() { return loc; }protected synchronized void updateLoc(ImmutablePoint newLoc){loc = newLoc;}public void moveTo(int x, int y) {updateLoc(new ImmutablePoint(x, y));}public synchronized void shiftX(int delta) {updateLoc(new ImmutablePoint(loc.x() + delta,loc.y()));}}2.4.4.1 Internal copy-on-writeWhen state representations are strictly internal to an object, there is no compelling reason to createnew classes just to enforce immutable access. Copy-on-write can be applied whenever the need toobtain consistent representations quickly and effortlessly overwhelms construction costs. It requires atmost one synchronized operation to access all of the state held by an immutable representation object.Additionally, in some contexts, it is convenient to obtain a single snapshot rather than one that reflectsany state modifications made during the use of that snapshot.For example, copy-on-write collection objects can be very useful for maintaining collections oflisteners in event and multicast frameworks (see § 4.1). Here objects maintain lists of listeners orhandlers that must receive notifications of state changes or other events of interest. These lists rarelychange, but may be traversed very frequently. Also, when objects receiving notifications makechanges in the list of notifyees, they are almost always intended to take effect the next time anotification is issued, not in the current round.While there are other good choices for the underlying data structure (including the special-purposetree-based structure used in java.awt.EventMulticaster , and more elaborate structuresmaintaining edit-records from a common base), an array-based copy-on-write collection class issuitable for most applications. Traversal via iterators is not only fast but also avoidsConcurrentModificationExceptions that can occur in some other approaches totraversal (see § 2.2.3).class CopyOnWriteArrayList {protected Object[] array = new Object[0];// Incompleteprotected synchronized Object[] getArray() { return array; }public synchronized void add(Object element) {int len = array.length;Object[] newArray = new Object[len+1];System.arraycopy(array, 0, newArray, 0, len);newArray[len] = element;array = newArray;}public Iterator iterator() {return new Iterator() {protected final Object[] snapshot = getArray();protected int cursor = 0;public boolean hasNext() {return cursor < snapshot.length;}public Object next() {try {return snapshot[cursor++];}catch (IndexOutOfBoundsException ex) {throw new NoSuchElementException();}}};}}(The util.concurrent package available from the online supplement contains a version of thisclass that conforms to the java.util.List interface.)This class would be horribly inefficient if used in contexts involving frequent modifications of largecollections, but it is well suited for most multicast applications, as illustrated in § 3.5.2 and § 3.6.4.2.4.4.2 Optimistic UpdatesOptimistic updates employ a weaker protocol than other copy-on-write techniques: Rather thanengaging locks for the entire duration of state update methods, they employ synchronization only atthe beginnings and ends of update methods. Typically, each method takes the form:1. Get a copy of the current state representation (while holding a lock).2. Construct a new state representation (without holding any locks).3. Commit to the new state only if the old state has not changed since obtaining it.Optimistic update techniques limit synchronization to very brief intervals — just long enough toaccess and later update state representations. This tends to provide very good performance onmultiprocessors, at least under appropriate usage conditions.The main added requirement here over conventional copy-on-write techniques is dealing with thepossibility that Step 3 will fail because some other thread has independently updated the staterepresentation before the current thread has had a chance to do so. The potential for failure introducestwo concerns (discussed in more detail in § 3.1.1) that limit the range of applicability of optimisticupdate techniques:Failure protocols. The choices are either to retry the entire method sequence or to propagate thefailure back to a client, which can then take evasive action. The most common choice is to retry.However, this can lead to livelock — the optimistic analog of indefinite blocking in which methodscontinuously spin without making any further progress. While the probability of livelock is normallyvanishingly small, the action may never complete and may expend a lot of CPU resources repeatedlyattempting to do so. For this reason, optimistic update techniques are bad choices for classes used incontexts that may encounter massive thread contention of unbounded duration. However, somespecialized wait-free optimistic algorithms have been proven to succeed after a bounded number ofattempts regardless of contention (see Further Readings).Side effects. Because they may fail, the actions performed while constructing new staterepresentations cannot include any irrevocable side effects. For example, they should not write to files,create threads, or draw to GUIs unless these actions can themselves be meaningfully cancelled uponfailure (see § 3.1.2).2.4.4.3 Atomic commitmentThe heart of any optimistic technique is an atomic commitment method that is used instead ofassignment statements. It must conditionally swap in a new state representation only if the existingstate representation is the one expected by the caller. There are many ways to distinguish and trackdifferent state representations, for example, using version numbers, transaction identifiers, timestamps, and signature codes. But it is by far most convenient and most common to simply rely on thereference identity of the state object. Here is a generic example:class Optimistic {// Generic code sketchprivate State state; // reference to representation objectprivate synchronized State getState() { return state; }private synchronized boolean commit(State assumed,State next) {if (state == assumed) {state = next;return true;}elsereturn false;}}There are several common minor variations in how the commit method is defined. For example, theversion usually named compareAndSwap returns the current value, which may be either the newor the old value depending on whether the operation committed successfully. The increasingpopularity of optimistic techniques in systems-level concurrent programming is in part due to (and inpart the cause of) the fact that most modern processors include an efficient built-incompareAndSwap instruction or one of its variants. While these are not directly accessible fromthe Java programming language, it is in principle possible for optimizing compilers to map constructsto use such instructions. (Even if not, optimistic updates are still efficient.)In a purely optimistic class, most update methods take a standard form: getting the initial state,building a new state representation, and then committing if possible, else looping or throwing anexception. However, methods that do not rely on any particular initial states can be written moresimply, unconditionally swapping in the new state. For example, here is an optimistic version of theDot class:class OptimisticDot {protected ImmutablePoint loc;public OptimisticDot(int x, int y) {loc = new ImmutablePoint(x, y);}public synchronized ImmutablePoint location() { return loc; }protected synchronized boolean commit(ImmutablePoint assumed,ImmutablePoint next) {if (loc == assumed) {loc = next;return true;}elsereturn false;}public synchronized void moveTo(int x, int y) {// bypass commit since the operation is unconditionalloc = new ImmutablePoint(x, y);}public void shiftX(int delta) {boolean success = false;do {ImmutablePoint old = location();ImmutablePoint next = new ImmutablePoint(old.x() + delta,old.y());success = commit(old, next);} while (!success);}}If the potential for prolonged interference is a concern, rather than simply spinning, the loop inshiftX can use an exponential back-off scheme as discussed in § 3.1.1.5.2.4.5 Open ContainersOrdered hierarchical locking techniques may be applied when you have a layered containment design(§ 2.3.3) but cannot, or do not want to, strictly hide all of the Part objects from other clients.If Parts are visible to clients, they must employ synchronization. But when these parts frequentlyinvoke methods on other parts, the resulting designs may be prone to deadlock. For example, supposeone thread holds the lock on part1 which in turn makes a call to part2 , while another thread isdoing the opposite:You can eliminate this form of deadlock by using the strategy seen in strict object confinementdesigns: arrange that the Part objects rely on the Host lock for their synchronization control. If clientsmust first obtain the host lock, then this form of deadlock cannot occur:This solution suffices for most containment designs involving visible components (see also § 2.5.1.3for an additional variant). Obtaining outermost locks of containers before operating on parts representsa structured approach to applying the resource-ordering techniques discussed in § 2.2.6. However,without confinement, there is no simple strategy that enforces this solution. Classes (and their authors)must know the rules and stick to them. The main policy choice concerns who should know these rules,the internal parts or the external clients. Neither choice is at all perfect, but one must be adopted:••Internal locking is difficult to retrofit to existing classes and can increase the dependence of aclass on its context.External locking fails if any client forgets to use the protocol.2.4.5.1 Internal disciplinesUnder internal containment locking, each Part uses its container's synchronization lock for all methodsrequiring dynamic exclusion control. In the most efficient case, each Part has a final field that isinitialized upon construction and then used for all locking. Additional unrelated locking inside the Partmethods may also be acceptable (but see § 3.3.4).For example:class Part {// Code sketchprotected final Object lock;// ...public Part(Object owner) { lock = owner; }public Part() { lock = this; } // if no owner, use selfpublic void anAction() {synchronized(lock) {anotherPart.help();// ...}}}As a matter of design policy, you can define most or all classes in this way in order to accommodateusage in various container-based frameworks. However, these designs are more difficult to managewhen the ownership of a Part can change dynamically. In this case you must additionally synchronizeaccess to the lock field itself (normally using synchronized(this) ) before using it to controlaccess to the body of a method.A simpler structure is available when you can arrange that each Part class be declared as an inner classof its Host. In this case, you can use synchronized blocks with Host.this as an argument:class Host {// ...// code sketchclass Part {// ...public void anAction() {synchronized(Host.this) {anotherPart.help();// ...}}}}2.4.5.2 External disciplinesIn the most extreme, unstructured version of external locking, each caller of each method on each Partmust somehow know which lock to acquire before making the call:synchronized(someLock) { aPart.anAction(); }In finite, closed systems, developers can even create a list defining which locks are to be associatedwith which objects and then require code authors to conform to these rules. This tactic can bedefensible for small non-extensible embedded systems that might otherwise be prone to deadlock.However, this solution of course does not scale well. In even slightly larger contexts, client code mustbe able to programmatically determine which lock to use. One way to arrange this is to constructtables that maintain the required associations between objects and locks. A slightly more structuredstrategy is to include in each Part class a method, say getLock , that returns the lock to use forsynchronization control. Clients can then make calls using:synchronized(aPart.getLock()) { aPart.anAction(); }This approach is used in the java.awt package (at least up through release 1.2). Eachjava.awt.Component supports method getTreeLock that returns the lock to be used forcontrolling synchronized operations on the current container (for example, a Frame ). Choice of howand when to use this lock is then left to client code. This introduces opportunities for ad-hocextensibility and can result in minor performance improvements compared to internal lockingdisciplines. For example, a client need not reacquire the lock if it is known to be held already. But thisform of external locking also introduces more opportunities for error, as well as the need for extensivedocumentation — clients must know enough about operations to determine whether and how locksshould be used.2.4.5.3 Multilevel containmentBoth approaches to hierarchical containment locking can be extended past two levels. Each layer ofthe hierarchy must have an associated lock. Code must pass through the locks at all layers, inoutermost-to-innermost order, before invoking update methods. Support for an arbitrary level ofnested locks is exceedingly awkward to set up using synchronized blocks or methods, but maybe approachable using lock utility classes and managers (see § 2.5.1).2.4.6 Further ReadingsA general account of refactoring classes is:Fowler, Martin. Refactoring, Addison-Wesley, 1999.Optimistic update algorithms that can be proven to succeed eventually include the class of wait-freealgorithms in which no thread ever blocks on a condition that can be satisfied only by the action ofsome other thread. In wait-free algorithms, every thread succeeds after a finite number of attempts,regardless of what other threads do or do not do. Most algorithms employ the notion of helping: whena thread cannot continue, it takes some action to help another thread complete its task. The theory ofwait-free algorithms is described in:Herlihy, Maurice. "Wait-free synchronization", ACM Transactions on Programming Languages andSystems, vol. 13, no. 1, 1991.Practical wait-free update algorithms are known for only a small number of common data structures,for example queues and lists. However, these algorithms are increasingly used in underlying run-timesupport in operating system kernels and JVM implementations. The online supplement contains anadaptation of a wait-free queue class described in the following paper, as well as links to descriptionsof wait-free algorithms implemented in other languages.Michael, Maged and Michael Scott. "Simple, fast, and practical non-blocking and blocking concurrentqueue algorithms", Proceedings, 15th ACM Symposium on Principles of Distributed Computing,ACM, 1996.2.5 Using Lock UtilitiesBuilt-in synchronized methods and blocks suffice for many lock-based applications, but theyhave the following limitations:••••There is no way to back off from an attempt to acquire a lock if it is already held, to give upafter waiting for a specified time, or to cancel a lock attempt after an interrupt. This can makeit difficult to recover from liveness problems.There is no way to alter the semantics of a lock, for example with respect to reentrancy, readversus write protection, or fairness.There is no access control for synchronization. Any method can performsynchronized(obj) for any accessible object, thus leading to potential denial-of-service problems caused by the holding of needed locks.Synchronization within methods and blocks limits use to strict block-structured locking. Forexample, you cannot acquire a lock in one method and release it in another.These problems can be overcome by using utility classes to control locking. Such classes can beconstructed using the techniques described in § 3.7. Here, we restrict attention to their use inimplementing lock-based designs. While it is possible to create lock classes providing just about anydesired semantics and usage properties, we illustrate only two common ones, mutual exclusion locksand read-write locks. For the sake of concreteness, presentations rely on the versions of these classesin the util.concurrent package available from the online supplement. However, similarremarks hold for just about any kind of lock utility class that you could construct.All lock-based designs discussed previously in this chapter can, if desired, be re-implemented usinglock utilities rather than built-in synchronized methods and blocks. (Additional examples maybe found in most of the concurrent systems programming texts listed in § 1.2.5.) This section focuseson usages that are otherwise difficult to arrange.The solutions provided by lock utility classes come at the price of more awkward coding idioms andless automatic enforcement of correct usage. Using lock utilities requires more care and disciplinethan typically necessary when using synchronized methods and blocks. These constructionsmay also entail greater overhead since they are less readily optimized than are uses of built-insynchronization.2.5.1 MutexesA Mutex (short for mutual exclusion lock) class can be defined as (omitting implementation code):public class Mutex implements Sync {public void acquire() throws InterruptedException;public void release();public boolean attempt(long msec) throwsInterruptedException;}(In the util.concurrent version, Mutex implements interface Sync , a standardizedinterface for all classes obeying acquire-release protocols.)As you might expect, acquire is analogous to the operations performed on entry into asynchronized block, and release is analogous to the operations performed on exit from ablock. The attempt operation returns true only if the lock is acquired within the specified time(at least to the best of the implementation's ability to measure this time and react in a timely manner— see § 3.2.5). Zero is a legal argument, meaning do not wait at all if the lock is not available.Also, unlike built-in synchronization, the acquire and attempt methods throwInterruptedException if the current thread has been interrupted while trying to obtain thelock. This complicates usage, but makes possible the development of responsive and robust code inthe face of cancellation. The range of reasonable responses to InterruptedException isdiscussed in more detail in § 3.1.2; here we illustrate only the most common options.A Mutex can be used in the same way as a built-in lock by replacing blocks of the form:synchronized(lock) { /* body */ }with the more verbose and awkward before/after construction:try {mutex.acquire();try {/* body */}finally {mutex.release();}}catch (InterruptedException ie) {/* response to thread cancellation during acquire */}Unlike synchronized blocks, locking in standard Mutex classes is non-reentrant. If the lock isheld, even by the thread performing the acquire , the thread will block. While it is possible todefine and use a ReentrantLock as well, a simple Mutex class suffices in many lockingapplications. For example, we can use it to re-implement the Particle class from § 1.1.1.1:class ParticleUsingMutex {protected int x;protected int y;protected final Random rng = new Random();protected final Mutex mutex = new Mutex();public ParticleUsingMutex(int initialX, int initialY) {x = initialX;y = initialY;}public void move() {try {mutex.acquire();try {x += rng.nextInt(10) - 5;y += rng.nextInt(20) - 10;}finally { mutex.release(); }}catch (InterruptedException ie) {Thread.currentThread().interrupt();}}public void draw(Graphics g) {int lx, ly;try {mutex.acquire();try {lx = x; ly = y;}finally { mutex.release(); }}catch (InterruptedException ie) {Thread.currentThread().interrupt();return;}g.drawRect(lx, ly, 10, 10);}}The try/finally constructions surrounding the operation bodies mimic the behavior ofsynchronized blocks in which locks are released no matter how the body exits, even if via anuncaught exception. As a design rule, it is a good idea to use try/finally even if you believethat the body cannot throw any exceptions.The move and draw methods both return immediately without performing any action if the threadwas interrupted during lock acquisition. This is a simple and appropriate response to cancellation.However, as discussed in § 3.1.2, the catch clauses are also obligated to propagate cancellationstatus via Thread.currentThread().interrupt() .The ParticleUsingMutex class is more resistant to hostile denial-of-service attacks than is theoriginal. Since the built-in synchronized lock is not used, it doesn't matter if anyone holds it.(Note, however, that no such problems could occur in ParticleApplet anyway because allreferences are confined to the applet.) If we were even more paranoid, we might declare mutex asprivate . But in most cases, this would needlessly preclude extensibility. Since any plausiblesubclass would also need to access the lock, declaring mutex as private is nearly equivalent todeclaring the class itself as final .2.5.1.1 Method adaptersBetter structure and discipline surrounding locks can be arranged via any of the before/after patternsdiscussed in § 1.4. For example, the use of method adapters supports definition of generic wrappersthat can run any code within any lock. A wrapper can be defined either as method of a class usinglocking or as a separate utility class. An example of the latter is:class WithMutex {private final Mutex mutex;public WithMutex(Mutex m) { mutex = m; }public void perform(Runnable r) throws InterruptedException {mutex.acquire();try { r.run(); }finally { mutex.release(); }}}This could be used by classes that separate out bare actions as internal methods, invoked withinwrappers by public methods, for example:class ParticleUsingWrapper {// Incomplete// ...protected final WithMutex withMutex =new WithMutex(new Mutex());protected void doMove() {x += rng.nextInt(10) - 5;y += rng.nextInt(20) - 10;}public void move() {try {withMutex.perform(new Runnable() {public void run() { doMove(); }});}catch (InterruptedException ie) {Thread.currentThread().interrupt();}}// ...}This design encounters somewhat greater overhead, so it is mainly applicable in classes protectingrelatively time-consuming actions. Also, the illustrated version applies only to internal actions that canbe expressed as argumentless, resultless Runnables . So, for example, it cannot be used with thedraw method. However, this scheme can be extended by defining additional method adapters thataccept other arguments and/or return results, as described in § 1.4.4.2.5.1.2 Back-offsThe attempt method is useful for recovery from deadlocks and other liveness problems involvingmultiple locks. When you cannot ensure that lockups are impossible (as is the case for at least somecomponents in most open systems), you can routinely use attempt instead of acquire ,providing a heuristic time-out value (for example a few seconds) to indicate possible lockups, andthen take evasive action upon failure (see § 3.2.5).The attempt method can also be used in more specialized constructions to deal with particulardeadlock-prone constructions. For example, here is another version of the Cell class from § 2.2.5,that backs out and retries upon discovering a potential deadlock. As a heuristic, it includes a shortdelay between retries. Because it relies on retries, it can livelock. This may be acceptable if you canconvince yourself that the probability of infinite livelock is, say, less than the probability of a randomhardware failure.Note that alias checking is needed here and in all similar constructions involving non-reentrant locksto avoid lockups while trying to re-acquire a lock that is already held (see § 2.2.6).class CellUsingBackoff {private long value;private final Mutex mutex = new Mutex();void swapValue(CellUsingBackoff other) {if (this == other) return;// alias check required herefor (;;) {try {mutex.acquire();try {if (other.mutex.attempt(0)) {try {long t = value;value = other.value;other.value = t;return;}finally {other.mutex.release();}}}finally {mutex.release();};Thread.sleep(100);}catch (InterruptedException ie) {Thread.currentThread().interrupt();return;}}}}2.5.1.3 ReorderingsBack-off techniques may be used as safeguards in designs employing lock ordering techniques (see §2.2.6 and § 2.4.5) in which there are relatively rare exceptions to a given locking hierarchy. In thesecases, code requiring multiple locks can try one ordering, and if it fails, release all locks and try adifferent ordering. This strategy can extend the range of applicability of containment-based lockingschemes. You do not need to be absolutely certain that all locking maintains the desired ordering ifyou can arrange a somewhat more expensive fallback strategy to deal with exceptional cases. Thismight occur, for example, in hierarchical containment designs employing callbacks or collectiontraversals in which it is not possible to ensure conformance to a given set of lock ordering rules.To illustrate basic techniques, here is a Cell class that employs such a deadlock-avoidance shufflefor swapValue . Upon getting stuck, it attempts to lock the two objects from the opposite direction:class CellUsingReorderedBackoff {private long value;private final Mutex mutex = new Mutex();private static boolean trySwap(CellUsingReorderedBackoff a,CellUsingReorderedBackoff b)throws InterruptedException {boolean success = false;}if (a.mutex.attempt(0)) {try {if (b.mutex.attempt(0)) {try {long t = a.value;a.value = b.value;b.value = t;success = true;}finally {b.mutex.release();}}}finally {a.mutex.release();}}return success;void swapValue(CellUsingReorderedBackoff other) {if (this == other) return;// alias check required heretry {while (!trySwap(this, other) &&!trySwap(other, this))Thread.sleep(100);}catch (InterruptedException ex) {Thread.currentThread().interrupt();}}}2.5.1.4 Non-block-structured lockingA Mutex may be used in constructions that cannot be expressed using synchronized blocksbecause the acquire/release pairs do not occur in the same method or code block.For example, you can use a Mutex for hand-over-hand locking (also known as lock coupling) acrossthe nodes of a linked list during traversal. Here, the lock for the next node must be obtained while thelock for the current node is still being held. But after acquiring the next lock, the current lock may bereleased.Hand-over-hand traversal allows extremely fine-grained locking and thus increases potentialconcurrency, but at the cost of additional complexity and overhead that would normally be worthwhileonly in cases of extreme contention.class ListUsingMutex {static class Node {Object item;Node next;Mutex lock = new Mutex(); // each node keeps its own lockNode(Object x, Node n) { item = x; next = n; }}protected Node head; // pointer to first node of list//Use plain synchronization to protect head field.// (We could instead use a Mutex here too but there is no// reason to do so.)protected synchronized Node getHead() { return head; }public synchronized void add(Object x) { // simple prepend// for simplicity here, do not allow null elementsif (x == null) throw new IllegalArgumentException();// The use of synchronized here protects only head field.// The method does not need to wait out other traversers// that have already made it past head node.head = new Node(x, head);}boolean search(Object x) throws InterruptedException {Node p = getHead();if (p == null || x == null) return false;p.lock.acquire();// Prime loop by acquiring first lock.// If above acquire fails due to interrupt, the method will//throw InterruptedException now, so there is no need for//further cleanup.for (;;) {Node nextp = null;boolean found;try {found = x.equals(p.item);if (!found) {nextp = p.next;if (nextp != null) {try {// Acquire next lock//while still holding currentnextp.lock.acquire();}catch (InterruptedException ie) {throw ie;// Note that finally clause will//execute before the throw}}}}finally {// release old lock regardless of outcomep.lock.release();}if (found)return true;else if (nextp == null)return false;else}}p = nextp;// ...}other similar traversal and update methods ...Another application of Mutex that exploits the lack of required block structuring is the constructionof condition variable objects, discussed in § 3.4.4.2.5.1.5 Lock Ordering ManagersWhen multiple locks must be obtained in some particular order, for example in the hierarchicalcontainment schemes discussed in § 2.4.5 and the general resource-ordering techniques discussed in §2.2.6, you can help ensure conformance by centralizing the ordering methods in a lock manager class.There are numerous techniques for structuring the kinds of locks used, defining their ordering rules,and establishing the responsibilities of the manager class. However, nearly any design containsmethods of the following form, which illustrates the care required to ensure that locks will be releasedno matter what exceptions occur:class LockManager {// Code sketch// ...protected void sortLocks(Sync[] locks) { /* ... */ }public void runWithinLocks(Runnable op, Sync[] locks)throws InterruptedException {sortLocks(locks);// for help in recovering from exceptionsint lastlocked = -1;InterruptedException caught = null;try {for (int i = 0; i < locks.length; ++i) {locks[i].acquire();lastLocked = i;}op.run();}catch (InterruptedException ie) {caught = ie;}finally {for (int j = lastlocked; j >= 0; --j)locks[j].release();}if (caught != null)throw caught;}}2.5.2 Read-Write LocksReadWriteLocks maintain a pair of associated locks. One way to define them is:interface ReadWriteLock {Sync readLock();Sync writelock();}The locks returned by the two methods here obey the same Sync interface as Mutex (see § 2.5.1),supporting methods acquire , release , and attempt .As discussed in § 3.3.3, there are a number of ways to implement this interface, depending onselection of the desired policies surrounding their use. For the sake of illustration, we will assumedefinition of a generic implementation class RWLock .The idea behind read-write locks is that the readLock may be held simultaneously by multiplereader threads, so long as there are no writers. The writeLock is exclusive. Read-Write locks aregenerally preferable to plain locks when:•••The methods in a class can be cleanly separated into those that only access (read) internallyheld data and those that modify (write).Reading is not permitted while writing methods are in progress. (If reads are permitted duringwrites, you may instead rely on unsynchronized read methods or copy-on-write updates —see § 2.4.)Target applications generally have more readers than writers.•The methods are relatively time-consuming, so it pays to introduce a bit more overheadassociated with read-write locks compared to simpler techniques in order to allowconcurrency among reader threads.Read-write locks are often used in classes that provide access to large collections of data, wheremethods are structured as:class DataRepository {// Code sketchprotected final ReadWriteLock rw = new RWLock();public void access() throws InterruptedException {rw.readLock().acquire();try {/* read data */}finally {rw.readLock().release();}}public void modify() throws InterruptedException {rw.writeLock().acquire();try {/* write data */}finally {rw.writeLock().release();}}}Read-write locks can be useful in some applications of ordinary collection classes. Theutil.concurrent package available from the online supplement contains a set of adapterclasses that can be used with java.util.Collection classes, placing read-locks aroundpurely inspective methods (such as contains ) and write-locks around update methods (such asadd ).2.5.3 Further ReadingsA set of patterns for using different styles of locks can be found in:McKenney, Paul. "Selecting Locking Primitives for Parallel Programming", Communications of theACM, 39(10): 75-82, 1996.Chapter 3. State DependenceTwo kinds of enabling conditions are generally needed to perform any action:External. An object receives a message requesting that an action be performed.Internal. The object is in an appropriate state to perform the action.As a non-programming example, suppose you are asked to write down a telephone message. To dothis, you need to have a pencil and paper (or some other recording device).Exclusion techniques are mainly concerned with maintaining invariants. State-dependent concurrencycontrol imposes additional concerns surrounding preconditions and postconditions. Actions may havestate-based preconditions that need not always hold when clients invoke methods on the host object.Conversely, actions may have postconditions that are unattainable when the host object is not in aproper state, when the actions of other objects it relies on fail to achieve their own postconditions, orwhen the actions of other threads have changed the states of other objects being relied on.Most design issues for classes with state-dependent actions revolve around the considerationsnecessary to complete a design so that you take into account all possible combinations of messagesand states, as in:phone ringtake messagehave pencilanswer phonewrite messagedo not have pencilanswer phone?As hinted in the table, designs usually need to take into account situations in which the object is not ina state that permits any "normal" action. In an ideal system, all methods would have no state-basedpreconditions and would always fulfill their postconditions. When sensible, classes and methodsshould be written in this fashion, thus avoiding nearly all the issues discussed in this chapter. Butmany activities are intrinsically state-dependent and just cannot be programmed to achievepostconditions in all states.There are two general approaches to the design and implementation of any state-dependent action, thatstem from liveness-first versus safety-first design perspectives:Optimistic try-and-see methods can always be tried when invoked, but do not always succeed, andthus may have to deal with failure.Conservative check-and-act methods refuse to proceed unless preconditions hold. When preconditionsdo hold, the actions always succeed.If methods check neither their preconditions nor their postconditions, they can be called only incontexts in which the preconditions are somehow known to hold. Reliance on such practices inconcurrent systems is problematic at best.Optimistic and conservative approaches are about equally prevalent, and appropriate forms of themmay be equally good or bad with respect to various design forces. But since their general forms aregoverned by issues that may be outside of your control, the two are not always interchangeable.Optimistic approaches rely on the existence of exceptions and related mechanism that indicate whenpostconditions do not hold. Conservative approaches rely on the availability of guard constructionsthat indicate when preconditions hold and guarantee that they continue to hold across the course of anaction relying on them. Mixtures are of course possible and are in fact common. In particular, manyconservative designs contain code that may encounter exceptions, and thus must be prepared to dealwith failure.Concurrency control measures that deal with state-dependent actions can require significant effort andattention in concurrent programming. This chapter divides coverage as follows:•••••••§ 3.1 discusses exceptions and cancellation.§ 3.2 introduces the guard constructions used in conservative designs, along with themechanics used to implement them.§ 3.3 presents structural patterns for classes employing concurrency control.§ 3.4 shows how utility classes can reduce complexity while improving reliability,performance, and flexibility.§ 3.5 extends problems and solutions to deal with joint actions — those depending on thestates of multiple participants.§ 3.6 provides a brief overview of transactional concurrency control.§ 3.7 concludes with some techniques seen in the construction of concurrency control utilityclasses.3.1 Dealing with FailurePure optimistic control designs originate from optimistic update and transaction protocols. Butoptimistic approaches of some sort are seen in just about any code making calls to methods that mayencounter failures. Try-and-see designs attempt actions without first ensuring that they will succeed,often because the constraints that would ensure success cannot be checked. However, optimisticmethods always check postconditions (often by catching failure exceptions) and, if they fail to hold,apply a chosen failure policy.The need for try-and-see approaches usually stems from inability or unwillingness to checkpreconditions and related constraints. This can arise in the following ways:••••Some conditions cannot be computed using the constructs available in a given language orexecution context. For example, it is not possible to check whether a given lock is being heldor a given reference is unique (see § 2.3).In concurrent programs, preconditions may have temporal scopes (in which case they aresometimes called activation constraints). If a constraint is not under the control of the hostobject, then even if it is known to hold momentarily, it need not hold throughout the course ofan action relying on it. For example, your pencil may break while you are writing a message.A file system that is known at entry to a method to have enough space to write a file may runout of space (due to the actions of other independent programs) before the method finisheswriting the file. Similarly, the fact that a given remote machine is currently available saysnothing about whether it will crash or become unreachable in the course of a method relyingon it.Some conditions change due to the signaling actions of other threads. The most commonexample is cancellation status, which may asynchronously become true while any thread isperforming any action (see § 3.1.2).Some constraints are too computationally expensive to check, for example a requirement thata matrix be normalized in upper-triangular form. When actions are simple and easy to undo orthe chances of failure are extremely low, it might not be worth computing even simplepreconditions, instead relying on fallback strategies upon later detection of failure.In all these cases, the lack of provisions that would ensure success forces methods to detect and dealwith potential failures to achieve postconditions.3.1.1 ExceptionsAccommodations for failure infiltrate the design of multithreaded programs. Concurrency introducesthe possibility that one part of a program will fail while others continue. But without care, a failingaction may leave objects in states such that other threads cannot succeed.Methods may throw exceptions (as well as set status indicators or issue notifications) when they havedetected that their intended effects or postconditions cannot be attained. There are six generalresponses to such failed actions: abrupt termination, continuation (ignoring failures), rollback, roll-forward, retry, and delegation to handlers. Abrupt termination and continuation are the two mostextreme responses. Rollback and roll-forward are intermediate options that ensure that objectsmaintain consistent states. Retries locally contain failure points. Delegation allows cooperativeresponses to failure across objects and activities.Choices among these options must be agreed upon and advertised. It is sometimes possible to supportmultiple policies and let client code decide which one to use — for example via dialogs asking userswhether to retry reading from a disk. Additional examples of these options are illustrated throughoutthis book.3.1.1.1 Abrupt terminationAn extreme response to failure is to let a method die immediately, returning (usually via an exception)regardless of the state of the current object or status of the current activity. This may apply if you arecertain that local failure forces failure of the entire activity and that the objects engaged in the activitywill never be used again (for example if they are completely confined within a session — see § 2.3.1).For example, this might be the case in a file-conversion component that fails to open the file to beconverted.Abrupt termination is also the default strategy for uncaught (and undeclared)RuntimeExceptions , such as NullPointerException , that most often indicateprogramming errors. When a normally recoverable failure cannot be dealt with, you can force moreextreme responses by escalating it to a throw of a RuntimeException or Error .Short of full program termination (via System.exit ), options for further recovery from sucherrors are often very limited. When objects are intrinsically shared across activities, and there is noway to re-establish consistent object states upon failure, and there is no possible (or practical) way toback out of a failing operation, then the only recourse is to set a broken or corrupted flag inthe object encountering the failure and then abruptly terminate. Such a flag should cause all futureoperations to fail until the object is somehow repaired, perhaps via the actions of an error handlerobject.3.1.1.2 ContinuationIf a failed invocation has no bearing on either the state of the caller object or the overall functionalityrequirements of the current activity, then it may be acceptable just to ignore the exception andcontinue forward. While it is ordinarily too irresponsible to contemplate, this option may apply inevent frameworks and oneway messaging protocols (see § 4.1). For example, a failed invocation of achange-notification method on a listener object might at worst cause some parts of an animationsequence to be skipped, without any other long-term consequences.Continuation policies are also seen within other error handlers (and inside most finally clauses)that ignore other incidental exceptions occurring while they are trying to deal with the failure thattriggered them, for example ignoring exceptions while closing files. They may also be used in threadsthat should never shut down, and thus try their best to continue in the face of exceptions.3.1.1.3 RollbackThe most desirable semantics in optimistic designs are clean-fail guarantees: Either the operationsucceeds completely, or it fails in a way that leaves the object in exactly the same state as before theoperation was attempted. The optimistic update techniques in § 2.4.4.2 demonstrate one form of thisapproach in which the success criterion is lack of interference by other threads trying to performupdates.There are two complementary styles for maintaining state representations that can be used inrollbacks:Provisional action. Before attempting updates, construct a new representation that will, upon success,be swapped in as the current state. Methods perform updates on the tentative new version of the staterepresentations, but do not commit to the new version until success is assured. This way, nothingneeds to be undone upon failure.Checkpointing. Before attempting updates, record the current state of the object in a history variable,perhaps in the form of a Memento (see the Design Patterns book). Methods directly perform updateson the current representation. But upon failure, fields can be reverted to the old values.Provisional action is usually necessary when actions are not otherwise fully synchronized. Provisionalaction eliminates the possibility that other threads will see inconsistent, partially updatedrepresentations. It is also more efficient when reads are much more common than writes.Checkpointing is usually simpler to arrange and is thus often preferable in other situations. In eitherapproach, it is not always necessary to create new representation objects to record state: often, a fewextra fields in the object, or local variables inside the methods, suffice.Situation-specific rollback techniques are needed for actions other than state updates that must beundone upon failure, including actions resulting from sending other messages. Every message sentwithin such a method should have an inverse antimessage. For example, a credit operation mightbe undone via debit . This idea can be extended to maintaining undo-lists associated with sequencesof actions, in order to allow rollback to any given point.Some kinds of operations can neither be provisionally attempted nor undone via antimessages, andthus cannot employ rollback techniques. This rules out methods with externally visible effects thatirrevocably change the real world by performing IO or actuating physical devices unless it is possibleto undo the actions without harm. In the case of IO, conventions can be adopted to allow theconceptual equivalent of rollback. For example, if methods log actions in a log file and the log filesupports a "please disregard log entry XYZ" option, then this can be invoked in case of failure.However, as discussed further in § 3.1.2.2, rollback of most IO objects (such as InputStreams )themselves is typically not possible. There are no control methods to revert the internal buffers orother fields of most IO objects back to the values they held at some arbitrary point. Typically, the bestyou can do is close the IO objects and construct new ones bound to the same files, devices, or networkconnections.3.1.1.4 Roll-forwardWhen rollback is impossible or undesirable but full continuation is also impossible, you may insteadpush ahead as conservatively as possible to re-establish some guaranteed legal, consistent state thatmay be different from the one holding upon entry to the method. Roll-forward (sometimes knownsimply as recovery) is often perfectly acceptable as far as other objects, methods, and threads areconcerned; in many cases, they cannot even distinguish it from rollback.Some such actions may be placed in finally clauses that perform minimal cleanup (for exampleclosing files, cancelling other activities) necessary to reach safe points of program execution. Mostroll-forward techniques otherwise take forms similar to rollback techniques. But because they do notrequire full representations of saved or provisional state, they are usually slightly easier to arrange.Some methods can be divided into two conceptual parts: a preliminary part that can roll back easily(for example, by either returning or rethrowing the exception immediately), and the part occurringafter a point of no return, at which some unrecoverable action has already begun, that must beadvanced to a safe point even upon failure. For example, a method may reach a point in a protocol atwhich an acknowledgment must be sent or received (see § 3.4.1.4).3.1.1.5 RetryYou can contain local failure to the current method, rather than throwing exceptions back to clients, ifyou have reason to believe that retrying an action will succeed. Retries are in general only possiblewhen local rollback options can be applied, so that the state of the object and status of the activityremain the same at the beginning of each retry attempt.Retry-based tactics may be used when failure is due to other independent objects that may have beenin temporarily bad or undesired states; for example, when dealing with IO devices and remotemachines. As seen in § 2.4.4.2, optimistic state update methods also typically rely on retries, sinceinterference patterns are extremely unlikely to persist indefinitely. Retries are also common in pollingdesigns, for example those discussed in § 4.1.5. Variants of retries are seen in cascading algorithmsthat first try the most desirable of several alternative actions, and if that fails, try a series of lessdesirable alternatives until one succeeds.Without care, retries can consume unbounded amounts of CPU time (see § 3.2.6). You can minimizethe likelihood of repeated contention-based failures, as well as reduce CPU wastage, by insertingheuristic delays between attempts. One popular strategy (seen for example in Ethernet protocols) isexponential backoff, in which each delay is proportionally longer than the last one.For example, you could use the following method to connect to a server that sometimes refusesconnections because it is overloaded. The retry loop backs off for a longer time after each failure.However, it fails upon thread interruption (see § 3.1.2) since there is no point in continuing if thecurrent thread has been cancelled. (As noted in § 3.1.2.2, on some releases of JDK, you may need tomodify this to catch InterruptedIOException and rethrowInterrruptedException .)class ClientUsingSocket {// Code sketch// ...Socket retryUntilConnected() throws InterruptedException {// first delay is randomly chosen between 5 and 10secslong delayTime = 5000 + (long)(Math.random() * 5000);}for (;;) {try {return new Socket(server, portnumber);}catch (IOException ex) {Thread.sleep(delayTime);delayTime = delayTime * 3 / 2 + 1; // increase 50%}}}3.1.1.6 HandlersCalls, callbacks, or notifications to error-handling objects can be useful when you need to offloaderror processing operations to centralized handlers because an exception in one thread or one part of asystem requires compensating actions in other threads or other parts of a system that wouldn'totherwise be known to the method catching the exception. They can also be used to make code moreextensible and more resilient when used by clients that cannot be expected to know how to respond tofailures. However, some care is needed when replacing exceptions with callbacks, events, and relatednotification techniques. When they escape the stack-based flow-of-control rules of exceptions, theiruse can make it more difficult to predict and manage responses to failure across different parts of asystem.One way to set up a handler is to create a before/after class (see § 1.4) that deals with exceptions as itsafter-action. For example, suppose you have an interface describing a service that can throw aServiceException , and an interface describing handlers for the resulting exceptions.Implementations of ServiceExceptionHandler serve here as Strategy objects, as discussedin the Design Patterns book. You can then make a proxy for use by clients that do not handleServiceException themselves. For example:interface ServerWithException {void service() throws ServiceException;}interface ServiceExceptionHandler {void handle(ServiceException e);}class HandledService implements ServerWithException {final ServerWithException server = new ServerImpl();final ServiceExceptionHandler handler = new HandlerImpl();public void service() { // no throw clausetry {server.service();}catch (ServiceException e) {handler.handle(e);}}}Note that while it is legal to declare that HandledService implementsServerWithException , all usages that rely on handlers would need to be statically typed touse HandledService , not the generic ServerWithException type.A handler object can perform any action that any code in a catch clause can, including shuttingdown processing in one or more threads or starting up other cleanup threads. The handler call can alsosomehow communicate the problem to error handling facilities occurring in a different thread, engagein some interactive protocol, rethrow the exception as a RuntimeException or Error , wrap itin an InvocationTargetException to indicate cascaded failures (see § 4.3.3.1), and so on.You can set up services in which clients always use handlers by supplying callback arguments toservice methods. Callback-based handling may also apply when the service itself does not even knowwhich exception it should throw upon failure. This can be set up via:interface ServerUsingCallback {void anotherservice(ServiceFailureHandler handler);}Here all callers must supply a callback target (which may just be themselves) to be invoked inexceptional situations. Further details, alternatives, and variants are discussed in § 4.3.1.Handlers may also be used when converting one style of messaging protocol to another (see § 4.1.1).For example, when using event-based frameworks, a service may generate and issue a newExceptionEvent that is processed by an ExceptionEventListener . The followingServiceIssuingExceptionEvent class shows one way to set this up. It uses theCopyOnWriteArrayList from § 2.4.4 for managing lists of handlers. Alternatively, the eventscould be issued asynchronously (see § 4.1).class ExceptionEvent extends java.util.EventObject {public final Throwable theException;public ExceptionEvent(Object src, Throwable ex) {super(src);theException = ex;}}class ExceptionEventListener {// Incompletepublic void exceptionOccured(ExceptionEvent ee) {// ... respond to exception...}}class ServiceIssuingExceptionEvent {// Incomplete// ...private final CopyOnWriteArrayList handlers =new CopyOnWriteArrayList();public void addHandler(ExceptionEventListener h) {handlers.add(h);}public void service() {// ...if ( /* failed */ ) {Throwable ex = new ServiceException();ExceptionEvent ee = new ExceptionEvent(this, ex);for (Iterator it = handlers.iterator(); it.hasNext();) {ExceptionEventListener l =(ExceptionEventListener)(it.next());l.exceptionOccured(ee);}}}}An inverse style of conversion, of events to exceptions, is used in the java.beans package, asdescribed in § 3.6.4.3.1.2 CancellationWhen activities in one thread fail or change course, it may be necessary or desirable to cancelactivities in other threads, regardless of what they are doing. Cancellation requests introduceinherently unforeseeable failure conditions for running threads. The asynchronous nature ofcancellation [1] leads to design tactics reminiscent of those in distributed systems where failures mayoccur at any time due to crashes and disconnections. Concurrent programs have the additionalobligation to ensure consistent states of internal objects participating in other threads.[1]The two-l spelling of cancellation seems to be most common in concurrent programming.Cancellation is a natural occurrence in most multithreaded programs, seen in:••••Nearly any activity associated with a GUI CANCEL button.Media presentations (for example animation loops) associated with normally terminatingactivities.Threads that produce results that are no longer needed. For example, when multiple threadsare used to search a database, once one thread returns an answer, the others may be cancelled.Sets of activities that cannot continue because one or more of them encounter unexpectederrors or exceptions.3.1.2.1 InterruptionThe best-supported techniques for approaching cancellation rely on per-thread interruption [2] statusthat is set by method Thread.interrupt , inspected by Thread.isInterrupted ,cleared (and inspected) by Thread.interrupted , and sometimes responded to by throwingInterruptedException .[2]Interruption facilities were not supported in JDK 1.0. Changes in policies and mechanisms across releasesaccount for some of the irregularities in cancellation support.Thread interrupts serve as requests that activities be cancelled. Nothing stops anyone from usinginterrupts for other purposes, but this is the intended convention. Interrupt-based cancellation relies ona protocol between cancellers and cancellees to ensure that objects that might be used across multiplethreads do not become damaged when cancelled threads terminate. Most (ideally all) classes in thejava.* packages conform to this protocol.In almost all circumstances, cancelling the activity associated with a thread should cause the thread toterminate. But there is nothing about interrupt that forces immediate termination. This gives anyinterrupted thread a chance to clean up before dying, but also imposes obligations for code to checkinterruption status and take appropriate action on a timely basis.This ability to postpone or even ignore cancellation requests provides a mechanism for writing codethat is both very responsive and very robust. Lack of interruption may be used as a preconditionchecked at safe points before doing anything that would be difficult or impossible to undo later. Therange of available responses includes most of the options discussed in § 3.1.1:•••Continuation (ignoring or clearing interruptions) may apply to threads that are intended not toterminate; for example, those that perform database management services essential to aprogram's basic functionality. Upon interrupt, the particular task being performed by thethread can be aborted, allowing the thread to continue to process other tasks. However, evenhere, it can be more manageable instead to replace the thread with a fresh one starting off in aknown good initial state.Abrupt termination (for example throwing Error ) generally applies to threads that provideisolated services that do not require any cleanup beyond that provided in a finally clauseat the base of a run method. However, when threads are performing services relied on byother threads (see § 4.3), they should also somehow alert them or set status indicators.(Exceptions themselves are not automatically propagated across threads.)Rollback or roll-forward techniques must be applied in threads using objects that are alsorelied on by other threads.You can control how responsive your code is to interrupts in part by deciding how often to checkstatus via Thread.currentThread().isInterrupted() . Checks need not occurespecially frequently to be effective. For example, if it takes on the order of 10,000 instructions toperform all the actions associated with the cancellation and you check for cancellation about every10,000 instructions, then on average, it would take 15,000 instructions total from cancellation requestto shutdown. So long as it is not actually dangerous to continue activities, this order of magnitudesuffices for the majority of applications. Typically, such reasoning leads you to place interrupt-detection code at only at those program points where it is both most convenient and most important tocheck cancellation. In performance-critical applications, it may be worthwhile to construct analyticmodels or collect empirical measurements to determine more accurately the best trade-offs betweenresponsiveness and throughput (see also § 4.4.1.7).Checks for interruption are performed automatically within Object.wait Thread.join ,Thread.sleep , and their derivatives. These methods abort upon interrupt by throwingInterruptedException , allowing threads to wake up and apply cancellation code.By convention, interruption status is cleared when InterruptedException is thrown. This issometimes necessary to support clean-up efforts, but it can also be the source of error and confusion.When you need to propagate interruption status after handling an InterruptedException ,you must either rethrow the exception or reset the status viaThread.currentThread().interrupt() . If code in threads you create calls other codethat does not properly preserve interruption status (for example, ignoringInterruptedException without resetting status), you may be able to circumvent problems bymaintaining a field that remembers cancellation status, setting it whenever calling interrupt andchecking it upon return from these problematic calls.There are two situations in which threads remain dormant without being able to check interruptionstatus or receive InterruptedException : blocking on synchronized locks and on IO. Threadsdo not respond to interrupts while waiting for a lock used in a synchronized method or block.However, as discussed in § 2.5, lock utility classes can be used when you need to drastically reducethe possibility of getting stuck waiting for locks during cancellation. Code using lock classesdormantly blocks only to access the lock objects themselves, but not the code they protect. Theseblockages are intrinsically very brief (although times cannot be strictly guaranteed).3.1.2.2 IO and resource revocationSome IO support classes (notably java.net.Socket and related classes) provide optionalmeans to time out on blocked reads, in which case you can check for interruption on time-out.An alternative approach is adopted in other java.io classes — a particular form of resourcerevocation. If one thread performs s.close() on an IO object (for example, an InputStream )s , then any other thread attempting to use s (for example, s.read() ) will receive anIOException . Revocation affects all threads using the closed IO objects and causes the IO objectsto be unusable. If necessary, new IO objects can be created to replace them.This ties in well with other uses of resource revocation (for example, for security purposes). Thepolicy also protects applications from having a possibly shared IO object automatically renderedunusable by the act of cancelling only one of the threads using it. Most classes in java.io do not,and cannot, clean-fail upon IO exceptions. For example, if a low-level IO exception occurs in themidst of a StreamTokenizer or ObjectInputStream operation, there is no sensiblerecovery action that will preserve the intended guarantees. So, as a matter of policy, JVMs do notautomatically interrupt IO operations.This imposes an additional obligation on code dealing with cancellation. If a thread may beperforming IO, any attempt to cancel it in the midst of IO operations must be aware of the IO objectbeing used and must be willing to close the IO object. If this is acceptable, you may instigatecancellation by both closing the IO object and interrupting the thread. For example:class CancellableReader {// Incompleteprivate Thread readerThread; // only one at a time supportedprivate FileInputStream dataFile;public synchronized void startReaderThread()throws IllegalStateException, FileNotFoundException {if (readerThread != null) throw newIllegalStateException();dataFile = new FileInputStream("data");readerThread = new Thread(new Runnable() {public void run() { doRead(); }});readerThread.start();}protected synchronized void closeFile() { // utility methodif (dataFile != null) {try { dataFile.close(); }catch (IOException ignore) {}dataFile = null;}}protected void doRead() {try {while (!Thread.interrupted()) {try {int c = dataFile.read();if (c == -1) break;else process(c);}catch (IOException ex) {break; // perhaps first do other cleanup}}}finally {closeFile();synchronized(this) { readerThread = null; }}}}public synchronized void cancelReaderThread() {if (readerThread != null) readerThread.interrupt();closeFile();}Most other cases [3] of cancelled IO arise from the need to interrupt threads waiting for input that yousomehow know will not arrive, or will not arrive in time to do anything about. With most socket-basedstreams, you can manage this by setting socket time-out parameters. With others, you can rely onInputStream.available , and hand-craft your own timed polling loop to avoid blocking inIO during a time-out (see § 4.1.5). These constructions can use a timed back-off retry protocol similarto the one described in § 3.1.1.5. For example:[3]Some JDK releases also supported InterruptedIOException , but it was only partiallyimplemented, and only on some platforms. As of this writing, future releases are projected to discontinuesupport, due in part to its undesirable consequence of rendering IO objects unusable. But sinceInterruptedIOException was defined as a subclass of IOException , the constructionshere work approximately as described on releases that include InterruptedIOExceptionsupport, although with an additional uncertainty: An interrupt may show up as either anInterruptedIOException or InterruptedException . One partial solution is to catchInterruptedIOException and then rethrow it as InterruptedException .class ReaderWithTimeout {// Generic code sketch// ...void attemptRead(InputStream stream, long timeout) throws...{long startTime = System.currentTimeMillis();try {for (;;) {if (stream.available() > 0) {int c = stream.read();if (c != -1) process(c);else break; // eof}else {try {Thread.sleep(100); // arbitrary fixed back-off time}catch (InterruptedException ie) {/* ... quietly wrap up and return ... */}long now = System.currentTimeMillis();if (now - startTime >= timeout) {/* ... fail ...*/}}}}catch (IOException ex) { /* ... fail ... */ }}}3.1.2.3 Asynchronous terminationThe stop method was originally included in class Thread , but its use has since been deprecated.Thread.stop causes a thread to abruptly throw a ThreadDeath exception regardless of whatit is doing. (Like interrupt , stop does not abort waits for locks or IO. But, unlikeinterrupt , it is not strictly guaranteed to abort wait , sleep , or join .)This can be an arbitrarily dangerous operation. Because Thread.stop generates asynchronoussignals, activities can be terminated while they are in the midst of operations or code segments thatabsolutely must roll back or roll forward for the sake of program safety and object consistency. For abare generic example, consider:class C {private int v;// Fragments// invariant: v >= 0synchronized void f() {v = -1 ; // temporarily set to illegal value as flagcompute(); // possible stop point (*)v = 1;// set to legal value}synchronized void g() {while (v != 0) {--v;something();}}}If a Thread.stop happens to cause termination at line (*) , then the object will be broken: Uponthread termination, it will remain in an inconsistent state because variable v is set to an illegal value.Any calls on the object from other threads might make it perform undesired or dangerous actions. Forexample, here the loop in method g will spin 2*Integer.MAX_VALUE times as v wraps aroundthe negatives.The use of stop makes it extremely difficult to apply rollback or roll-forward recovery techniques.At first glance, this problem might not seem so serious — after all, any uncaught exception thrown bythe call to compute would also corrupt state. However, the effects of Thread.stop are moreinsidious since there is nothing you can do in these methods that would eliminate theThreadDeath exception (thrown by Thread.stop ) while still propagating cancellationrequests. Further, unless you place a catch(ThreadDeath) after every line of code, you cannotreconstruct the current object state precisely enough to recover, and so you may encounter undetectedcorruption. In contrast, you can usually bullet-proof code to eliminate or deal with other kinds of run-time exceptions without such heroic efforts.In other words, the reason for deprecating Thread.stop was not to fix its faulty logic, but tocorrect for misjudgments about its utility. It is humanly impossible to write all methods in ways thatallow a cancellation exception to occur at every bytecode. (This fact is well known to developers oflow-level operating system code. Programming even those few, very short routines that must beasynch-cancel-safe can be a major undertaking.)Note that any executing method is allowed to catch and then ignore the ThreadDeathexception thrown by stop . Thus, stop is no more guaranteed to terminate a thread than isinterrupt , it is merely more dangerous. Any use of stop implicitly reflects an assessment thatthe potential damage of attempting to abruptly terminate an activity is less than the potential damageof not doing so.3.1.2.4 Resource controlCancellation may play a part in the design of any system that loads and executes foreign code.Attempts to cancel code that does not conform to standard protocols face a difficult problem. The codemay just ignore all interrupts, and even catch and discard ThreadDeath exceptions, in which caseinvocations of Thread.interrupt and Thread.stop will have no effect.You cannot control exactly what foreign code does or how long it does it. But you can and shouldapply standard security measures to limit undesirable effects. One approach is to create and use aSecurityManager and related classes that deny all checked resource requests when a thread hasrun too long. (Details go beyond the scope of this book; see Further Readings.) This form of resourcedenial, in conjunction with resource revocation strategies discussed in § 3.1.2.2 can together preventforeign code from taking any actions that might otherwise contend for resources with other threadsthat should continue. As a byproduct, these measures often eventually cause threads to fail due toexceptions.Additionally, you can minimize contention for CPU resources by invokingsetPriority(Thread.MIN_PRIORITY) for a thread. A SecurityManager may beused to prevent the thread from re-raising its priority.3.1.2.5 Multiphase cancellationSometimes, even ordinary code must be cancelled with more extreme prejudice than you wouldordinarily like. To deal with such possibilities, you can set up a generic multiphase cancellationfacility that tries to cancel tasks in the least disruptive manner possible and, if they do not terminatesoon, tries a more disruptive technique.Multiphase cancellation is a pattern seen at the process level in most operating systems. For example,it is used in Unix shutdowns, which first try to terminate tasks using kill -1 , followed if necessaryby kill -9 . An analogous strategy is used by the task managers in most window systems.Here is a sketch of sample version. (More details on the use of Thread.join seen here may befound in § 4.3.2.)class Terminator {// Try to kill; return true if known to be deadstatic boolean terminate(Thread t, long maxWaitToDie) {if (!t.isAlive()) return true;// already dead// phase 1 -- graceful cancellationt.interrupt();try { t.join(maxWaitToDie); }catch(InterruptedException e){} //if (!t.isAlive()) return true;ignore// success// phase 2 -- trap all security checkstheSecurityMgr.denyAllChecksFor(t); // a made-up methodtry { t.join(maxWaitToDie); }catch(InterruptedException ex) {}if (!t.isAlive()) return true;// phase 3 -- minimize damaget.setPriority(Thread.MIN_PRIORITY);return false;}}Notice here that the terminate method itself ignores interrupts. This reflects the policy choice thatcancellation attempts must continue once they have begun. Cancelling a cancellation otherwise invitesproblems in dealing with code that has already started termination-related cleanup.Because of variations in the behavior of Thread.isAlive on different JVM implementations(see § 1.1.2), it is possible for this method to return true before all traces of the killed thread havedisappeared.3.1.3 Further ReadingsA pattern-based account of exception handling may be found in:Renzel, Klaus. "Error Detection", in Frank Buschmann and Dirk Riehle (eds.) Proceedings of the 1997European Pattern Languages of Programming Conference, Irsee, Germany, Siemens TechnicalReport 120/SW1/FB, 1997.Some low-level techniques for protecting code from asynchronous cancellation or interruption (e.g.,masking hardware interrupts) are not available or appropriate in the Java programming language. Buteven many systems-level developers avoid asynchronous cancellation at all costs. See for exampleButenhof's book listed in § 1.2.5. Similar concerns are expressed about concurrent object-orientedprograms in:Fleiner, Claudio, Jerry Feldman, and David Stoutamire. "Killing Threads Considered Dangerous",Proceedings of the POOMA '96 Conference, 1996.Detecting and responding to termination of a group of threads can require more complex protocolswhen applied in less structured contexts than seen in most concurrent programs. General-purposetermination detection algorithms are discussed in several of the sources on concurrent and distributedprogramming listed in § 1.2.5.Security management is described in:Gong, Li. Inside JavaTM 2 Platform Security, Addison-Wesley, 1999.A resource control framework is described in:Czajkowski, Grzegorz, and Thorsten von Eicken. "JRes: A Resource Accounting Interface for Java",Proceedings of 1998 ACM OOPSLA Conference, ACM, 1998.3.2 Guarded MethodsConservative check-and-act methods refuse to perform actions unless they can ensure that theseactions will succeed, in part by first checking their preconditions. The three basic flavors reflect policydecisions surrounding failed preconditions:Balking. Throwing an exception if the precondition fails. The exceptions thrown are conceptuallydifferent from those seen in optimistic methods: here, an exception indicates refusal, not failure. Butthese exceptions usually have the same consequences to clients.Guarded suspension. Suspending the current method invocation (and its associated thread) until theprecondition becomes true.Time-outs. The range of cases falling between balking and suspension, where an upper bound isplaced on how long to wait for the precondition to become true.There is no universally best policy choice among these options. As illustrated in § 3.4.1, it is oftenpossible to create multiple methods that support multiple policies among which clients may choose.Balking is common in both sequential and concurrent programs. Refusal is the only sensible strategywhen there is no reason to believe that a precondition will ever become true if it is not true already.For example, Thread.start throws IllegalThreadStateException if a thread isalready started (see § 1.1.2), since it can never again enter an unstarted state once started. Refusal isalso the best choice for nearly all argument-based preconditions. For example, a graphics methodmight throw an IllegalArgumentException when asked to draw something with a negativesize. Balking is also useful whenever a method is intended to have now-or-never semantics associatedwith the availability of resources. When refusal is not considered to be exceptional, a balking methodneed not throw an exception. This is seen for example in the ParticleApplet.stop method in§ 1.1.1.3, that quietly ignores attempts to stop the applet if it is not running.3.2.1 Guarded SuspensionGuarded suspension and time-outs have no analog in sequential programs, but play central roles inconcurrent software. This is reflected in the wide range of approaches to conceptualizing guards andin the many different notations and constructs available for designing concurrent software usingguards. Before delving into implementation matters, it is worth stepping back to consider higher-levelapproaches and constructs that help organize designs relying on guarded suspension.As fodder, consider the following toy BoundedCounter example, expressed for now only as aninterface. The idea here is that implementations of BoundedCounter are obligated to maintain acount between MIN and MAX :interface BoundedCounter {static final long MIN = 0; // minimum allowed valuestatic final long MAX = 10; // maximum allowed valuelong count(); // INV: MIN <= count() <= MAX// INIT: count() == MINvoid inc(); // only allowed when count() < MAXvoid dec(); // only allowed when count() > MIN}3.2.1.1 GuardsIn one sense, guarded methods are customizable extensions of synchronized methods, providingextended forms of exclusion. The "guard" for a plain synchronized method is just that an object is inthe Ready execution state; i.e., is not engaged in any activity. At the implementation level, this meansthat the current thread is in possession of the object's synchronization lock. Guarded methods furtherpartition the Ready state by adding state-based conditions (for example that count() < MAX ) thatare logically necessary for an action to proceed.Guards may also be considered as special forms of conditionals. In sequential programs, an ifstatement can check whether a condition holds upon entry to a method. When the condition is false,there is no point in waiting for it to be true; it can never become true since no other concurrentactivities could cause the condition to change. But in concurrent programs, asynchronous statechanges can happen all the time.Guarded methods thus pose liveness issues that simple conditionals do not encounter. Any guardimplicitly asserts that, eventually, some other thread(s) will cause the required state changes to occur,or, if they do not, that it would be best never to proceed with the current activity. Time-outs are a wayof softening such assertions, using a balking policy as a backup if the wait continues too long.Some high-level design methods express conditional waits using an if -like construct called WHEN(also known as AWAIT ) that can be useful in designing guarded methods. For example, here is apseudocode version of the counter class using WHEN :pseudoclass BoundedCounterWithWhen {protected long count = MIN;// Pseudocodepublic long count() { return count; }public void inc() {WHEN (count < MAX) {++count;}}public void dec()WHEN (count > MIN) {--count;}}}The WHEN constructs here express the idea that the BoundedCounter is obligated to keep thecount between MIN and MAX . If a dec message is received but the count cannot be decrementedbecause it is already at MIN , the thread is blocked, resuming sometime later if and when the countbecomes greater than MIN via an inc message invoked by some method running in some otherthread.3.2.1.2 State-based message acceptanceActions in guarded methods trigger only when both a certain message is received and the object is in acertain state. Because neither the message nor the state is necessarily primary, you can design abstractversions of methods with the two parts inverted. This state-based style can be easier to use whendesigning classes in which several different methods are all triggered in the same states, for examplewhen the object is assuming a particular role. This form also more clearly reflects state-basednotations used in several popular high-level OO analysis and design methods.Ada concurrency constructs can be used to define methods in this fashion. Expressed in Ada-likepseudocode, the BoundedCounter is:pseudoclass BoundedCounterWithAccept {protected long count = MIN;// PseudocodeWHEN (true) ACCEPT public long count() {return count;}WHEN (count < MAX) ACCEPT public void inc()++count;{}WHEN (count > MIN) ACCEPT public void dec()--count;}}{Going to the extreme, some designs are easier to reason about if you think of actions as always beingrequested, but triggered only when the object makes a particular state transition. Some loopingmethods take this form. For example, you might design a special counter with a continuously enabledmechanism that resets the count to zero whenever it reaches a threshold. This style is sometimes calledconcurrent constraint programming, where actions can be triggered only by state changes since thereare no messages.3.2.1.3 Defining logical control stateMany objects maintain attributes that together constitute a very large (or for all practical purposesinfinite) state space, but maintain only a small logical state space for purposes of guarding actions. Forexample, for purposes of inc and dec , BoundedCounters have only three logical states, notone state per value of their count:StatetopmiddlebottomincConditioncount == MAXMIN < count < MAXcount == MINdecno yesyes yesyes noA bit of care is needed in characterizing these states. For example, if MAX is equal to MIN+1 , thenthere is no distinct middle state. And if MIN is equal to MAX , then there is no way to distinguish topfrom bottom: neither method should ever fire.As seen in the table, logical states are normally defined in terms of predicates — boolean expressionsthat distinguish particular ranges, values and/or other computable properties of fields. They can becoded either as free-standing internal boolean methods or simply as boolean conditions written insidemethods relying on them. When state analysis becomes too big and unwieldy for such techniques, youcan design and encode states using StateCharts, tables, decision trees, automata, and related tools ofthe trade for dealing with state machines (see the Further Readings in § 1.3.5).Instead of relying on predicate expressions, you can represent logical state explicitly in a variable.Each distinct state can be labeled as an integer or any other discrete data type. The field representingstate must be re-evaluated upon each update so that it is always accurate (see § 3.3.1). It is not strictlynecessary to use a single variable — multiple variables can be used if object state can be partitionedon several independent dimensions. Special cases include:••Role variables control responses to all of a related set of methods (often those declared in asingle interface). When objects may alternate among roles, a single variable suffices to directappropriate behavior. For example, an object may alternate between being a Producer anda Consumer . When in one role, it may ignore or delay responses to messages associatedwith the other.Rather than coding state as a value, you can code it as a reference to a state-object. For eachstate, you can write a class describing the behavior of the object when it is in that state. Themain class then contains a reference field, say stateObject , that is always bound to theappropriate delegate. This is an application of the States as Objects pattern in the DesignPatterns book; a variant is described in § 3.7.2.3.2.2 Monitor MechanicsThere are at least as many ways to implement guarded methods as there are ways to design them. Butnearly all these techniques can be considered specializations of the following strategy employingmethods Object.wait , Object.notify , and Object.notifyAll :••For each condition that needs to be waited on, write a guarded wait loop that causes thecurrent thread to block if the guard condition is false.Ensure that every method causing state changes that affect the truth value of any waited-forcondition notifies threads waiting for state changes, causing them to wake up and rechecktheir guard conditions.As a preliminary to discussing such techniques, here is a summary of the properties of waiting andnotification methods.In the same way that every Object has a lock (see § 2.2.1), every Object has a wait set that ismanipulated only by methods wait , notify , notifyAll , and Thread.interrupt .Entities possessing both locks and wait sets are generally called monitors (although almost everylanguage defines details somewhat differently). Any Object can serve as a monitor.The wait set for each object is maintained internally by the JVM. Each set holds threads blocked bywait on the object until corresponding notifications are invoked or the waits are otherwise released.Because of the way in which wait sets interact with locks, the methods wait , notify , andnotifyAll may be invoked only when the synchronization lock is held on their targets.Compliance generally cannot be verified at compile time. Failure to comply causes these operations tothrow an IllegalMonitorStateException at run time.The actions of these methods are as follows:Wait. A wait invocation results in the following actions:•••If the current thread has been interrupted, then the method exits immediately, throwing anInterruptedException . Otherwise, the current thread is blocked.The JVM places the thread in the internal and otherwise inaccessible wait set associated withthe target object.The synchronization lock for the target object is released, but all other locks held by thethread are retained. A full release is obtained even if the lock is re-entrantly held due to nestedsynchronized calls on the target object. Upon later resumption, the lock status is fullyrestored.Notify. A notify invocation results in the following actions:•••If one exists, an arbitrarily chosen thread, say T, is removed by the JVM from the internalwait set associated with the target object. There is no guarantee about which waiting threadwill be selected when the wait set contains more than one thread — see § 3.4.1.5.T must re-obtain the synchronization lock for the target object, which will always cause it toblock at least until the thread calling notify releases the lock. It will continue to block ifsome other thread obtains the lock first.T is then resumed from the point of its wait .NotifyAll. A notifyAll works in the same way as notify except that the steps occur (in effect,simultaneously) for all threads in the wait set for the object. However, because they must acquire thelock, threads continue one at a time.Interrupt. If Thread.interrupt is invoked for a thread suspended in a wait , the samenotify mechanics apply, except that after re-acquiring the lock, the method throws anInterruptedException and the thread's interruption status is set to false . If aninterrupt and a notify occur at about the same time, there is no guarantee about which actionhas precedence, so either result is possible. (Future revisions of JLS may introduce deterministicguarantees about these outcomes.)Timed Waits. The timed versions of the wait method, wait(long msecs) and wait(longmsecs , int nanosecs) , take arguments specifying the desired maximum time to remain in thewait set. They operate in the same way as the untimed version except that if a wait has not beennotified before its time bound, it is released automatically. There is no status indication differentiatingwaits that return via notifications versus time-outs. Counterintuitively, wait(0) and wait(0 , 0)both have the special meaning of being equivalent to an ordinary untimed wait() .A timed wait may resume an arbitrary amount of time after the requested bound due to threadcontention, scheduling policies, and timer granularities. (There is no guarantee about granularity. MostJVM implementations have observed response times in the 1-20ms range for arguments less than1ms.)The Thread.sleep(long msecs) method uses a timed wait, but does not tie up the currentobject's synchronization lock. It acts as if it were defined as:if (msecs != 0) {Object s = new Object();synchronized(s) { s.wait(msecs); }}Of course, a system need not implement sleep in exactly this way. Note that sleep(0) pausesfor at least no time, whatever that means.To illustrate some of the underlying mechanics, consider the following useless class that blindly issueswait and notifyAll :class X {synchronized void w() throws InterruptedException {before(); wait(); after();}synchronized void n() { notifyAll(); }void before() {}void after() {}}Here is one possible outcome of three threads invoking methods on a common x . Notice that eventhough T1 began waiting before T2, T2 resumed before T1. It could have been otherwise; there are noguarantees.3.2.3 Guarded WaitsThe standard coding idiom for expressing guarded methods is a simple while loop invoking wait .For example, the inc method of a BoundedCounter implementation might start out as:synchronized void inc() throws InterruptedException {while (count >= MAX) wait();++count;// ...}To ensure that guards are implemented correctly, it is sometimes helpful to encapsulate each guard inits own method. For a generic example:class GuardedClass {// Generic code sketchprotected boolean cond = false;// PRE: lock heldprotected void awaitCond() throws InterruptedException {while (!cond) wait();}public synchronized void guardedAction() {try {awaitCond();}catch (InterruptedException ie) {// fail}}// actions}Condition checks must be placed in while loops. When an action is resumed, the waiting taskdoesn't know whether the condition it is waiting for is actually true; it only knows that it has beenwoken up. So, in order to maintain safety properties, it must check again.As a matter of programming practice, this style should be used even if the class contains only a singleinstance of wait that waits for a single condition. It is never acceptable to write code that assumes anobject is in some particular state when it resumes after a given wait . One reason is that such codecould fail just because some other unrelated object invoked notify or notifyAll on the targetobject by mistake. (These are public methods defined on all objects.) Additionally, it is wise toavoid breakage in the case of spurious wakeups in which waits are released by the system without anyexplicit call to a notification method [4] . However, a more important consideration is that without re-evaluation, such code will start failing in peculiar ways if people define additional methods (perhapsin subclasses of your class) that also use waits and notifications for other purposes.[4]As of this writing, the JLS does not specifically acknowledge that spurious wakeups may occur. However,many JVM implementations are constructed using system routines (for example POSIX thread libraries) inwhich spurious wakeups are permitted and are known to occur.Objects with guarded waits can be harder to think about than simple fully synchronized objects (§2.2.2). Methods with guarded waits are not completely atomic. A waiting method suspends withoutretaining its synchronization lock, thus allowing any other thread to begin executing anysynchronized method on that object. (And, as usual, other unsynchronized methods can stillexecute at any time.)Guarded methods thus need to be written so that objects are in consistent states upon entering wait .The best strategy for ensuring this stems from the general idea of check-and-act policies. If you placea guarded wait as the first statement in a method and do not change state in the process of checkingit, then you cannot have changed state in any inconsistent way when entering wait .3.2.3.1 Interrupted waitsA wait will be broken (or will not start at all) if the waiting thread has been interrupted. This enablesblocked threads to respond to thread cancellation. In this sense, guarded methods are similar to try-and-see methods — attempts to pass preconditions may themselves fail — and the failure policies andimplementations described in § 3.1 apply.By far the most common policy applied in guarded methods is just to rethrowInterruptedException to denote failure to the client, which will then need to deal with it.Assuming that guarded waits appear at the beginnings of methods, no further local cleanup isnecessary.The routine practice of rethrowing InterruptedException (or, in the usual case, merely notcatching it) and thus including throws InterruptedException in method signatures alsoserves as a simple declarative assertion that a method employs a guarded wait or derivative. This canbe vital information for potential users of a class (see especially § 3.3.4).3.2.4 NotificationsWait-based constructions make up the bulk of the safety side of guard implementation. To ensureliveness, classes must also contain code to wake up waiting threads when the conditions they arewaiting for change. Every time the value of any field mentioned in a guard changes in a way thatmight affect the truth value of the condition, waiting tasks must be awakened so they can recheckguard conditions.The simplest way to arrange that blocked threads eventually recheck conditions is to insertnotifyAll in methods that cause relevant state changes. In turn, the simplest way to do this is todefine utility methods that encapsulate assignment, issuing a notification upon any change in value.This may lead to useless signals and poor performance (due to context switching overhead) in classesthat perform lots of assignments. However, as a design practice, it is occasionally a good idea to startout using blanket notifications within assignment methods, and then to minimize and reorganize themas discussed in later sections of this chapter. For example, here is a first pass atBoundedCounter :class SimpleBoundedCounter {protected long count = MIN;public synchronized long count() { return count; }public synchronized void inc() throws InterruptedException {awaitUnderMax();setCount(count + 1);}public synchronized void dec() throws InterruptedException {awaitOverMin();setCount(count - 1);}protected void setCount(long newValue) { // PRE: lock heldcount = newValue;notifyAll(); // wake up any thread depending on new value}protected void awaitUnderMax() throws InterruptedException {while (count == MAX) wait();}protected void awaitOverMin() throws InterruptedException {while (count == MIN) wait();}}3.2.4.1 Slipped conditions and missed signalsIn SimpleBoundedCounter , the calls to awaitUnderMax and setCount in methodinc are performed under the same synchronized lock scope. It would not suffice to separatelysynchronize awaitUnderMax and setCount but not inc . This could encounter a safetyviolation. Expanding these out:}void badInc() throws InterruptedException { // Do not usesynchronized(this) { while (count >= MAX) wait(); }// (*)synchronized(this) { ++count; notifyAll(); }This version may encounter a slipped condition in which the condition changes due to the actions ofsome other thread executing at point (*) — between the time the lock is released after the wait andthen reacquired before incrementing the count. This could result in the action being performed even ifthe guard is now false, possibly breaking the object by causing the required invariant to become false.Additionally, a liveness failure could result if setCount were written in a non-atomic fashion, inparticular as:}void badSetCount(long newValue) {// Do not usesynchronized(this) { notifyAll(); }// (**)synchronized(this) { count = newValue; }Here, the method first acquires the lock to perform notifyAll , then releases it, and then re-acquires it to change count . This could result in a missed signal: A thread executing at point (**)might start waiting after the signal intended to wake it up was issued but before the condition waschanged. This thread will wait forever, or at least until the next notification is somehow produced.Note that within synchronized methods, the order in which a notifyAll is placed does notmatter. No awakened threads will be able to continue until the synchronization lock is released. Just asa matter of style, most people put notifications last in method bodies.The mistakes leading to missed signals and slipped conditions illustrated here may seem farfetched.But they can be common sources of error in designs making more extensive use of waiting andnotification techniques (see for example § 3.7.2).3.2.4.2 Single notificationsThe SimpleBoundedCounter class uses notifyAll because threads may be waiting for thecount either to be greater than MIN or less than MAX . It would not suffice here to use notify ,which wakes up only one thread (if one exists). The JVM might pick a thread waiting for a conditionthat does not hold without picking the possibly many that could continue. This might happen, forexample, if there are several threads all trying to increment and several all trying to decrement.(Consider for example the case where MAX == MIN+1 .)However, in some other classes, you can reduce the context-switch overhead associated withnotifications by using a single notify rather than notifyAll . Single notifications can be usedto improve performance when you are sure that at most one thread needs to be woken. This applieswhen:•••All possible waiting threads are necessarily waiting for conditions relying on the samenotifications, usually the exact same condition.Each notification intrinsically enables at most a single thread to continue. Thus it would beuseless to wake up others.You can accommodate uncertainties surrounding the possibility that an interrupt and anotify may occur at about the same time. In this case, the one thread that was notified isabout to terminate. You might want another thread to receive notification instead, but this isnot automatically arranged. (The issue does not arise with notifyAll since all threads arewoken.)To illustrate the relation between notify and notifyAll , the followingGuardedClassUsingNotify class uses notify to approximate the effects ofnotifyAll by adding instrumentation to helper methods that encapsulate guards. Here, adding anexecution state variable to track the number of waiting threads allows construction of a loop thatbroadcasts a notification to all waiting threads, thus simulating notifyAll (although onlyapproximately — notifyAll is a primitive built-in operation).The odd-looking catch clause seen here ensures that if a cancelled thread receives a notify, it relaysthat notification to some other waiting thread (if one exists). This safeguard is not really needed heresince all waiting threads are being awakened anyway, but the technique should be employed in anycode using notify in which interruptions do not necessarily shut down an entire program.Note that the extra call to notify inside the catch clause may cause the count of waiting threadsto overestimate the number of notifications necessary to wake up all threads. This in turn may causemore than the minimal number of calls to notify to be issued. This fact underscores the need toplace waits in guard loops, even when using notify .class GuardedClassUsingNotify {protected boolean cond = false;protected int nWaiting = 0; // count waiting threadsprotected synchronized void awaitCond()throws InterruptedException {while (!cond) {++nWaiting;// record fact that a thread is waitingtry {wait();}catch (InterruptedException ie) {notify();// relay to non-cancelled threadthrow ie;}finally {--nWaiting;}}}}// no longer waitingprotected synchronized void signalCond() {if (cond) {// simulate notifyAllfor (int i = nWaiting; i > 0; --i) notify();}}In open, extensible designs (see § 1.3.4), the conditions under which notify apply are rather specialand fragile. The use of notify , and optimizations of guarded constructions more generally, arecommon sources of error. As a general design tactic, it is a better idea to isolate uses of notify toconcurrency control utility classes (see § 3.4) that can be heavily optimized and carefully reviewedand tested. We adopt this approach throughout the remainder of this chapter.The conditions for using notify hold much more frequently in closed designs, where you are in fullcontrol of all participating threads. For example, the following sketch of a closed-system two-playergame uses waits for turn-taking. A single notify suffices to wake the only thread that can possiblybe awaiting its turn. On the other hand, because there is only one thread waiting anyway, theperformance differences between this version and one using notifyAll are probably too small tomeasure — the main overhead associated with notifyAll is context switching, not the call tonotifyAll itself.Note that giveTurn is invoked as an open call (see § 2.4.1.3) in methodGamePlayer.releaseTurn . It is good practice to release as much synchronization as possiblewhen performing notifications (see § 3.7.2).class GamePlayer implements Runnable {protected GamePlayer other;protected boolean myturn = false;// Incompleteprotected synchronized void setOther(GamePlayer p) {other = p;}synchronized void giveTurn() { // called by other playermyturn = true;notify();// unblock thread}void releaseTurn() {GamePlayer p;synchronized(this) {myturn = false;p = other;}p.giveTurn(); // open call}synchronized void awaitTurn() throws InterruptedException {while (!myturn) wait();}void move() { /*... perform one move ... */ }public void run() {try {for (;;) {awaitTurn();move();releaseTurn();}}catch (InterruptedException ie) {} // die}public static void main(String[] args) {GamePlayer one = new GamePlayer();GamePlayer two = new GamePlayer();one.setOther(two);two.setOther(one);one.giveTurn();new Thread(one).start();new Thread(two).start();}}3.2.5 Timed WaitsRather than waiting forever for a condition to become true in a guarded method, time-out designsplace a bound on how long any given wait should remain suspended.Responses to time-outs are of course situation-dependent. When time-outs are used heuristically, thefact that a predicate does not hold may be only of informational value. In other cases, time-outs forcecancellation of attempted actions, in which case it is often appropriate to declare aTimeoutException as a subclass of InterruptedException .Time-outs are typically more useful than other techniques that detect unanticipated liveness problems(such as deadlock [5] ) because they make fewer assumptions about contexts — any stall that causesunacceptably long blockages can be detected by a time-out that then triggers failure responses (see §3.1.1). Since most responses to delays of any kind are the same, they can all be triggered by time-outexceptions or related notification techniques.[5]Deadlock detection algorithms are discussed, for example, in the texts by Andrews and by Bernstein andLewis listed in the Further Readings in § 1.2.5. Implementation requires use of special lock classes.However, some run-time systems and debuggers contain features allowing detection of deadlocks involvingbuilt-in synchronization.The parameters controlling wait time and condition re-evaluation are sometimes completely arbitrary,and often require some trial and error. Usually, it is not too hard to provide values that will catch trueliveness problems without false-alarming on waits that just happen to be slow. Since many suchfailures will at some point require human intervention, policies can be backed up via mechanisms thatquery users about remedial actions.Time-outs are somewhat awkward to express using wait(msec) . In the followingTimeoutBoundedCounter class, the wait is placed in a loop in order to deal with the factthat unrelated notifications may occur. This loop is slightly messy but has the identical rationale asversions without time-outs. The condition being waited on is always checked first after waking upfrom the wait , before checking for time-out. This helps avoid programming errors stemming fromcases in which a wait is released by a time-out, but other contending threads execute before the timed-out thread gets a chance to resume. One of those other threads could have changed the condition, inwhich case it would not be necessary or appropriate to return a failure indication. If the condition doesnot hold, the time-out value is checked and adjusted for use in the next iteration.You could change this code to make the opposite decision about ordering the condition check andtime check if time-outs are always considered to denote failure, even if the condition does hold uponresumption from the time-out.class TimeoutException extends InterruptedException { ... }class TimeOutBoundedCounter {protected long count = 0;protected long TIMEOUT = 5000; // for illustration// ...synchronized void inc() throws InterruptedException {if (count >= MAX) {long start = System.currentTimeMillis();long waitTime = TIMEOUT;for (;;) {if (waitTime <= 0)throw new TimeoutException();else {try {wait(waitTime);}catch (InterruptedException ie) {throw ie; // coded this way just for emphasis}if (count < MAX)break;else {long now = System.currentTimeMillis();waitTime = TIMEOUT - (now - start);}}}}++count;notifyAll();}synchronized void dec() throws InterruptedException {// ... similar ...}}3.2.6 Busy WaitsImplementing guards via waiting and notification methods is nearly always superior to using anoptimistic-retry-style busy-wait "spinloop" of the form:protected void busyWaitUntilCond() {while (!cond)Thread.yield();}Busy-waits have drawbacks that make them poor choices for implementing most guarded actions. Thecontrasts between the two techniques help explain why suspension-based waiting and notificationmethods are defined as they are.3.2.6.1 EfficiencyBusy-waits can waste an unbounded amount of CPU time spinning uselessly. The wait -basedversion rechecks conditions only when some other thread provides a notification that the object's statehas changed, thus possibly affecting the guard condition. Even if notifications are sometimes sentwhen enabling conditions do not hold, conditions are likely to be unproductively rechecked far lessoften than in a spinloop that continually, blindly rechecks.The main exceptions are those cases in which you somehow know that the condition must becometrue within some very short, bounded amount of time. In such cases, the time wasted spinning mightbe less than the time required to suspend and resume threads. This may apply to operations associatedwith device control. Bounded spins, followed by suspensions, are also sometimes used inside run-timesystems as an optimization for "adaptive" locks that are usually held only briefly.3.2.6.2 SchedulingThe yield in the spinloop version is only a hint (see § 1.1.2) and is not guaranteed effective inallowing other threads to execute so they can change the condition. Thus the utility of busy-waits ismore dependent on the policies of a particular JVM, and may interact with other aspects ofscheduling. For example, if the spinning task is running at a high priority but the threads that changethe condition run at low priority, the spinning task may still crowd the others out. In the wait -basedversion, the waiting task does not run at all, and thus cannot encounter such scheduling problems(although other scheduling problems can of course still arise).Some of the most plausible situations for using spinloops are those in which some other action can betaken within the loop if the condition is not true, rather than just yielding. This helps limit CPUwastage and interacts better with common scheduling policies. If spinning is for some reasonnecessary and no other alternatives apply, you can reduce CPU costs and scheduling uncertainties byusing the timed back-off techniques described in § 3.1.1.5.3.2.6.3 TriggeringUnlike wait-based constructions, methods with spinloops need not be paired with methods thatprovide notifications to trigger checks. Spinloops are sometimes used in desperation when no suchsignaling method exists or can be written. But busy waits can miss opportunities to fire if they happennot to be scheduled to execute during times when the condition is momentarily true.Note however, that similar phenomena also occur in wait -based constructions: A condition signaledby a notify or notifyAll may later change due to the action of some other thread occurringbefore the notified thread gets a chance to continue. This is one reason to guard all forms of waits.Additionally, neither technique alone automatically guarantees fairness — that each potentiallyenabled thread eventually proceeds. Even in wait-based constructions, it could happen that oneparticular looping thread that repeatedly encounters the guard is always the one that proceeds, starvingout all others (see § 3.4.1.5).3.2.6.4 Synchronizing actionsIt can be difficult to synchronize spinloops in the desired manner. For example, it wouldn't alwayswork to declare the method busyWaitUntilCond as synchronized , since this does notallow any other synchronized method to change the condition. Minimally, cond needs to bedeclared as volatile and/or accessed and set in its own synchronized methods. However,without synchronization of an entire check-act sequence, you cannot in general ensure that an objectremains in the same state between the condition test and the associated action.As described in § 3.4.2.1, reliable use of unsynchronized busy-waits in guarded methods is generallyrestricted to latching predicates that are somehow guaranteed to remain true forever once set. Incontrast, the wait -based version automatically relinquishes the synchronization lock (for the hostobject only) upon wait and re-obtains the lock upon waking up. So long as both the guard and theaction are enclosed within a common lock, and the guard references only variables protected by thatlock, there is no danger of slipped conditions. This is one reason that wait statements can be usedonly under synchronization. However, the fact that waiting tasks hold any locks at all can be thesource of logistical difficulties, including the nested monitor problem discussed in § 3.3.4.3.2.6.5 ImplementationsIn those rare cases in which you have no alternative to busy-waits, you can use a class such as thefollowing SpinLock . There is never any reason to use this class for locking (see § 2.5.1), but it is asimple vehicle for illustrating constructions that can be applied in other contexts.The release method here is synchronized as an assurance that a memory synchronization occursupon lock release, as would be necessary in nearly any use of this class (see § 2.2.7). The escalationrules for failed checks are uncomfortably dependent on settings that are intrinsically platform- andapplication-specific (for example, the pure yield -less spin phase is plausible only onmultiprocessors), and can be difficult to tune effectively even with empirical feedback.class SpinLock {// Avoid needing to use thisprivate volatile boolean busy = false;synchronized void release() { busy = false; }void acquire() throwsint spinsBeforeYieldint spinsBeforeSleeplong sleepTime = 1;int spins = 0;for (;;) {if (!busy) {synchronized(this)if (!busy) {busy = true;return;}}}}InterruptedException {= 100;// 100 is arbitrary= 200;// 200 is arbitrary// 1msec is arbitrary{// test-and-test-and-setif (spins < spinsBeforeYield) {// spin phase++spins;}else if (spins < spinsBeforeSleep) { // yield phase++spins;Thread.yield();}else {// back-off phaseThread.sleep(sleepTime);sleepTime = 3 * sleepTime / 2 + 1; // 50% is arbitrary}}}3.3 Structuring and Refactoring ClassesThe basic waiting and notification techniques described in § 3.2 can be combined with other designstrategies to improve reusability and/or performance, as well as to obtain finer-grained control overactions. This section surveys some common patterns, techniques, and problems seen when trackinglogical state and execution state, wrapping control in overridable methods, and creating confinement-based designs.3.3.1 Tracking StateThe most conservative strategy for writing guarded methods is to call notifyAll every time youchange the value of any instance variable. This strategy is highly extensible. If all changes to allinstance variables generate notifyAll , then any method in the class and all of its possiblesubclasses can define a guard clause that waits for any particular state. On the other hand, this practicecan be inefficient when it generates notifications that cannot possibly affect the guard conditions ofany waiting thread. Often, some or all of these useless notifications can be eliminated via logical stateanalysis. Rather than issuing notifications upon all changes in instance variables, you can arrange toissue notifications only upon transitions out of the logical states in which threads can wait. Thefollowing examples illustrate techniques.3.3.1.1 Channels and bounded buffersChannel abstractions play central roles in several styles of concurrent software design (see § 1.2.4 and§ 4.1). A Channel interface may be defined as:interface Channel {void put(Object x) throws InterruptedException;Object take()throws InterruptedException;}Methods take and put may be viewed as data-carrying analogs of Sync acquire andrelease operations (see § 2.5.1), non-IO-based versions of stream read and write operations,encapsulated forms of transfer operations (see § 2.3.4), and when channel elements representmessages, message receive and send operations (see § 4.1.1).A bounded buffer can be used as a channel (see § 3.4.1 for some other alternatives). Bounded buffershave the same overall structure as bounded counters. In addition to a size (count), a buffer maintains afixed array of elements. Instead of inc , it supports put , and instead of dec , it supports take .Also, the MIN is simply zero and the MAX is the capacity (declared as int to simplify use in arrayindexing).interface BoundedBuffer extends Channel {int capacity(); // INV: 0 < capacityint size();// INV: 0 <= size <= capacity}As described in just about any data structures textbook, implementations of BoundedBufferscan employ a fixed-sized array along with two indices that circularly traverse the array, keeping trackof the next positions to put and take respectively. The logical states and transitions defined for aBoundedBuffer are similar to those for a BoundedCounter :StatefullpartialemptyConditionsize == capacity0 < size < capacitysize == 0puttakeno yesyes yesyes noNotice that the only transitions that can possibly affect waiting threads are those that step away fromstates empty and full; that is, increment the size up from zero or decrement it down from the capacity.These observations lead to the following implementation of BoundedBuffer in whichnotifications are issued only when transitions are made out of the empty and full states. (Part of theconciseness of the code is due to the convenience of post-increment and post-decrement codingidioms.)This version can generate far fewer notifications than a version in which every change to sizeresults in a notification, thus uselessly waking up threads. In cases where evaluating guards is itselfcomputationally expensive, minimizing rechecks in this fashion results in even greater efficiencyimprovements.class BoundedBufferWithStateTracking {protected final Object[] array; // the elementsprotected int putPtr = 0;// circular indicesprotected int takePtr = 0;protected int usedSlots = 0;// the countpublic BoundedBufferWithStateTracking(int capacity)throws IllegalArgumentException {if (capacity <= 0) throw new IllegalArgumentException();array = new Object[capacity];}public synchronized int size() { return usedSlots; }public int capacity() { return array.length; }public synchronized void put(Object x)throws InterruptedException {while (usedSlots == array.length) // wait until not fullwait();array[putPtr] = x;putPtr = (putPtr + 1) % array.length; // cyclically inc}if (usedSlots++ == 0)notifyAll();// signal if was emptypublic synchronized Object take()throws InterruptedException{while (usedSlots == 0)wait();// wait until not emptyObject x = array[takePtr];array[takePtr] = null;takePtr = (takePtr + 1) % array.length;if (usedSlots-- == array.length) // signal if was fullnotifyAll();return x;}}3.3.1.2 State variablesState tracking can sometimes be simplified and better encapsulated by using state variables thatrepresent the entire logical state of an object in a single field (see § 3.2.1.3). Usually, a state variabletakes on values of an enumerated type. The variable is re-evaluated after any update to relevant fields.This re-evaluation may then be isolated in a single method, say updateState , called after eachupdate method. After re-evaluating state, updateState issues notifications associated with thestate change. For example, using a state variable in a BoundedCounter (a BoundedBufferwould work similarly) leads to:class BoundedCounterWithStateVariable {static final int BOTTOM = 0, MIDDLE = 1, TOP = 2;protected int state = BOTTOM; // the state variableprotected long count = MIN;protected void updateState() {//PRE: synch lock heldint oldState = state;if(count == MIN) state = BOTTOM;else if (count == MAX) state = TOP;elsestate = MIDDLE;if (state != oldState && oldState != MIDDLE)notifyAll();// notify on transition}public synchronized long count() { return count; }public synchronized void inc() throws InterruptedException {while (state == TOP) wait();++count;updateState();}public synchronized void dec() throws InterruptedException {while (state == BOTTOM) wait();--count;updateState();}}Instead of using updateState to reassess state, you can arrange that each method that performsupdates also determines the correct next state and sends it as an argument to updateState , whichcan then still perform notifications upon change. (However, this may compound the fragility problemsdiscussed in § 3.3.3.3.) As the number of states grows, you can employ heavier machinery, such asfinite-state machines or decision tables (see Further Readings).3.3.2 Conflict SetsClasses that track the execution state of underlying operations can use this information to decide whatto do about new incoming requests. One of the main applications is construction of custom-madeexclusion policies that provide more fine-grained exclusion control than seen in Chapter 2.To illustrate, consider an Inventory class with methods to store and retrieve objects,each of which has a unique description. Suppose that these operations are somewhat time-consuming,but are implemented in a way that does not necessarily require low-level synchronization. In this case,we can allow those operations that do not semantically conflict with each other to execute at the sametime, thus permitting more concurrency than possible in a fully synchronized version of the class.In the classic context of this form of policy control, basic functionality is arranged via databasetransactions, but we will illustrate using java.util.Hashtable . Even though the fullysynchronized Hashtable class allows an Inventory class to be defined without worryingabout some low-level synchronization details, we still want to place some semantic constraints on thestore and retrieve operations. One policy choice is:••A retrieve operation should not run concurrently with a store operation since thestore might be in the process of adding exactly the item requested, in which case you don'twant to return a failure indication.Two or more retrieve operations should not execute at the same time, since one may bein the process of removing the item requested by the others.We could have made other decisions here, for example even allowing all operations to operateconcurrently, thus allowing failures. Also, we could have based the policies on the internalimplementation details of the operations. For example, the above choices would also hold here if theretrieve method were programmed in a way that required exclusion, but store did not.Several formal and semiformal notations have been devised to help represent this kind of information.The most widely used method, which suffices for most concurrency control problems of this kind, isbased on conflict sets — sets of pairs of actions that cannot co-occur. For example, here the conflictset is merely:{ (store, retrieve), (retrieve, retrieve) }.This information can serve both as documentation of class semantics and as a guide for implementingthese semantics via execution-state tracking.3.3.2.1 ImplementationClasses based on conflict sets can employ before/after designs (see § 1.4) in which ground actions aresurrounded by code that maintains the intended exclusion relations. The following mechanics can beimplemented via any before/after pattern:•••For each method, declare a counter field representing whether or not the method is inprogress.Isolate each ground action in a non-public method.Write public versions of the methods that surround the ground action with before/aftercontrol:o Each synchronized before-action first waits until all non-conflicting methods haveterminated, as indicated by counters. It then increments the counter associated withthe method.o Each synchronized after-action decrements the method counter and performsnotifications to wake up other waiting methods.Applying these steps directly to the methods of an Inventory class leads to:class Inventory {protected final Hashtable items = new Hashtable();protected final Hashtable suppliers = new Hashtable();// execution state tracking variables:protected int storing = 0; // number of in-progress storesprotected int retrieving = 0; // number of retrieves// ground actions:protected void doStore(String description, Object item,String supplier) {items.put(description, item);suppliers.put(supplier, description);}protected Object doRetrieve(String description) {Object x = items.get(description);if (x != null)items.remove(description);return x;}public void store(String description,Object item,String supplier)throws InterruptedException {synchronized(this) {// before-actionwhile (retrieving != 0) // don't overlap with retrieveswait();++storing;// record exec state}try {doStore(description, item, supplier); // ground action}finally {// after-actionsynchronized(this) {// signal retrievesif (--storing == 0) // only necessary when hit zeronotifyAll();}}}public Object retrieve(String description)throws InterruptedException {synchronized(this) {// before-action// wait until no stores or retrieveswhile (storing != 0 || retrieving != 0)wait();++retrieving;}try {return doRetrieve(description);// ground action}finally {synchronized(this) {if (--retrieving == 0)notifyAll();}}}}// after-action(Because of the nature of the conflict set here, the notifyAll in the retrieve method happensalways to be enabled. However, more generally the notifications should take the conditional formshown.)3.3.2.2 Variants and extensionsThe ideas seen in the above Inventory example also apply to optimistic methods, in which caseconflicts are often termed invalidation relations. These are implemented by aborting conflictingoperations before commitment rather than waiting until it is safe to perform them (see § 3.6).More extensive notation can be used to represent conflict at an arbitrarily fine level of detail, coveringcases such as those in which, say, some methodA conflicts with methodB only if it occurs aftermethodC . Similarly, in the Inventory class, we might want to use a more precise notation inorder to state that a store operation can commence if a retrieve is in progress, but not viceversa. A range of notation has been devised for such purposes (see the Further Readings in § 1.2.5 and§ 3.3.5), enabling more detailed representation of conflicts while still allowing semi-automaticimplementation via execution-state tracking variables. However, in the extreme, it may be that nothingshort of a full history log suffices to implement a given policy.The techniques described in § 3.4 and § 3.7 can be used to reduce the number of notifications andcontext switches in most classes relying on conflict sets.Implementations based on execution-state tracking and conflict sets can suffer fragility and non-extensibility problems. Since conflict sets are based on the methods actually defined in a class ratherthan on logical representations of their semantics or underlying state invariants, they are difficult toextend when changing or adding methods in subclasses. For example, if a sort method is introducedto re-order the items in some fashion, or a search method to check if an item exists, they mightconflict in different ways from those currently handled, requiring rework.The Readers and Writers pattern and related constructions described in § 3.3.3 alleviate some of theseproblems by classifying operations into extensible categories. The Readers and Writers pattern alsoaddresses matters of precedence and scheduling that are not covered by conflict notations. Forexample, in Inventory , we might want to add a provision that if there are multiple waitingthreads, threads waiting to perform retrieve operations are preferred over those waiting toperform store operations, or vice versa.3.3.3 SubclassingSubclassing can be used to layer different control policies over existing mechanism, or even viceversa. This practice extends the applications of subclassing seen in § 2.3.3.2 that layer locking overbare functionality.3.3.3.1 Readers and WritersThe Readers and Writers pattern is a family of concurrency control designs having a common basisbut differing in matters of policy governing control of threads invoking accessors ("Readers") versusthose invoking mutative, state-changing operations ("Writers").In § 2.5.2, we saw a version of this pattern encapsulated as a utility class. Here we show asubclassable before/after version using the template method pattern (see § 1.4.3). Beyond its intrinsicutility, this design is a good model for any kind of policy that can be implemented by mixing togethersubclass-based before/after concurrency control and counters recording messages and activities. Forexample, very similar techniques apply to classes that require certain categories of messages to occurin ordered pairs (as in enforcing, say, read , write , read , write , and so on). They also apply toextended schemes supporting intention locks that reserve the option to later acquire (or upgrade to)read or write locks for any of a set of objects reachable from a given container (see § 2.4.5).Before putting control mechanisms in place, you must first establish a set of policies governing theiruse. Readers and Writers policies are generalizations of the kinds of concurrency-control policiesseen, for example, in the Inventory class in § 3.3.2. But rather than dealing with particularmethods, they deal with all methods having the semantics of reading versus writing. However, thedetails are still situation-dependent. Considerations include:•••If there are already one or more active (executing) Readers, can a newly arriving Readerimmediately join them even if there is also a waiting Writer? If so, a continuous stream ofentering Readers will cause Writers to starve. If not, the throughput of Readers decreases.If both some Readers and some Writers are waiting for an active Writer to finish, should youbias the policy toward allowing Readers? a Writer? Earliest first? Random? Alternate?Similar choices are available after termination of Readers.Do you need a way to allow Writers to downgrade access to be Readers without having togive up locks?Although there are no right answers to these policy matters, there are some standard solutions andcorresponding implementations. We'll illustrate with a common set of choices: Readers are blocked ifthere are waiting Writers, waiting Writers are chosen arbitrarily (just relying on the order in which theunderlying JVM scheduler happens to resume unblocked threads), and there are no downgrademechanisms.Implementing this concurrency control policy requires execution state tracking. Like most policies, itcan be established by maintaining counts of threads that are actively engaged in the read and writeoperations, plus those that are waiting to do so. Tracking waiting threads is the main extension here ofthe techniques seen in typical implementations of conflict sets.To structure the corresponding implementations, control code can be factored out into method pairsthat surround the actual read and write code, which must be defined in subclasses. This before/afterdesign (see § 1.4.3) allows construction of any number of public read-style and write-style methods,where each public method invokes the non-public one within the pairs.The following version is written in a generic fashion, so that minor variants are simple to implementin subclasses. In particular, the count of waiting readers is not really necessary in this version, since nopolicy depends on its value. However, its presence allows you to adjust policies by changing thepredicates in the allowReader and allowWriter methods to rely on them in some way. Forexample, you might alter the conditionals to give preference to whichever count is greater.abstract class ReadWrite {protected int activeReaders = 0;protected int activeWriters = 0;// threads executing read// always zero or oneprotected int waitingReaders = 0; // threads not yet in readprotected int waitingWriters = 0; // same for writeprotected abstract void doRead(); // implement in subclassesprotected abstract void doWrite();public void read() throws InterruptedException {beforeRead();try{ doRead(); }finally { afterRead(); }}public void write() throws InterruptedException {beforeWrite();try{ doWrite(); }finally { afterWrite(); }}protected boolean allowReader() {return waitingWriters == 0 && activeWriters == 0;}protected boolean allowWriter() {return activeReaders == 0 && activeWriters == 0;}protected synchronized void beforeRead()throws InterruptedException {++waitingReaders;while (!allowReader()) {try { wait(); }catch (InterruptedException ie) {--waitingReaders; // roll back statethrow ie;}}--waitingReaders;++activeReaders;}protected synchronized void afterRead()--activeReaders;notifyAll();}{protected synchronized void beforeWrite()throws InterruptedException {++waitingWriters;while (!allowWriter()) {try { wait(); }catch (InterruptedException ie) {--waitingWriters;throw ie;}}--waitingWriters;++activeWriters;}protected synchronized void afterWrite() {--activeWriters;notifyAll();}}This class or its subclasses may also be repackaged to support the ReadWriteLock interfacediscussed in § 2.5.2. This can be done using inner classes. (A similar strategy is used by theutil.concurrent versions of ReadWriteLock , which also include some optimizationsdiscussed in § 3.7 to minimize unnecessary notifications.) For example:class RWLock extends ReadWrite implements ReadWriteLock {class RLock implements Sync {public void acquire() throws InterruptedException {beforeRead();}public void release() {afterRead();}}public boolean attempt(long msecs)throws InterruptedException{return beforeRead(msecs);}class WLock implements Sync {public void acquire() throws InterruptedException {beforeWrite();}public void release() {afterWrite();}public boolean attempt(long msecs)throws InterruptedException{return beforeWrite(msecs);}}protected final RLock rlock = new RLock();protected final WLock wlock = new WLock();public Sync readLock() { return rlock; }public Sync writeLock() { return wlock; }public boolean beforeRead(long msecs)throws InterruptedException {// ... time-out version of beforeRead ...}}public boolean beforeWrite(long msecs)throws InterruptedException {// ... time-out version of beforeWrite ...}3.3.3.2 Layering GuardsGuards may be added to basic data structure classes that were originally written in balking form. Forexample, consider a simple Stack :class StackEmptyException extends Exception { }class Stack {Fragments//public synchronized boolean isEmpty() { /* ... */ }public synchronized void push(Object x) { /* ... */ }{public synchronized Object pop() throws StackEmptyExceptionif (isEmpty())throw new StackEmptyException();// else ...}}Balking on attempts to pop an element from an empty stack is attractive since it makes the classusable in sequential settings where it would be pointless to wait for a pop : if no other threads can addan element, the program will just stall forever. On the other hand, some clients of a Stack inconcurrent contexts might want to hold up and wait for an element to appear. One inefficient approachis to try to perform pop and if a StackEmptyException is caught, to try again. This is adisguised form of busy-waiting.A version that directly supports guarded usage can be built using a straightforward subclass-baseddesign introducing methods that provide further coordination. However, it is not a particularly goodidea to override method pop here. Among other considerations, the different policies of balkingversus waiting are reflected in the different signatures of the methods: The balking form of pop canthrow StackEmptyException , but a waiting version never can; conversely, a waiting versioncan throw InterruptedException , but a balking version never can. While these could bemerged under some blander interface, it is more manageable all around to define them as separatemethods.Even so, it is possible to add method waitingPop in the subclass without needing to rewrite all ofthe internals of pop . Notice, however, that this also requires overriding push to providenotifications for threads blocked in waitingPop . (The notifyAll here could be furtheroptimized.)class WaitingStack extends Stack {public synchronized void push(Object x) {super.push(x);notifyAll();}public synchronized Object waitingPop()throws InterruptedException {while (isEmpty()) {wait();}}try {return super.pop();}catch (StackEmptyException cannothappen) {// only possible if pop contains a programming errorthrow new Error("Internal implementation error");}}3.3.3.3 Inheritance anomaliesSome concurrent OO programming languages (see Further Readings) syntactically require separationbetween non-public methods defining functionality and public methods defining concurrency controlpolicies; that is, they mandate the kind of separation seen in the template method version of classReadWrite . Even when separation is not strictly required, it is an attractive option:•••It enables either action code or concurrency control code to be varied independently insubclasses, avoiding constructions that would make it impossible for the subclass to obtaindesired functionality without rewriting nearly every method.It avoids the need to mix variables used solely for purposes of synchronization with logicalstate variables required for base functionality. Instead, these variables can be introduced insubclasses.It avoids problems surrounding exclusive control, access to internal variables and methods,object identity, nested monitors (§ 3.3.4), and interface adaptation encountered with otherlayering techniques. Subclassing extends objects rather than composing them. For example,no special considerations are needed to guarantee unique ownership of the superclass "part"of an object.So long as all relevant variables and methods are declared as protected , a subclass can usuallyperform necessary modifications to base-level code in order to support a desired policy. Despite thebest intentions of class authors, extensive surgery on method code in a subclass is sometimes the onlyway to salvage a class so that it obeys a given policy. Although protected access has some cleardrawbacks as a design convention, in concurrent settings the resulting ability for subclasses to alterpolicy control can outweigh concerns about abuse of superclass representations.For this to work, necessary invariants must be well documented. Superclasses relying onprotected fields and methods and documented constraints are more likely to be correctlyextended than those that publicly expose all fields (even via get/set methods), hoping that externalclients can figure out how to preserve consistency, semantic invariants, and atomicity requirements fornew actions or new policies.But this form of subclassing does have its limitations. When people first started using experimentalconcurrent OO languages, several researchers noticed that it can be difficult or even impossible todefine subclasses that add or extend commonly desired functionality or policy to superclasses. Similarconcerns have been expressed in accounts of high-level OO analysis and design methods.Some constructions in purely sequential classes are hard to extend as well, for example thosedeclaring methods as final for no good reason. But enough additional snags are encountered inconcurrent OO programming for this state of affairs to have been labeled the inheritance anomaly.The issues and problems covered by this term are only loosely related. Examples include:••••If a subclass includes guarded waits on conditions about which superclass methods do notprovide notifications, then these methods must be recoded. This is seen in classWaitingStack (§ 3.3.3.2), where push is overridden solely in order to providenotifications for the new method waitingPop .Similarly, if a superclass uses notify instead of notifyAll , and a subclass addsfeatures that cause the conditions for using notify no longer to hold, then all methodsperforming notifications must be recoded.If a superclass does not explicitly represent and track aspects of its logical or execution stateon which subclass methods depend, then all methods that need to track and check that statemust be recoded.Using state variables (§ 3.3.1.2) restricts subclasses to those in which synchronizationdepends only on the logical states or subdivisions of these states defined in the superclass.Thus, subclasses must conform to the same abstract specifications with respect to logicalstate. This practice is recommended in several accounts of high-level OO analysis and design,but can impede subclassing efforts. For example, suppose you want to extend classBounded CounterWithStateVariable to add a disable method that causesinc and dec to block, and an enable method that allows them to continue. Support forthese additional methods introduces a new dimension to logical state that alters both the guardand the notification conditions for the base methods.Taken together, these kinds of problems serve as a warning that, without more care than is usuallynecessary in sequential settings, you are likely to write concurrent classes that programmers (includingyou) will not be able to extend easily or usefully. Although they have no catchy name, similarobstacles may be encountered when trying to aggregate, compose, and delegate to objects.An approach that avoids some of the most common extensibility problems is to encapsulate bothguards and notifications in overridable methods and then structure public actions as:public synchronized void anAction() {awaitGuardsForThisAction();doAction();notifyOtherGuardsAffectedByThisAction();}However, just as in sequential OO programming, there are no universally valid rules for makingclasses that can serve as useful superclasses for all possible extensions or can be used withoutmodification in all possible contexts. Most guidelines for writing classes that avoid obstacles boildown to two well-known design rules:1. Avoid premature optimization.2. Encapsulate design decisions.Both of these rules can be surprisingly hard to follow. More often than not, avoiding optimizationrequires more abstraction and scaffolding than optimizing for known situations. Similarly, you cannotencapsulate a design decision unless you are aware that a decision has been made. This requirescontemplation of alternatives that may not occur to you upon first writing a class.Rules such as these are perhaps most commonly applied retrospectively, during cleanup of existingcode in efforts to make it more reusable. In an ideal world, you might be able to anticipate all the waysa purportedly reusable class must be opened up to make it more extensible. The world is almost neverthis ideal. Retrospective refactorings and iterative reworkings are honorable and routine aspects ofsoftware development.3.3.4 Confinement and Nested MonitorsAs discussed in § 2.3.3 and § 2.4.5, it is generally acceptable to confine synchronized Part objectswithin synchronized Host objects — at worst, you may encounter some superfluous locking overhead.However, this story becomes significantly more complicated for Parts that employ waiting andnotification methods. The associated issues are usually described as the nested monitor problem. Toillustrate the potential for lockout, consider the following minimal classes:class PartWithGuard {protected boolean cond = false;synchronized void await() throws InterruptedException {while (!cond)wait();// any other code}}synchronized void signal(boolean c) {cond = c;notifyAll();}class Host {protected final PartWithGuard part = new PartWithGuard();synchronized void rely() throws InterruptedException {part.await();}synchronized void set(boolean c) {part.signal(c);}}Guarded suspension makes sense when you believe that other threads can eventually unblock await . But here, the Host class structurally precludes other threads from executing code that coulddo so. Problems here stem from the fact that any thread waiting in a wait set retains all of its locksexcept that of the object in whose wait set it was placed. For example, suppose that in thread T a call ismade to host.rely causing it to block within part . The lock to host is retained while T isblocked: no other thread will ever get a chance to unblock it via host.set .These nesting constraints can lead to unexpected lockouts when otherwise ordinary-lookingsynchronized methods invoke other equally ordinary-looking synchronized methods that employwait . As with all policies for handling state-dependent behavior, you need to document andadvertise the wait policies employed in a class so that people trying to use them have a chance toaddress potential problems. Simply adding InterruptedException to the signatures ofguarded methods is a good start.There are two general approaches to avoiding nested monitor lockouts. The first and simplest (in fact,just an application of our default rules in § 1.1.1.1) is not to employ Host synchronization in the Hostmethods that relay to Part methods. This applies whenever the call is stateless with respect to the Host(see § 2.4.1).In other cases, where Part methods must access locked Host state, you can redefine Part classes to usean extended form of hierarchical containment locking (see § 2.4.5) employing the Host as the monitor.For example:class OwnedPartWithGuard {// Code sketchprotected boolean cond = false;final Object lock;OwnedPartWithGuard(Object owner) { lock = owner; }void await() throws InterruptedException {synchronized(lock) {while (!cond)lock.wait();// ...}}void signal(boolean c) {synchronized(lock) {cond = c;lock.notifyAll();}}}3.3.5 Further ReadingsMore thorough discussions and further examples of inheritance anomalies can be found in thecollection edited by Agha, Wegner, and Yonezawa listed in § 1.2.5, as well as in papers presented atrecent OO conferences such as ECOOP, the thesis by David Holmes listed in § 1.4.5, and in:McHale, Ciaran. Synchronization in Concurrent Object-Oriented Languages, PhD Thesis, TrinityCollege, Ireland, 1994.The Composition-Filters system is an example of an OO development framework that requiresseparation of functionality from synchronization control. It also includes a more extensive notationthan conflict sets for representing concurrency control constraints. See for example, papers byMehmet Aksit and others in the collection edited by Guerraoui, Nierstrasz, and Riveill listed in §1.2.5.Techniques for representing states and transitions (for example using finite state machines) aredescribed in most accounts of OO and concurrent software design listed in § 1.3.5. Additional patternsare discussed in:Dyson, Paul, and Bruce Anderson. "State Patterns", in Robert Martin, Dirk Riehle, and FrankBuschmann (eds.), Pattern Languages of Program Design, Volume 3, Addison-Wesley, 1998.The inner classes used in RWLock illustrate a simple, non-queryable version of the Extension Objectpattern. See:Gamma, Erich. "Extension Object", in Robert Martin, Dirk Riehle, and Frank Buschmann (eds.),Pattern Languages of Program Design, Volume 3, Addison-Wesley, 1998.3.4 Using Concurrency Control UtilitiesBuilt-in waiting and notification methods provide sufficient mechanisms for implementing any kind ofstate-dependent coordination scheme. But they present three related obstacles:•••The requirements and properties of waiting and notification methods often intrude intoapparently unrelated aspects of class design, leading to unnecessary conceptual overhead andcode complexity. For example, while the template-method version of Readers and Writers in§ 3.3.3 is sound and flexible, using it requires more understanding of the underlying designthan does the version supporting the ReadWriteLock interface in § 2.5.2.While simple applications of monitor methods are indeed simple, the chances for error (forexample slipped conditions) can increase dramatically when additional factors are addressed,especially performance and robustness in the face of thread cancellation. When solutions areencapsulated as utility classes, the hard work of putting them together need be done onlyonce. This may be worthwhile even when the resulting classes impose additionalprogramming obligations on their users, as long as reusing classes is not more difficult anderror-prone than re-inventing them. To improve software quality, utility classes (of any sort)should encapsulate not-so-simple implementations of simple ideas and impose minimalobstacles surrounding their use.While an unbounded number of designs can in principle be implemented via guardedmethods, a large fraction of those used in practice fall under a small number of generalcategories. Much of the code for these can be reused, rather than rewritten from scratch insideeach class using them. This also provides a clearer separation between the choice of aparticular concurrency control policy and its implementation.This section discusses four representative examples of utilities and their applications, including theconstruction of larger utilities out of more basic ones. A few others are introduced later in this book.For concreteness, descriptions focus on the versions available in the util.concurrent package,but nearly all discussions apply to any others you could construct. Most implementation detailssurrounding these classes are postponed to § 3.7 (which is probably of interest only to developerscreating their own customized versions of such utilities).3.4.1 SemaphoresSemaphores (specifically, counting semaphores) are classic concurrency control constructs. Likemany other utilities, they conform to an acquire-release protocol, and thus support the same Syncinterface as class Mutex in § 2.5.Conceptually, a semaphore maintains a set of permits initialized in a constructor. Each acquireblocks if necessary until a permit is available, and then takes it. Method attempt is the same exceptthat it fails upon time-out. Each release adds a permit. However, no actual permit-objects areused; the semaphore just keeps track of the number available and acts accordingly.There are other ways to describe semaphores as well, including those based on their originalmotivating metaphor: the signaling flags used to prevent railroad collisions.3.4.1.1 Mutual exclusion locksSemaphores can be used to implement mutual exclusion locks simply by initializing the number ofpermits to 1 . For example, a Mutex class could be defined as:class Mutex implements Sync {private Semaphore s = new Semaphore(1);public void acquire() throws InterruptedException {s.acquire();}public void release(); {s.release();}public boolean attempt(long ms) throws InterruptedException {return s.attempt(ms);}}This kind of lock is also known as a binary semaphore, since the counter should only take on thevalues zero and one. One minor detail that is not (but could be) addressed here is that by the mostcommon convention, releasing a Mutex that is not held has no effect. (A less common alternativeconvention is to throw an exception.) Otherwise, there is no strict need to define a Mutex class at all.A Semaphore initialized to 1 can be used directly as a lock, in which case "extra" releases areremembered and thus allow extra acquires. While this property is not at all desirable here, in contextsunrelated to locking it can be exploited as a cure for missed signals (see § 3.2.4.1).Because semaphores can be used as locks as well as other forms of concurrency control, they sufficeas a single primitive concurrency control construct. For example, it is possible to implement theequivalents of synchronized method locks, wait , notify , and notifyAll operations outof semaphores rather than vice versa. (For details, see for example Andrews's book listed in theFurther Readings in § 1.2.5.)Several systems and languages have in fact offered semaphores as their sole concurrency controlconstruct. However, overreliance on bare semaphores for mutual exclusion purposes tends to be morecomplex and error-prone than block-structured locking, as enforced by synchronized methodsand blocks and assisted by before/after constructions surrounding the use of Mutex . Semaphores aremuch more valuable in contexts that exploit their counting and signaling capabilities rather than theiruse as locks.3.4.1.2 Resource poolsSemaphores are specialized counters, and so are natural choices for concurrency control in manyclasses involving counts. For example, pool classes of various kinds normally keep counts of resourceitems (e.g., file descriptors, printers, buffers, large graphical objects) that clients can check out andlater check back in.The following Pool class illustrates the basic structure of most resource pools. This class containsonly one of several common and useful safeguards, ensuring that items checked back into the pool hadactually been checked out. Others could be added, for example, checks to make sure that callers areeligible to obtain items.To aid conformance to this check-out/check-in protocol, users of pools should normally employbefore/after constructions, as in:try {Object r = pool.getItem();try { use(r); }finally { pool.returnItem(r); }}catch (InterruptedException ie) {// deal with interrupt while trying to obtain item}The Pool class displays a layered structure characteristic of nearly all classes using concurrencycontrol utilities: public unsynchronized control methods surround internal synchronized helpermethods. Exclusion is needed in methods doGet and doReturn because multiple clients may passavailable.acquire . Without locking, several threads could operate concurrently on theunderlying lists. On the other hand, it would be a mistake to declare the getItem andreturnItem methods as synchronized . Not only would this make no sense, it can also causea form of nested monitor lockout (see § 3.3.4) when a thread waiting in acquire holds the lockneeded by any thread that could perform a release .class Pool {// Incompleteprotected java.util.ArrayList items = new ArrayList();protected java.util.HashSet busy = new HashSet();protected final Semaphore available;public Pool(int n) {available = new Semaphore(n);initializeItems(n);}public Object getItem() throws InterruptedException {available.acquire();return doGet();}public void returnItem(Object x) {if (doReturn(x))available.release();}protected synchronized Object doGet() {Object x = items.remove(items.size()-1);busy.add(x); // put in set to check returnsreturn x;}protected synchronized boolean doReturn(Object x) {if (busy.remove(x)) {items.add(x); // put back into available item listreturn true;}else return false;}protected void initializeItems(int n) {// Somehow create the resource objects// and place them in items list.}}Note that the use of HashSet here requires that the classes defining resource items not overridemethod equals in a way that disrupts the identity-based comparisons (see § 2.1.1) needed for poolmaintenance.3.4.1.3 Bounded buffersSemaphores are useful tools whenever you can conceptualize a design in terms of permits. Forexample, we can design a BoundedBuffer based on the idea that:•••Initially, for a buffer of size n, there are n put-permits and 0 take-permits.A take operation must acquire a take-permit and then release a put-permit.A put operation must acquire a put-permit and then release a take-permit.To exploit this, it is convenient to isolate the underlying array operations in a simpleBufferArray helper class. (In fact, as illustrated in § 4.3.4, a completely different underlying datastructure such as a linked list can be used without otherwise altering the logic of this design.) TheBufferArray class uses synchronized methods, maintaining exclusion when multipleclients receive permits and could otherwise insert or extract elements concurrently.class BufferArray {protected final Object[] array; // the elementsprotected int putPtr = 0;// circular indicesprotected int takePtr = 0;BufferArray(int n) { array = new Object[n]; }synchronized void insert(Object x) { // put mechanicsarray[putPtr] = x;putPtr = (putPtr + 1) % array.length;}synchronized Object extract() {// take mechanicsObject x = array[takePtr];array[takePtr] = null;takePtr = (takePtr + 1) % array.length;return x;}}The corresponding BoundedBufferWithSemaphores class surrounds buffer operations withsemaphore operations to implement put and take . Even though each method starts with anacquire and ends with a release , they follow a different usage pattern than seen with locks in §2.5. The release is on a different semaphore from the acquire, and is performed only after the elementis successfully inserted or extracted. So, among other consequences, these releases are not placed infinally clauses: If there were any chance that buffer operations could fail, some recoveryactions would be needed, but these trailing release statements are not among them.class BoundedBufferWithSemaphores {protected final BufferArray buff;protected final Semaphore putPermits;protected final Semaphore takePermits;public BoundedBufferWithSemaphores(int capacity) {if (capacity <= 0) throw new IllegalArgumentException();buff = new BufferArray(capacity);putPermits = new Semaphore(capacity);takePermits = new Semaphore(0);}public void put(Object x) throws InterruptedException {putPermits.acquire();buff.insert(x);takePermits.release();}public Object take() throws InterruptedException {takePermits.acquire();Object x = buff.extract();putPermits.release();return x;}public Object poll(long msecs) throws InterruptedException {if (!takePermits.attempt(msecs)) return null;Object x = buff.extract();putPermits.release();return x;}public boolean offer(Object x, long msecs)throws InterruptedException {if (!putPermits.attempt(msecs)) return false;buff.insert(x);takePermits.release();return true;}}This class also includes variants of put and take , called offer and poll , that support balking(when msecs is 0) or time-out policies. These methods are implemented usingSemaphore.attempt , which handles the messy time-based constructions described in § 3.2.5.Methods offer and poll allow clients to choose the guarding policy most appropriate for theirneeds. However, clients must still pick compatible policies. For example, if a producer relied solely onoffer(x , 0) and its only consumer used poll(0) , items would rarely be transferred.The BoundedBufferWithSemaphores class is likely to run more efficiently than theBoundedBufferWithStateTracking class in § 3.3.1 when there are many threads allusing the buffer. BoundedBufferWithSemaphores relies on two different underlying waitsets. The BoundedBufferWithStateTracking class gets by with only one, so any empty-to-partial or full-to-partial state transition causes all waiting threads to wake up, including thosewaiting for the other logical condition and those that will immediately rewait because some otherthread took the only item or filled the only available slot.The BoundedBufferWithSemaphore s class isolates the monitors for these two conditions.This can be exploited by the underlying Semaphore implementation (see § 3.7.1) to eliminateunnecessary context switching by using notify instead of notifyAll . This reduces the worst-case number of wakeups from being a quadratic function of the number of invocations to being linear.More generally, whenever you can isolate a condition using a semaphore, you can usually improveperformance as compared to notifyAll -based solutions.3.4.1.4 Synchronous channelsAs mentioned in § 3.3.1, the interface for BoundedBuffer can be broadened to describe any kindof Channel that supports a put and a take operation:interface Channel {// Repeatedvoid put(Object x) throws InterruptedException;Object take()throws InterruptedException;}(The util.concurrent version of this interface also includes the offer and poll methodsthat support time-outs, and declares it to extend interfaces Puttable and Takable to allow typeenforcement of one-sided usages.)There are many possible semantics that you might attach to a Channel . For example, the queueclass in § 2.4.2 has unbounded capacity (at least conceptually — failing only when a system runs outof memory), while bounded buffers have finite predetermined capacity. A limiting case is the idea of asynchronous channel that has no internal capacity. With synchronous channels, every threadattempting a put must wait for a thread attempting a take , and vice versa. This allows the precisecontrol over thread interaction needed in several of the design frameworks and patterns discussed in §4.1.4 and § 4.5.1.Semaphores can be used to implement synchronous channels. Here, we can use the same approach aswith bounded buffers, adding another semaphore that permits a put to continue only after its offereditem has been taken. However, this introduces a new problem. So far, we have used only blockingconstructions that can throw InterruptedExceptions as the first lines of methods, allowingsimple clean exit upon interruption. But here, we need to do a second acquire at the end of theput method. Aborting at this point of no return would break the protocol. While it is possible todefine a version of this class that performs full rollback, the simplest solution here is to roll forward(see § 3.1.1.4), ignoring any interrupt until after the second acquire completes:class SynchronousChannel implements Channel {protected Object item = null;// to hold while in transitprotected final Semaphore putPermit;protected final Semaphore takePermit;protected final Semaphore taken;public SynchronousChannel() {putPermit = new Semaphore(1);takePermit = new Semaphore(0);taken = new Semaphore(0);}public void put(Object x) throws InterruptedException {putPermit.acquire();item = x;takePermit.release();// Must wait until signaled by takerInterruptedException caught = null;for (;;) {try {taken.acquire();break;}catch(InterruptedException ie) { caught = ie; }}if (caught != null) throw caught; // can now rethrow}public Object take() throws InterruptedException {takePermit.acquire();Object x = item;item = null;putPermit.release();taken.release();return x;}}3.4.1.5 Fairness and schedulingBuilt-in waiting and notification methods do not provide any fairness guarantees. They make nopromises about which of the threads in a wait set will be chosen in a notify operation, or whichthread will grab the lock first and be able to proceed (thus excluding others) in a notifyAlloperation.This flexibility in JVM implementations permitted by the JLS makes it all but impossible to proveparticular liveness properties of a system. But this is not a practical concern in most contexts. Forexample, in most buffer applications, it doesn't matter at all which of the several threads trying totake an item actually do so. On the other hand, in a resource pool management class, it is prudent toensure that threads waiting for needed resource items don't continually get pushed aside by othersbecause of unfairness in how the underlying notify operations choose which threads to unblock.Similar concerns arise in many applications of synchronous channels.It is not possible to change the semantics of notify , but it is possible to implement Semaphore(sub)class acquire operations to provide stronger fairness properties. A range of policies can besupported, varying in exactly how fairness is defined.The best-known policy is First-In-First-Out (FIFO), in which the thread that has been waiting thelongest is always selected. This is intuitively desirable, but can be unnecessarily demanding and evensomewhat arbitrary on multiprocessors where different threads on different processors start waiting at(approximately) the same time. However, various weakenings of and approximations to FIFO areavailable that provide sufficient fairness for applications that need to avoid indefinite postponement.There are, however, some intrinsic limitations to such guarantees: There is no way to ensure that anunderlying system will ever actually execute a given runnable process or thread unless the systemprovides guarantees that go beyond the minimal requirements stated in the JLS. However, this isunlikely to be a significant pragmatic issue. Most if not all JVM implementations strive to providesensible scheduling policies that extend well beyond minimal requirements. They display some sort ofweak, restricted, or probabilistic fairness properties with respect to executing runnable threads.However, it is difficult for a language specification to state all the reasonable ways in which this mayoccur. The matter is left as a quality-of-implementation issue in the JLS.Utility classes such as semaphores are convenient vehicles for establishing different fairness policies,modulo these scheduling caveats. For example, § 3.7.3 describes implementation of aFIFOSemaphore class that maintains FIFO notification order. Applications such as the Poolclass can use this or other implementations of semaphores that provide any supported fairnessproperties, at the potential cost of additional overhead.3.4.1.6 PrioritiesIn addition to addressing fairness, semaphore implementation classes can pay attention to threadpriorities. The notify method is not guaranteed to do so, but it is of course allowed to, and does soon some JVM implementations.Priority settings (see § 1.1.2.3) tend to be of value only when there may be many more runnablethreads than CPUs, and the tasks running in these threads intrinsically have different urgencies orimportances. This occurs most commonly in embedded (soft) real-time systems where a single smallprocessor must carry out many tasks that interact with its environment.Reliance on priority settings can complicate notification policies. Even if notifications unblock (andrun) threads in highest-priority-first order, systems may still encounter priority inversions. A priorityinversion occurs when a high-priority thread becomes blocked waiting for a low-priority thread tocomplete and then release a lock or change a condition needed by the high-priority thread. In a systemusing strict priority scheduling, this can cause the high-priority thread to starve if the low-prioritythread does not get a chance to run.One solution is to use special semaphore classes or lock classes constructed via such semaphores.Here, the concurrency control objects themselves manipulate priorities. When a high-priority threadbecomes blocked, the concurrency control object can temporarily raise the priority of a low-prioritythread that could unblock it. This reflects the fact that proceeding to a release point is a high-priorityaction (see Further Readings in § 1.2.5). For this to work, all relevant synchronization and lockingmust rely on such priority-adjusting utility classes.Further, this tactic is guaranteed to maintain the intended properties only on particular JVMimplementations that use strict priority scheduling. In practice, any usable JVM implementationsupporting strict priority scheduling is sure to apply priority adjustment for built-in lock and monitoroperations. Doing otherwise would defeat most of the rationale for adopting strict priority schedulingin the first place.The main practical consequence is that programs that absolutely rely on strict priority schedulingsacrifice portability. They need additional JVM implementation-specific guarantees that may bebolstered via construction and use of additional concurrency control utilities. In other more portableprograms, semaphore classes and related utilities that prefer higher-priority threads can still be usedoccasionally as devices for heuristically improving responsiveness.3.4.2 LatchesA latching variable or condition is one that eventually receives a value from which it never againchanges. A binary latching variable or condition (normally just called a latch, also known as a one-shot) can change value only once, from its initial state to its final state.Concurrency control techniques surrounding latches can be encapsulated using a simple Latch classthat again obeys the usual acquire-release interface, but with the semantics that a single releasepermits all previous and future acquire operations to proceed.Latches help structure solutions to initialization problems (see § 2.4.1) where you do not want a set ofactivities to proceed until all objects and threads have been completely constructed. For example, amore ambitious game-playing application than shown in § 3.2.4 might need to ensure that all playerswait until the game officially begins. This could be arranged using code such as:class Player implements Runnable {// ...protected final Latch startSignal;// Code sketchPlayer(Latch l) { startSignal = l; }public void run() {try {startSignal.acquire();play();}catch(InterruptedException ie) { return; }}// ...}class Game {// ...void begin(int nplayers) {Latch startSignal = new Latch();for (int i = 0; i < nplayers; ++i)new Thread(new Player(startSignal)).start();startSignal.release();}}Extended forms of latches include countdowns, which allow acquire to proceed when a fixednumber of releases occur, not just one. Latches, countdowns, and other simple utilities built ontop of them can be used to coordinate responses to conditions involving:Completion indicators. For example, to force a set of threads to wait until some other activitycompletes.Timing thresholds. For example, to trigger a set of threads at a certain date.Event indications. For example, to trigger processing that cannot occur until a certain packet isreceived or button is clicked.Error indications. For example, to trigger a set of threads to proceed with global shut-down tasks.3.4.2.1 Latching variables and predicatesWhile utility classes are convenient for most one-shot triggering applications, latching fields (alsoknown as permanent variables) and predicates can improve reliability, simplify usage, and improveefficiency in other contexts as well.Among their other properties, latching predicates (including the common special case of thresholdindicators) are among the very few conditions for which unsynchronized busy-wait loops (see § 3.2.6)may be a possible (although rarely taken) implementation option for guarded methods. If a predicate isknown to latch, then there is no risk that it will slip (see § 3.2.4.1). Its value cannot change betweenthe check to see if it is true and a subsequent action that requires it to remain true. For example:class LatchingThermometer {// Seldom usefulprivate volatile boolean ready; // latchingprivate volatile float temperature;public double getReading() {while (!ready)Thread.yield();return temperature;}void sense(float t) { // called from sensortemperature = t;ready = true;}}Note that this kind of construction is confined to classes in which all relevant variables are eitherdeclared as volatile or are read and written only under synchronization (see § 2.2.7).3.4.3 ExchangersAn exchanger acts as a synchronous channel (see § 3.4.1.4) except that instead of supporting twomethods, put and take , it supports only one method, rendezvous (sometimes just calledexchange ) that combines their effects (see § 2.3.4). This operation takes an argument representingan Object offered by one thread to another, and returns the Object offered by the other thread.Exchangers can be generalized to more than two parties, and can be further generalized to applyarbitrary functions on arguments rather than simply exchanging them. These capabilities are supportedby the Rendezvous class in util.concurrent . But the majority of applications arerestricted to the exchange of resource objects among two threads (as arranged below by using only thedefault two-party constructor for Rendezvous ).Exchange-based protocols extend those described in § 2.3.4 to serve as alternatives to resource pools(see § 3.4.1.2). They can be used when two or more tasks running in different threads at all times eachmaintain one resource. When one thread is finished with one resource and needs another, it exchangeswith another thread. The most common application of this protocol is buffer exchange. Here, onethread fills up a buffer (for example by reading in data). When the buffer is full, it exchanges it with athread that processes the buffer, thereby emptying it. In this way, only two buffers are ever used, nocopying is needed, and a resource management pool becomes unnecessary.The following FillAndEmpty class gives a glimpse of the additional exception-handlingobligations required with exchangers. Because the protocol is symmetric, cancellation or time-out ofone party in the midst of an attempted exchange must lead to an exception (here,BrokenBarrierException ) in the other party. In the example below, this is handled simplyby returning from the run method. A more realistic version would entail further cleanup, includingadditional adjustments to deal with incompletely filled or emptied buffers upon termination, as well asto deal with IO exceptions and end-of-file conditions surrounding the readByte method.class FillAndEmpty {// Incompletestatic final int SIZE = 1024; // buffer size, for demoprotected Rendezvous exchanger = new Rendezvous(2);protected byte readByte() { /* ... */; }protected void useByte(byte b) { /* ... */ }public void start() {new Thread(new FillingLoop()).start();new Thread(new EmptyingLoop()).start();}class FillingLoop implements Runnable { // inner classpublic void run() {byte[] buffer = new byte[SIZE];int position = 0;try {for (;;) {if (position == SIZE) {buffer = (byte[])(exchanger.rendezvous(buffer));position = 0;}buffer[position++] = readByte();}}catch (BrokenBarrierException ex) {} // diecatch (InterruptedException ie) {} // die}}class EmptyingLoop implements Runnable { // inner classpublic void run() {byte[] buffer = new byte[SIZE];int position = SIZE; // force exchange first time throughtry {for (;;) {if (position == SIZE) {buffer = (byte[])(exchanger.rendezvous(buffer));position = 0;}useByte(buffer[position++]);}}catch (BrokenBarrierException ex) {} // diecatch (InterruptedException ex) {} // die}}}The use of exchangers here illustrates one of the design advantages of utility classes that replaceconcerns surrounding the fields of objects with those surrounding the passing of messages. This canbe much easier to deal with as coordination schemes scale up (see Chapter 4).3.4.4 Condition VariablesMonitor operations in the Java programming language maintain a single wait set for each object.Some other languages and thread libraries (in particular POSIX pthreads) include support for multiplewait sets associated with multiple condition variables managed under a common object or lock.While any design requiring multiple wait sets can be implemented using other constructions such assemaphores, it is possible to create utilities that mimic the condition variables found in other systems.In fact, support for pthreads-style condvars leads to usage patterns that are almost identical to those inconcurrent C and C++ programs.A CondVar class can be used to represent a condition variable that is managed in conjunction with agiven Mutex , where this Mutex is also (unenforceably) used for all exclusion locking in theassociated class(es). Thus, classes using CondVar must also rely on the "manual" lockingtechniques discussed in § 2.5.1. More than one CondVar can use the same Mutex [6] .[6]The converse that more than one Mutex serve the same condition variable is logically possible butusually reflects a programming error and is not supported by this class.The class supports analogs of the standard waiting and notification methods, here given names basedon those in pthreads:class CondVar {// Implementation omittedprotected final Sync mutex;public CondVar(Sync lock) { mutex = lock; }public void await() throws InterruptedException;public boolean timedwait(long ms) throwsInterruptedException;public void signal();// analog of notifypublic void broadcast();// analog of notifyAll}(In the util.concurrent version, the nuances of these operations also mirror those in pthreads.For example, unlike notify , signal does not require the lock to be held.)The main applications of such a class lie not in original design efforts, but in adapting code originallywritten using other languages and systems. In other respects, a CondVar may be employed in thesame design patterns, encountering the same design issues, as discussed in § 3.3. For example, here isanother bounded buffer class. Except for the structured exception handling, this version almost looksas if it came out of a pthreads programming book (see Further Readings in § 1.2.5).class PThreadsStyleBuffer {private final Mutex mutex = new Mutex();private final CondVar notFull = new CondVar(mutex);private final CondVar notEmpty = new CondVar(mutex);private int count = 0;private int takePtr = 0;private int putPtr = 0;private final Object[] array;public PThreadsStyleBuffer(int capacity) {array = new Object[capacity];}public void put(Object x) throws InterruptedException {mutex.acquire();try {while (count == array.length)notFull.await();array[putPtr] = x;putPtr = (putPtr + 1) % array.length;++count;notEmpty.signal();}finally {mutex.release();}}public Object take() throws InterruptedException {Object x = null;mutex.acquire();try {while (count == 0)notEmpty.await();x = array[takePtr];array[takePtr] = null;takePtr = (takePtr + 1) % array.length;--count;notFull.signal();}finally {mutex.release();}return x;}}3.4.5 Further ReadingsAdditional discussions and examples of semaphores and condition variables can be found in almostany book on concurrent programming (see § 1.2.5).Resource pools can be extended into more general Object Manager classes. See:Sommerlad, Peter. "Manager", in Robert Martin, Dirk Riehle, and Frank Buschmann (eds.), PatternLanguages of Program Design, Volume 3, Addison-Wesley, 1998.Exchangers are described in more detail in:Sane, Aamod, and Roy Campbell. "Resource Exchanger", in John Vlissides, James Coplien, andNorman Kerth (eds.), Pattern Languages of Program Design, Volume 2, Addison-Wesley, 1996.The approximate fairness of some commonly used scheduling policies is discussed in:Epema, Dick H. J. "Decay-Usage Scheduling in Multiprocessors", ACM Transactions on ComputerSystems, Vol. 16, 367-415, 1998.3.5 Joint ActionsSo far, this chapter has confined itself mainly to discussions of guarded actions that rely on the state ofa single object. Joint action frameworks provide a more general setting to attack more general designproblems. From a high-level design perspective, joint actions are atomic guarded methods that involveconditions and actions among multiple, otherwise independent participant objects. They can bedescribed abstractly as atomic methods involving two or more objects:void jointAction(A a, B b) {// PseudocodeWHEN (canPerformAction(a, b))performAction(a, b);}Problems taking this general, unconstrained form are encountered in distributed protocol development,databases, and concurrent constraint programming. As seen in § 3.5.2, even some ordinary-lookingdesign patterns relying on delegation require this kind of treatment when otherwise independentactions in otherwise independent objects must be coordinated.Unless you have a special-purpose solution, the first order of business in dealing with joint actions istranslating vague intentions or declarative specifications into something you can actually program.Considerations include:Allocating responsibility. Which object has responsibility for executing the action? One of theparticipants? All of them? A separate coordinator?Detecting conditions. How can you tell when the participants are in the right state to perform theaction? Do you ask them by invoking accessors? Do they tell you whenever they are in the right state?Do they tell you whenever they might be in the right state?Programming actions. How are actions in multiple objects arranged? Do they need to be atomic?What if one or more of them fails?Linking conditions to actions. How do you make sure that the actions occur only under the rightconditions? Are false alarms acceptable? Do you need to prevent one or more participants fromchanging state between testing the condition and performing the action? Do the actions need to beperformed when the participants enter the appropriate states, or merely whenever the conditions arenoticed to hold? Do you need to prevent multiple objects from attempting to perform the action at thesame time?3.5.1 General SolutionsNo small set of solutions addresses all issues across all contexts. But the most widely applicablegeneral approach is to create designs in which participants tell one another when they are (or may be)in appropriate states for a joint action, while at the same time preventing themselves from changingstate again until the action is performed.These designs provide efficient solutions to joint action problems. However, they can be fragile andnon-extensible, and can lead to high coupling of participants. They are potentially applicable whenyou can build special subclasses or versions of each of the participant classes to add particularnotifications and actions, and when you can prevent or recover from deadlocks that are otherwiseintrinsic in many joint action designs.The main goal is to define notifications and actions within synchronized code that nests correctlyacross embedded calls, in a style otherwise reminiscent of double-dispatching and the Visitor pattern(see the Design Patterns book). Very often, good solutions rely on exploiting special properties ofparticipants and their interactions. The combination of direct coupling and the need to exploit anyavailable constraints to avoid liveness failures accounts for the high context dependence of many jointaction designs. This in turn can lead to classes with so much special-purpose code that they must bemarked as final .3.5.1.1 StructureFor concreteness, the following descriptions are specific to the two-party case (for classes A and B ),but can be generalized to more than two. Here, state changes in either participant can lead tonotifications to the other. These notifications can in turn lead to coordinated actions in either or bothparticipants.Designs can take either of two characteristic forms. Flat versions couple participant objects directly:Explicitly coordinated versions route some or all messages and notifications through a third object (aform of Mediator — see the Design Patterns book) that may also play some role in the associatedactions. Coordination through third parties is rarely an absolute necessity, but can add flexibility andcan be used to initialize objects and connections:3.5.1.2 Classes and methodsThe following generic steps can be applied when constructing the corresponding classes and methods:•Define versions (often subclasses) of A and B that maintain references to each other, alongwith any other values and references needed to check their parts in triggering conditions••••and/or to perform the associated actions. Alternatively, link participants indirectly with thehelp of a coordinator class.Write one or more methods that perform the main actions. This can be done by choosing oneof the classes to house the main action method, which in turn calls secondary helper methodsin the other. Alternatively, the main action can be defined in the coordinator class, in turncalling helper methods in A and B .In both classes, write synchronized methods designed to be called when the otherobject changes state. For example, in class A , write method Bchanged , and in class B ,write Achanged . In each, write code to check if the host object is also in the correct state.If the resulting actions involve both participants, they must be performed without losing eithersynchronization lock.In both classes, arrange that the other's changed method is called upon any change thatmay trigger the action. When necessary, ensure that the state-change code that leads to thenotification is appropriately synchronized, guaranteeing that the entire check-and-actsequence is performed before breaking the locks held on both of the participants at the onsetof the change.Ensure that connections and states are initialized before instances of A and B are allowed toreceive messages that result in interactions. This can be arranged most easily via acoordinator class.These steps are almost always somehow simplified or combined by exploiting available situation-dependent constraints. For example, several substeps disappear when notifications and/or actions arealways based in only one of the participants. Similarly, if the changed conditions involve simplelatching predicates (see § 3.4.2), then there is typically no need for synchronization to bridgenotifications and actions. And if it is permissible to establish a common lock in the coordinator classand use it for all methods in classes A and B (see § 2.4.5), you can remove all other synchronization,and then treat this as a disguised form of a single-object concurrency control problem, usingtechniques from § 3.2-§ 3.4.3.5.1.3 LivenessWhen all notifications and actions are symmetrical across participants, the above steps normally yielddesigns that have the potential for deadlock. A sequence starting with an action issuing Achangedcan deadlock against one issuing Bchanged . While there is no universal solution, conflict-resolution strategies for addressing deadlock problems include the following approaches. Some ofthese remedies require extensive reworking and iterative refinement.Forcing directionality. For example, requiring that all changes occur via one of the participants. Thisis possible only if you are allowed to change the interfaces of the participants.Precedence. For example, using resource ordering (see § 2.2.6) to avoid conflicting sequences.Back-offs. For example, ignoring an update obligation if one is already in progress. As illustrated inthe example below, update contention can often be simply detected and safely ignored. In other cases,detection may require the use of utility classes supporting time-outs, and semantics may require that aparticipant retry the update upon failure.Token passing. For example, enabling action only by a participant that holds a certain resource,controlled via ownership-transfer protocols (see § 2.3.4).Weakening semantics. For example, loosening atomicity guarantees when they turn out not to impactbroader functionality (see § 3.5.2).Explicit scheduling. For example, representing and managing activities as tasks, as described in §4.3.4.3.5.1.4 ExampleTo illustrate some common techniques, consider a service that automatically transfers money from asavings account to a checking account whenever the checking balance falls below some threshold, butonly if the savings account is not overdrawn. This operation can be expressed as a pseudocode jointaction:void autoTransfer(BankAccount checking,// PseudocodeBankAccount savings,long threshold,long maxTransfer) {WHEN (checking.balance() < threshold &&savings.balance() >= 0) {long amount = savings.balance();if (amount > maxTransfer) amount = maxTransfer;savings.withdraw(amount);checking.deposit(amount);}}We'll base a solution on a simple BankAccount class:class BankAccount {protected long balance = 0;public synchronized long balance() {return balance;}public synchronized void deposit(long amount)throws InsufficientFunds {if (balance + amount < 0)throw new InsufficientFunds();elsebalance += amount;}public void withdraw(long amount) throws InsufficientFunds {deposit(-amount);}}Here are some observations that lead to a solution:•••••There is no compelling reason to add an explicit coordinator class. The required interactionscan be defined in special subclasses of BankAccount .The action can be performed if the checking balance decreases or the savings balanceincreases. The only operation that causes either one to change is deposit (sincewithdraw is here defined to call deposit ), so versions of this method in each classinitiate all transfers.Only a checking account needs to know about the threshold , and only a savings accountneeds to know about the maxTransfer amount. (Other reasonable factorings would leadto slightly different implementations.)On the savings side, the condition check and action code can be rolled together by definingthe single method transferOut to return zero if there is nothing to transfer, andotherwise to deduct and return the amount.On the checking side, a single method tryTransfer can be used to handle bothchecking-initiated and savings-initiated changes.Without further care, the resulting code would be deadlock-prone. This problem is intrinsic insymmetrical joint actions in which changes in either object could lead to an action. Here, both asavings account and a checking account can start their deposit sequences at the same time. We need away to break the cycle that could lead to both being blocked while trying to invoke each other'smethods. (Note that deadlock would never occur if we require only that the action take place whenchecking balances decrease. This would in turn lead to a simpler solution all around.)For illustration, potential deadlock is addressed here in a common (although of course not universallyapplicable) fashion, via a simple untimed back-off protocol. The tryTransfer method uses aboolean utility class supporting a testAndSet method that atomically sets its value to true andreports its previous value. (Alternatively, the attempt method of a Mutex could be used here.)class TSBoolean {private boolean value = false;// set to true; return old valuepublic synchronized boolean testAndSet() {boolean oldValue = value;value = true;return oldValue;}public synchronized void clear() {value = false;}}An instance of this class is used to control entry into the synchronized part of the mainchecking-side method tryTransfer , which is the potential deadlock point in this design. Ifanother transfer is attempted by a savings account while one is executing (always, in this case, onethat is initiated by the checking account), then it is just ignored without deadlocking. This isacceptable here since the executing tryTransfer and transferOut operations are based onthe most recently updated savings balance anyway.All this leads to the following very special subclasses of BankAccount , tuned to work only in theirgiven context. Both classes rely upon an (unshown) initialization process to establish interconnections.The decision on whether to mark the classes as final is a close call. However, there is just enoughlatitude for minor variation in the methods and protocols not to preclude knowledgeable subclassauthors from, say, modifying the transfer conditions in shouldTry or the amount to transfer intransferOut .class ATCheckingAccount extends BankAccount {protected ATSavingsAccount savings;protected long threshold;protected TSBoolean transferInProgress = new TSBoolean();public ATCheckingAccount(long t) { threshold = t; }// called only upon initializationsynchronized void initSavings(ATSavingsAccount s) {savings = s;}protected boolean shouldTry() { return balance < threshold; }void tryTransfer() { // called internally or from savingsif (!transferInProgress.testAndSet()) { // if not busy ...try {synchronized(this) {if (shouldTry()) balance += savings.transferOut();}}finally { transferInProgress.clear(); }}}public synchronized void deposit(long amount)throws InsufficientFunds {if (balance + amount < 0)throw new InsufficientFunds();else {balance += amount;tryTransfer();}}}class ATSavingsAccount extends BankAccount {protected ATCheckingAccount checking;protected long maxTransfer;public ATSavingsAccount(long max) {maxTransfer = max;}// called only upon initializationsynchronized void initChecking(ATCheckingAccount c) {checking = c;}synchronized long transferOut() { // called only fromcheckinglong amount = balance;if (amount > maxTransfer)amount = maxTransfer;if (amount >= 0)balance -= amount;return amount;}public synchronized void deposit(long amount)throws InsufficientFunds {if (balance + amount < 0)throw new InsufficientFunds();else {balance += amount;checking.tryTransfer();}}}3.5.2 Decoupling ObserversThe best way to avoid the design and implementation issues surrounding full joint-action designs isnot to insist that operations spanning multiple independent objects be atomic in the first place. Fullatomicity is rarely necessary, and can introduce additional downstream design problems that impedeuse and reuse of classes.To illustrate, consider the Observer pattern from the Design Patterns book:In the Observer pattern, Subjects (sometimes called Observables) represent the state of whatever theyare modeling (for example a Temperature ) and have operations to reveal and change this state.Observers somehow display or otherwise use the state represented by Subjects (for example bydrawing different styles of Thermometers ). When a Subject's state is changed, it merely informsits Observers that it has changed. Observers are then responsible for probing Subjects to determine thenature of the changes via callbacks checking whether, for example, Subject representations need to bere-displayed on a screen.The Observer pattern is seen in some GUI frameworks, publish-subscribe systems, and constraint-based programs. A version is defined in classes java.util.Observable andjava.util.Observer , but they are not as of this writing used in AWT or Swing (see § 4.1.4).It is all too easy to code an Observer design as a synchronized joint action by mistake, withoutnoticing the resulting potential liveness problems. For example, if all methods in both classes aredeclared as synchronized and Observer.changed can ever be called from outside of theSubject.changeValue method, then it would be possible for these calls to deadlock:This problem could be solved by one of the techniques discussed in § 3.5.1. However, it is easier andbetter just to avoid it. There is no reason to synchronize operations surrounding change notificationsunless you really need Observer actions to occur atomically in conjunction with any change in theSubject . In fact, this requirement would defeat most of the reasons for using the Observer patternin the first place.Instead, here you can apply our default rules from § 1.1.1.1 and release unnecessary locks whenmaking calls from Subjects to Observers , which serves to implement the desired decoupling.This permits scenarios in which a Subject changes state more than once before the change isnoticed by an Observer , as well as scenarios in which the Observer doesn't notice any changewhen invoking getValue . Normally, these semantic weakenings are perfectly acceptable and evendesirable.Here is a sample implementation in which Subject just uses a double as an example of modeledstate. It uses the CopyOnWriteArrayList class described in § 2.4.4 to maintain itsobservers list. This avoids any need for locking during traversal, which helps satisfy the designgoals. For simplicity of illustration, Observer here is defined as a concrete class (rather than as aninterface with multiple implementations) and can deal with only a single Subject .class Subject {protected double val = 0.0; // modeled stateprotected final CopyOnWriteArrayList observers =new CopyOnWriteArrayList();public synchronized double getValue() { return val; }protected synchronized void setValue(double d) { val = d; }public void attach(Observer o) { observers.add(o); }public void detach(Observer o) { observers.remove(o); }public void changeValue(double newstate) {setValue(newstate);for (Iterator it = observers.iterator(); it.hasNext();)((Observer)(it.next())).changed(this);}}class Observer {protected double cachedState;protected final Subject subj;public Observer(Subject s) {subj = s;cachedState = s.getValue();display();}// last known state// only one allowed herepublic synchronized void changed(Subject s){if (s != subj) return;// only one subjectdouble oldState = cachedState;cachedState = subj.getValue(); // probeif (oldState != cachedState)display();}protected void display() {// somehow display subject state; for example just:System.out.println(cachedState);}}3.5.3 Further ReadingsJoint actions serve as a unifying framework for characterizing multiparty actions in the DisComodeling and specification language:Jarvinen, Hannu-Matti, Reino Kurki-Suonio, Markku Sakkinnen and Kari Systa. "Object-OrientedSpecification of Reactive Systems", Proceedings, 1990 International Conference on SoftwareEngineering, IEEE, 1990.They are further pursued in a slightly different context in IP, which also addresses different senses offairness that may apply to joint action designs. For example, designs for some problems avoidconspiracies among some participants to starve out others. See:Francez, Nissim, and Ira Forman. Interacting Processes, ACM Press, 1996.For a wide-ranging survey of other approaches to task coordination among objects and processes, see:Malone, Thomas, and Kevin Crowston. "The Interdisciplinary Study of Coordination", ACMComputing Surveys, March 1994.Joint action frameworks can provide the basis for implementing the internal mechanisms supportingdistributed protocols. For some forward-looking presentations and analyses of protocols amongconcurrent and distributed objects, see:Rosenschein, Jeffrey, and Gilad Zlotkin. Rules of Encounter: Designing Conventions for AutomatedNegotiation Among Computers, MIT Press, 1994.Fagin, Ronald, Joseph Halpern, Yoram Moses, and Moshe Vardi. Reasoning about Knowledge, MITPress, 1995.A joint action framework that accommodates failures among participants is described in:Stroud, Robert, and Avelino Zorzo. "A Distributed Object-Oriented Framework for DependableMultiparty Interactions", Proceedings of OOPSLA, ACM, 1999.3.6 TransactionsIn the context of concurrent OO programming, a transaction is an operation performed by an arbitraryclient that invokes an arbitrary set of methods on an arbitrary set of participant objects, all withoutinterference from other activities.The arbitrariness of both the participants and the action sequences requires extensions of the jointaction control strategies discussed in § 3.5. Transaction techniques extend delegation-basedsynchronization and control to situations in which each participant may be unaware of the atomicityconstraints placed on its actions, and cannot rely on more efficient structural solutions. In transactionframeworks, each participant (and each client) gives up its local autonomy in deciding how to performconcurrency control. Participants must instead reach consensus deciding how and when to performactions and/or to commit to their effects.Transaction frameworks are among the most famous examples of how providing components thatimplement valuable general-purpose functionality sometimes has the price of introducing a largenumber of programmer obligations. Classes supporting transaction protocols can be highly usable andreusable. Transaction frameworks can be used to tackle most of the concurrency problems discussedin this book. But they rely on designs in which each class, at each layer of functionality, supports astandardized transaction protocol that propagates control down through successive layers. Theheaviness of transaction frameworks usually restricts their use to contexts in which you really need toset up objects so as to guarantee atomicity of arbitrary code sequences.For example, you may be able to bypass transactional control if you know all the call-sequences thatwill ever be encountered in a component or application. In this case, you can specifically designsupport for each one (using whatever techniques happen to apply) without having to address thegeneral case. This is a perhaps extreme extension of the idea (see § 2.2.2) of padding reusablesynchronized objects with atomic versions of frequently needed convenience methods. This issometimes a plausible alternative, in the spirit of doing the simplest and surest thing that couldpossibly work. Similarly, you may be able to rely entirely on client-side locking (see § 2.2.3) in caseswhere clients somehow know to obtain all locks required for a given action and how to avoid anypotential deadlocks.This section provides a brief overview of transaction-based techniques applicable in general-purposeconcurrent programming contexts. The designs presented here deal only with internal concurrency,and not explicitly with databases or distribution. Because even lightweight (at least in a relative sense)internal transaction frameworks are normally tied to other application-specific constraints andfeatures, you are unlikely to use the exact interfaces and classes described here (although most aresimplified variants of those in the net.jini package). And if you instead rely on a standardizedtransaction framework such as JDBC or JTS, you will encounter additional issues tied to persistencesupport and related services that fall outside the scope of this book. However, the final example in thissection (§ 3.6.4) illustrates how the ideas behind transactions can help structure more ordinaryconcurrent OO designs. Thus, the main goals of this section are to give a brief synopsis of howtransaction systems extend other approaches to concurrency control, and to present techniques thatmay be scaled down as needed to apply to other concurrency problems.As a running example, consider again writing a transfer operation for the BankAccount classin § 3.5.1. From a transactional point of view, a stand-alone transfer operation (without any provisionsfor automatic transfers) looks like:pseudoclass AccountUser {// PseudocodeTransactionLogger log; // any kind of logging facility// ...// Attempt transfer; return true if successfulpublic boolean transfer(long amount,BankAccount source,BankAccount destination) {TRANSACTIONALLY {if (source.balance() >= amount) {log.logTransfer(amount, source, destination);source.withdraw(amount);destination.deposit(amount);return true;}elsereturn false;}}}The TRANSACTIONALLY pseudo-qualifier indicates that we'd like this code to be executed in anall-or-none fashion without any possibility of interference from other activities. Once implemented,this operation could be used in an automated transfer scheme of the sort described in § 3.5.1.Additionally, the transactional approach permits greater flexibility than seen in our specific solution,although with significantly greater overhead. Once classes are fitted with transactional apparatus, itbecomes possible to associate transactionality with any sequence of operations involving bankaccounts.3.6.1 Transaction ProtocolsTransaction frameworks rely on extended forms of the before/after tactics characteristic of mostconcurrency control strategies. Here, the before-action is typically called join (or sometimes, begin)and the after-action is called commit. The main differences between join/commit and operations suchas lock acquire/release stem from the fact that join/commit require consensus among the set ofparticipating objects: All participants must agree to begin and end transactions. This leads to two-phase protocols surrounding join and/or commit — first to obtain consensus and then to act. If anyparticipant disagrees about joining or committing, the attempted transaction is aborted. The moststraightforward version of the basic protocol is:1.2.3.4.For each participant p, if p cannot join, abort.For each participant p, tentatively execute p's action.For each participant p, if p cannot commit, abort.For each participant p, commit p's effects of the transaction.As in most concurrency control contexts, two complementary sets of policies can be applied to thisprotocol. In the purest form of optimistic transactions, participants can always join, but cannot alwayscommit. In the purest form of conservative transactions, participants cannot always join, but if theydo, they can always commit. Optimistic approaches apply best when the likelihood of contention islow enough to outweigh rollback costs. Conservative approaches apply best when it is difficult orimpossible to undo actions performed during transactions. However, it is rare to find pure forms ofeach, and it is not hard to create frameworks that permit mixtures.The most classic forms of conservative transactions can be implemented only if the identities of allparticipants can be known before any actions are taken. This is not always possible. In an OO system,the participants are just those objects whose methods are invoked during some call sequence that iswrapped as a transaction. Because of polymorphism, dynamic loading, etc., it is generally impossibleto identify them all beforehand; instead, their identities become known only as the action unfolds.Still, in many cases, at least some participants are known beforehand and they can be probed beforestarting to engage in any unrecoverable action.However, in most approaches to conservative OO transactions, participants join only tentatively. Theycan still later refuse to commit, using approximately the same strategy seen in optimistic transactions.Conversely, full rollback is not always necessary in optimistic approaches. Some roll-forwardoperations may be allowed if they do not impact overall functionality.3.6.2 Transaction ParticipantsIn addition to supporting methods for joining, committing, aborting, and (when necessary) creatingtransactions, each class in a structured transaction framework must declare all of its public methods toadd a transaction control argument to its set of normal arguments.A method invocation supplying a given transaction argument serves as a request to perform theassociated action on behalf of the given transaction, but without committing to its effects untilrequested to do so. Methods take the form:ReturnType aMethod(Transaction t, ArgType args) throws...For example, BankAccount.deposit would be declared as:void deposit(Transaction t, long amount) throws ...Transaction is any type that supplies the necessary control information. This transactioninformation must be propagated throughout all methods invoked in the course of a particulartransaction, including nested calls to helper objects. The simplest kind of transaction argument is atransaction key that uniquely identifies each transaction. Each method in each participating object isthen responsible for using this key to manage and isolate actions in accord with the given transactionpolicy. Alternatively, a transaction argument may refer to a special control or coordinator objectpossessing methods that help participants perform their roles in transactions.It is, however, possible to cheat here, and many transaction frameworks do. For example, transactionidentifiers can be hidden as thread-specific data (see § 2.3.2). Before/after control can be restricted tointercepted entry points into sessions performing services provided by components. Participants canbe determined via reflection or scanning bytecodes. And rollback obligations can be semi-automatedby serializing the entire state of a component and/or acquiring locks on entry into a service session.These kinds of tactics can help hide the details of transactional control from application writers. Thiscomes at the expense overhead and usage restrictions that are not generally worthwhile in lightweighttransaction frameworks performing internal concurrency control.3.6.2.1 InterfacesParticipant classes must implement interfaces defining the methods used in transaction control. Here isa simple but representative interface:class Failure extends Exception {}interface Transactor {// Enter a new transaction and return true, if possiblepublic boolean join(Transaction t);// Return true if this transaction can be committedpublic boolean canCommit(Transaction t);// Update state to reflect current transactionpublic void commit(Transaction t) throws Failure;// Roll back state (No exception; ignore if inapplicable)public void abort(Transaction t);}Among many other variants, it is possible to split the join phase similarly to the commit phase — apreliminary canJoin followed by a required join . The canCommit method is most oftennamed prepare in transaction frameworks.For simplicity of illustration, a single Failure exception type is associated with these operations,as well as all others in this series of examples. Participant objects are allowed to raise exceptions whenthey encounter actual or potential conflicts and when they are requested to participate in transactionsthey do not know about. Of course in practice, you'd want to subclass these exception types and usethem to provide additional information to clients in cases of failure.A second interface or class is needed to describe Transaction objects themselves. In discussingbasic operations, we can use a no-op version:class Transaction {// add anything you want here}Again, it is not even necessary to associate an object with a transaction. A simple unique longtransactionKey argument may suffice in place of all uses of Transaction . At the otherextreme, you may need a TransactionFactory for creating all Transactions . Thisallows different kinds of Transaction objects to be associated with different styles oftransactions.3.6.2.2 ImplementationsParticipants in transactions must support both a transaction participant interface and an interfacedescribing their basic actions. For example:interface TransBankAccount extends Transactor {public long balance(Transaction t) throws Failure;public void deposit(Transaction t, long amount)throws InsufficientFunds, Failure;public void withdraw(Transaction t, long amount)throws InsufficientFunds, Failure;}However, it is not always necessary to provide transactional signatures for pure accessor methods suchas balance here. Instead (or in addition to transactional versions), such methods can return themost recently committed value when called from clients that are not participating in transactions.Alternatively, a special null-transaction type (or just passing null for the Transactionargument) can be used to denote one-shot invocations of transactional methods.The most common approach to implementing transactional classes entails first splitting out underlyingstate representations into separate helper classes using either a provisional action or checkpointingapproach (see § 2.4.4 and § 3.1.1.3). This makes it easier to perform virtual state changes that areupdated only after commit operations and/or reverted from during abort operations. Thisapproach is especially appropriate in transaction frameworks supporting persistence, which oftenrequire representations to be isolated anyway in order to be efficiently read from and written to disksand other media.While this is by far the most tractable option, it leads to a sometimes-uncomfortable coding style inwhich objects must pretend to be in the states maintained by representations associated with particulartransactions. Each normal public method performs operations only on the state representationassociated with the given transaction, and invokes methods on other objects that are doing likewise.Implementations of transactional methods (both control methods and base actions) can span the rangefrom optimistic to conservative tactics. The following table sketches some highlights of the end-pointsfor methods invoked with Transaction argument tx :Methodjoin••OptimisticCreate a copy of state and associate itwith tx (for example in a hash table),along with some record of the versionof the state it originated with.Return true.•••ConservativeReturn false if alreadyparticipating in conflictingtransaction, optionally firsttrying a timed wait for it tocomplete.Ask all other objects referencedin action methods if they canjoin; return false if any cannot.Make a backup copy of current•actionmethods•••abort••commit••canCommit•••If tx is not a known transaction, thenfirst join tx , failing if the join fails.Perform base action on current stateand/or by calling other methods onother objects with argument tx ,recording identity of all such objects.On any failure, mark tx as notcommittable. •Throw away all bookkeepingassociated with tx .Propagate to all other knownparticipants. •Save representation associated withtx as current state.Propagate to all known participants. •Return false if any conflicting commitoccurred since joining tx , or if anyother conflicting transaction hasalready promised to commit.Ask all other objects referenced in thecourse of actions if they can commit;return false if any cannot.Record that tx has promised tocommit; return true. ••••••state to recover to in the case ofan abort.Record that tx is currenttransaction; return true.If tx is not current transaction,fail.Perform base action on currentstate and/or by calling othermethods on other joined objectswith argument tx .On any failure, mark currenttransaction as not committable.If tx is current transaction,reset state to backup copy andrecord that there is no currenttransaction.Propagate to all other knownparticipants.Throw away backup; recordthat there is no currenttransaction.Propagate to all knownparticipants.Ask other participants, returnfalse if any cannot.Return true unless a localfailure occurred during anaction.When applied to the BankAccount class, taking the simplest possible option at each step leads to amixed-strategy version that is probably not fit for serious use. Among other scale-downs, it maintainsonly a single backup copy of state (as a single field), so can be used only for non-overlappingtransactions. But this version suffices to illustrate the general structure of transactional classes andalso, implicitly, how much more code would be required to build a more useful version:class SimpleTransBankAccount implements TransBankAccount {protected long balance = 0;protected long workingBalance = 0; // single shadow copyprotected Transaction currentTx = null; // single transactionpublic synchronized long balance(Transaction t) throwsFailure {if (t != currentTx) throw new Failure();return workingBalance;}public synchronized void deposit(Transaction t, long amount)throws InsufficientFunds, Failure {if (t != currentTx) throw new Failure();if (workingBalance < -amount)throw new InsufficientFunds();workingBalance += amount;}public synchronized void withdraw(Transaction t, long amount)throws InsufficientFunds, Failure {deposit(t, -amount);}public synchronized boolean join(Transaction t) {if (currentTx != null) return false;currentTx = t;workingBalance = balance;return true;}public synchronized boolean canCommit(Transaction t) {return (t == currentTx);}public synchronized void abort(Transaction t) {if (t == currentTx)currentTx = null;}public synchronized void commit(Transaction t) throwsFailure{if (t != currentTx) throw new Failure();balance = workingBalance;currentTx = null;}}Classes obeying the Transactor interface can also employ arbitrary sharing of references amongparticipants. For example, you can construct a Proxy account that forwards messages to anotherunrelated and otherwise uncontrolled account.class ProxyAccount implements TransBankAccount {private TransBankAccount delegate;public boolean join(Transaction t) {return delegate.join(t);}public long balance(Transaction t) throws Failure {return delegate.balance(t);}// and so on...}3.6.3 Creating TransactionsTransactions that employ participants obeying the Transactor interface take a standard form,performing the following steps:••••Create a new Transaction .Invoke join on all (initially known) participants, failing immediately if any cannot join.Try the entire action, aborting all participants on any failure and also rolling back any otherauxiliary actions.Upon completion, collect votes using canCommit and then commit or abort .In most applications, it simplifies matters if the classes initiating transactions also support theTransactor interface. They may also support other methods that set up logging and relatedbookkeeping matters.It is possible to automate many aspects of this protocol, redistribute or centralize functionality, andincorporate additional features. For example, an arbitrary amount of effort can be expended computingwhether a transaction can be joined and/or committed in order to minimize the probability andexpense of aborts. The actions and participant structure of potentially conflicting transactions can beanalyzed and manipulated (for example, via use of conflict sets — see § 3.3.2) to allow overlaps incases when you can determine that no conflicts are possible.Similarly, locking strategies can be refined to use read and write locks, or even further refined tosupport lock upgrades and intention locks (see § 3.3.3.1).3.6.3.1 ExampleThe following version of the transfer operation deals with several kinds of potential failures:Semantic failure. There may not be sufficient funds in the accounts, in which case the method returnsfalse . In this example, there is not even a pre-check that the source holds a sufficient balance. Evenif it reported true, the withdraw attempt may fail anyway. Similarly, since the amount is allowedto be negative, destination.deposit may fail even if source.withdraw succeeds.(For a negative amount, a deposit acts like a withdraw and vice versa.) Additional exceptions could becaught here to deal with other errors encountered within these methods.Interference. If either account cannot join or cannot commit to this transaction due to interference byanother concurrent transaction, an exception is thrown indicating that the action is retryable.Transaction error. Unrecoverable, catastrophic operation failure can occur if objects fail to commitafter they say they can. Of course, these methods should do everything within their power to avoidcommitment failure, since there is nothing to be done about this internal error. Here, the exception ispropagated back to clients. In a more realistic version, this might in turn trigger a recovery from thelast recorded persistent record of the object's state.The recovery action for each of these cases happens to be identical in this example (and is factoredinto a helper method). The abort clauses perform the state rollbacks. But the log must be cancelledindependently.class FailedTransferException extends Exception {}class RetryableTransferException extends Exception {}class AccountUser {TransactionLogger log;// a made-up class// helper method called on any failurevoid rollback(Transaction t, long amount,TransBankAccount src, TransBankAccount dst) {log.cancelLogEntry(t, amount, src, dst);src.abort(t);dst.abort(t);}public boolean transfer(long amount,TransBankAccount src,TransBankAccount dst)throws FailedTransferException, RetryableTransferException {if (src == null || dst == null) // screen argumentsthrow new IllegalArgumentException();if (src == dst) return true;// avoid aliasingTransaction t = new Transaction();log.logTransfer(t, amount, src, dst);// recordif (!src.join(t) || !dst.join(t)) { // cannot joinrollback(t, amount, src, dst);throw new RetryableTransferException();}try {src.withdraw(t, amount);dst.deposit(t, amount);}catch (InsufficientFunds ex) {rollback(t, amount, src, dst);return false;// semantic failure}catch (Failure k) {// transaction errorrollback(t, amount, src, dst);throw new RetryableTransferException();}if (!src.canCommit(t) || !dst.canCommit(t)) { //interferencerollback(t, amount, src, dst);throw new RetryableTransferException();}try {src.commit(t);dst.commit(t);log.logCompletedTransfer(t, amount, src, dst);return true;}catch(Failure k) {// commitment failurerollback(t, amount, src, dst);throw new FailedTransferException();}}}3.6.4 Vetoable ChangesThe fact that transaction frameworks can become almost arbitrarily heavy sometimes makesdevelopers neglect simpler transactional solutions in smaller-scale concurrent design efforts. Weconclude this section with a more ordinary-sounding design problem that is readily solved in atransactional fashion.In the JavaBeansTM framework, component objects have sets of properties — fields that supportget and set methods. Constrained properties may support vetoable set methods. A hostcomponent may have a list of listeners to which it sends vetoable change events in the course of avetoable set method. If any listener responds to an event with a PropertyVetoException ,then an attempted set of the property must be cancelled.Some components express many of their operations as vetoable property changes. For example, anattempt to exit an editor application may be implemented as a set method, vetoable by anydocuments that have not yet been saved, as well as by confirmation dialogs.Vetoable changes employ a slimmed-down transaction protocol that has only one active participant,but possibly several passive participants that must be polled for consensus. This can be done in eithera conservative (i.e., before performing the update) or optimistic (i.e., after tentatively performing theupdate) fashion.Here are some background notes about java.beans support needed to construct any solution:•••Listeners are normally structured identically to the Observers discussed in § 3.5.2 except thatthey are triggered via events that contain information about changes. In the normal casediscussed here, the event-based methodvetoableChange(PropertyChangeEvent evt) is invoked directly for eachlistener rather than being held in queues described in § 4.1.The VetoableChangeSupport and PropertyChangeSupport classes in thejava.beans package can be used to manage multicasts to listeners. But, as usual, we'lladopt copy-on-write versions that allow lock-free multicasting. The version below usesVetoableChangeMulticaster and PropertyChangeMulticaster fromutil.concurrent , both of which support the same interfaces as java.beansversions. They provide methods to attach and detach listeners similar to those described in §2.4.4.The VetoableChangeMulticaster.fireVetoableChange methodconstructs and multicasts a PropertyChangeEvent with event fields indicating thename of the property, its old value, and its proposed new value.As a bland example illustrating basic techniques, consider a ColoredThing component with avetoable color property. Each ColoredThing may have several vetoers, as well as severalordinary listeners that are notified upon every update. We'll use a simple conservative-style solution.When a ColoredThing receives a request to setColor(Color newColor) , it performsthe following steps:1. Check to see if another attempted setColor operation is already in progress, if sothrowing a PropertyVetoException . To manage this, the class maintains a booleanexecution state variable indicating whether a change is pending. A fancier (but probably lessdesirable) version could instead wait out other transactions using a wait / notifyAllconstruction based on changePending .2. Check to see if the argument is null, in which case also refuse to change the property. Thisillustrates how a component can, in a sense, veto its own changes.3. Invoke fireVetoableChange , which multicasts to vetoers.4. If a PropertyVetoException results from the change event, abort and rethrow theexception. Otherwise, update the color field, clear the pending flag, and send a change eventto all property listeners. As an extra safeguard here, the method maintains a completedvariable used for detecting run-time exceptions. The finally clause makes sure that thechangePending flag is reset properly if the method encounters such an exception.class ColoredThing {protected Color myColor = Color.red; // the sample propertyprotected boolean changePending;// vetoable listeners:protected final VetoableChangeMulticaster vetoers =new VetoableChangeMulticaster(this);// also some ordinary listeners:protected final PropertyChangeMulticaster listeners =new PropertyChangeMulticaster(this);// registration methods, including:void addVetoer(VetoableChangeListener l) {vetoers.addVetoableChangeListener(l);}public synchronized Color getColor() { // property accessorreturn myColor;}// internal helper methodsprotected synchronized void commitColor(Color newColor) {myColor = newColor;changePending = false;}protected synchronized void abortSetColor() {changePending = false;}public void setColor(Color newColor)throws PropertyVetoException {Color oldColor = null;boolean completed = false;synchronized (this) {timeif (changePending) { // allow only one transaction at athrow new PropertyVetoException("Concurrent modification", null);}else if (newColor == null) {// Argument screeningthrow new PropertyVetoException("Cannot change color to Null", null);}else {changePending = true;oldColor = myColor;}}try {vetoers.fireVetoableChange("color", oldColor, newColor);// fall through if no exception:commitColor(newColor);completed = true;// notify other listeners that change is committedlisteners.firePropertyChange("color", oldColor,newColor);}}catch(PropertyVetoException ex) { // abort on vetoabortSetColor();completed = true;throw ex;}finally {// trap any unchecked exceptionif (!completed) abortSetColor();}}3.6.5 Further ReadingsMore thorough accounts of transactions in database systems may be found in:Bacon, Jean. Concurrent Systems, Addison-Wesley, 1993.Cellary, Wojciech, E. Gelenbe, and Tadeusz Morzy, Concurrency Control in Distributed DatabaseSystems, North-Holland, 1988.Gray, Jim, and Andreas Reuter. Transaction Processing: Concepts and Techniques, MorganKaufmann, 1993.Khoshafian, Setrag. Object-Oriented Databases, Wiley, 1993.Lynch, Nancy, Michael Merritt, William Weihl, and Alan Fekete. Atomic Transactions, MorganKaufmann, 1994.The following covers database programming using JDBC:White, Seth, Maydene Fisher, Rick Cattell, Graham Hamilton, and Mark Hapner. JDBCTM APITutorial and Reference, Second Edition, Addison-Wesley, 1999.3.7 Implementing UtilitiesUtility classes and methods can encapsulate efficient, reliable, general-purpose implementations ofconcurrency control constructs in a way that lets them be used almost as if they were part of thelanguage proper. These classes can capture clever, complex, error-prone constructions and efficientlyexploit special cases, packaging the results so that programs using them can be written more simply,reliably, and often with better performance. It is worth the development effort to arrive at such classesonly once, and only when justified by real design concerns.This section illustrates some techniques used in the construction of common utilities. All of them relyon general design and implementation tactics described previously in this book, but also introduce afew additional specialized constructions that typically arise only when building support classes.The section starts by illustrating how to package acquire-release protocols under a common interface.This is followed by an example showing how to apply joint action design techniques to split classesinto parts for the sake of obtaining necessary concurrency control, and then recombining them toimprove efficiency. Finally, it discusses how to isolate waiting threads in order to managenotifications.3.7.1 Acquire-Release ProtocolsAs discussed in § 2.5.1 and § 3.4.1, many concurrency control constructs conform to an acquire-release protocol that can be encompassed under the simple interface:interface Sync {void acquire() throws InterruptedException;void release();boolean attempt(long msec) throws InterruptedException;}Supporting this interface under a given semantics (for example, locks, semaphores, latches) requiresthat the internal state representations that drive waits and notifications be managed by the Syncobjects, not the classes using them. Additionally, all control must be placed within the exportedmethods; it cannot be strewn around other methods in client classes, and it is a bad idea to introduceother methods that clients must use in a special, non-standard way to obtain desired behavior.Most of the resulting issues and concerns can be illustrated with a sample implementation of the basicSemaphore class discussed in § 3.4.1. Implementations of other Sync classes follow similarpatterns. (In fact, as shown in § 3.4.1, classes such as Mutex can in turn be defined usingsemaphores.)Both at the conceptual and representational level, a semaphore maintains a count of the number ofpermits that it manages. The basic idea is that an acquire should wait (if necessary) until there is atleast one permit, and that a release should increment the number of permits and providenotifications to any waiting threads. Here are some other observations and choices that lead to animplementation:•••Since all waiting threads are waiting for permits, and since a release adds one permit, wecan use notify rather than notifyAll , leading to cheaper notifications. Also, the extra-notify-on-interrupt technique described in § 3.2.4.2 is available to avoid lossage when threadsare interrupted at just the wrong time.Because this is intended to be a general-purpose class, we should play it safe and use long(not int ) for counts. This avoids all practical possibility of value overflow and costs almostnothing compared to monitor overhead.To maintain responsiveness, we should check to make sure that the current thread has notbeen interrupted before acquiring any locks. This minimizes windows of vulnerability forclient threads getting stuck waiting for locks when they should be cancelling themselves (see§ 3.1.2). It also provides a more uniform guarantee that InterruptedException willbe thrown if the thread enters in an interrupted state, rather than having the exception thrownonly if the thread happens to block on the internal wait .class Semaphore implements Sync {protected long permits; // current number of availablepermitspublic Semaphore(long initialPermits) {permits = initialPermits;}public synchronized void release() {++permits;notify();}public void acquire() throws InterruptedException {if (Thread.interrupted()) throw new InterruptedException();synchronized(this) {try {while (permits <= 0) wait();--permits;}catch (InterruptedException ie) {notify();throw ie;}}}public boolean attempt(long msecs)throwsInterruptedException{if (Thread.interrupted()) throw new InterruptedException();synchronized(this) {if (permits > 0) {// same as acquire but messier--permits;return true;}else if (msecs <= 0)// avoid timed wait if not neededreturn false;else {try {long startTime = System.currentTimeMillis();long waitTime = msecs;for (;;) {wait(waitTime);if (permits > 0) {--permits;return true;}else {// check for time-outlong now = System.currentTimeMillis();waitTime = msecs - (now - startTime);if (waitTime <= 0)return false;}}}}catch(InterruptedException ie) {notify();throw ie;}}}}3.7.2 Delegated ActionsJoint action designs can be used to address a potential source of inefficiency in guarded methods inwhich different threads in a wait set are waiting for different logical conditions. A notifyAllintended to alert threads about one condition also wakes up threads waiting for completely unrelatedconditions. Useless signals, and the resulting "thundering herds" of context switches can be minimizedby delegating operations with different wait conditions to different helper objects.We achieved this effect with almost no effort using semaphores in § 3.4.1. Here, we will proceed fromthe ground up, potentially achieving better performance by exploiting the special properties ofparticular design problems. The techniques here are worth using only when a design problem isamenable to optimizations that can be applied only to bare waiting and notification mechanics.Splitting classes with state-dependent actions extends ideas seen in § 2.4.2 for splitting objects withrespect to locks, as well as some from the States as Objects pattern (see Design Patterns). However,the design space is restricted to a narrow range of constructions because of constraints including:•••Since helpers must access common state, you cannot fully isolate each helper along with itsown self-contained representation. Independent access to common representations acrosshelpers requires appropriate synchronization.Each of the helpers that might affect guard conditions for another must provide it witheffective notifications while avoiding liveness problems.Synchronization of helper methods involving wait mechanics must avoid nested monitorproblems (§ 3.3.4).3.7.2.1 Design stepsA general approach to these constraints is first to decompose the Host class into its smallest possiblepieces: one class for the shared state representation and one each per kind of helper. You can then dealwith the resulting coordinated joint action design problem. Finally, you can organize the pieces intouseful classes:••Define a class, say Representation , to hold fields used across more than one method.This is just a record-style class with non-private fields, allowing arbitrary accesses andupdates to be performed within special synchronized blocks.Define a Helper class for each set of functionality that shares the same wait conditions.Each Helper class requires instance variables referencing the host and the representation(this reference may be indirect via the host).• Define the Host class as a pass-through: Each public Host method should be anunsynchronized forwarding method. Also, define unsynchronized methods designed to becalled by helpers whenever they change states in ways that may affect other helpers. Relaythe associated notify or notifyAll calls. (Alternatively, these notifications can be sentdirectly among helpers.) The host should also initialize all helper objects in its constructor.• Each helper method must avoid liveness failures while still preserving safety. In particular:o If the condition checks involve the shared representation, they must be performedwhile both the representation and helper are locked.o The representation lock must be released before entering any wait , but the lock onthe helper must be retained to avoid missed signals (see § 3.2.4) in which waits arestarted after notifications have already occurred.o Notification relays must be initiated without synchronization to avoid potentialdeadlocks.A generic helper method can take the form:void doM() throws InterruptedException {for(;;) {// wait loopsynchronized(this) {// check->wait must lock thissynchronized(rep) {// check->act must lock repboolean canAct = inRightState(rep);if (canAct) {update(rep);// the guarded actionbreak;}}// release rep lock before waitwait();// fall-through if !canAct}// release lock before signal}host.signalChange();}3.7.2.2 Bounded buffersAs our last examples of BoundedBuffer , we will create delegated versions that also exploitspecial characteristics of the underlying data structure and algorithm to obtain better performance. Thefinal result is just slightly faster than previous versions, but serves to exemplify techniques.First, we need to split up helper objects to do put and take . Delegation designs normally require ahelper class per method. But here, we can get away with only one helper class (with two instances) byexploiting an observation about ownership transfers. As noted in § 2.3.4, the single operationexchange can be used for both put -style and take -style transfers. For example,exchange(null) accomplishes a take . The buffer-based version of exchange replaces theold value with the argument at the current array slot and then circularly advances to the next arrayposition.It is convenient to define the helper class Exchanger as an inner class to gain access to the hostand the array serving as the shared representation. We also need a slot counter variable to indicatewhen an exchange operation must stall because there are no more items. For the helper doing put ,the counter starts off at capacity; for take , it starts off at zero. An exchange operation can proceedonly if the number of slots is greater than zero.Each successful exchange operation decrements the count. Waits on zero counts can be released onlyby the helper performing the complementary operation, which must provide a notification. This isimplemented by issuing an addedSlotNotification to the other exchanger, as relayedthrough the host.Another special consideration in this particular design leads to another minor economy. Even thoughthe data array must be shared across the two helpers, it does not need synchronization protection solong as put and take are the only operations supported. This can be ensured by declaring the hostclass final . We can make do without a synchronization lock because, in this algorithm, anyexecuting put must be operating on a different array slot than the one being accessed by anyexecuting take . Additionally, the outer synchronizations suffice to preclude memory visibilityproblems (see § 2.2.7). In contrast, the BoundedBufferWithSemaphores class requireslocking around array operations because it does not otherwise restrict at most one put or take tooccur at any given time.As a further performance enhancement, notifications here use notify , since the conditions for itsuse (discussed in § 3.2.4.2) are met: (1) Each waiting task in each helper is waiting on the samelogical condition (non-emptiness for take , and non-fullness for put ). (2) Each notification enablesat most a single thread to continue — each put enables one take , and each take enables oneput . (3) We can re- notify to deal with interruptions.And to squeeze another bit of efficiency out of this, it is simple here to (conservatively) track whetherthere are any waiting threads, and issue notify only if there can be threads that need notifying. Theperformance effect of this tactic varies across JVM implementations. As notify operations becomeincreasingly cheap, the minor bookkeeping overhead here to avoid calls becomes decreasinglyworthwhile.final class BoundedBufferWithDelegates {private Object[] array;private Exchanger putter;private Exchanger taker;public BoundedBufferWithDelegates(int capacity)throws IllegalArgumentException {if (capacity <= 0) throw new IllegalArgumentException();array = new Object[capacity];putter = new Exchanger(capacity);taker = new Exchanger(0);}public void put(Object x) throws InterruptedException {putter.exchange(x);}public Object take() throws InterruptedException {return taker.exchange(null);}void removedSlotNotification(Exchanger h) { // relayif (h == putter) taker.addedSlotNotification();elseputter.addedSlotNotification();}protected class Exchanger {protected int ptr = 0;protected int slots;protected int waiting = 0;threads// Inner class// circular index// number of usable slots// number of waitingExchanger(int n) { slots = n; }synchronized void addedSlotNotification() {++slots;if (waiting > 0) // unblock a single waiting threadnotify();}Object exchange(Object x) throws InterruptedException {Object old = null; // return valuesynchronized(this) {while (slots <= 0) { // wait for slot++waiting;try {wait();}catch(InterruptedException ie) {notify();throw ie;}finally {--waiting;}}--slots;// use slotold = array[ptr];array[ptr] = x;ptr = (ptr + 1) % array.length; // advance position}removedSlotNotification(this); // notify of changereturn old;}}}3.7.2.3 Collapsing classesSynchronization splitting of all kinds can be accomplished in two ways. In the case of lock-splitting (§2.4.2), you can either create new helper classes and forward operations from the host, or you can justkeep the methods in the host but invoke them under synchronization of Objects that conceptuallyrepresent the different helpers.The same principle holds when splitting state-dependent actions. Rather than delegating actions tohelpers, you can keep the methods in the host class, adding Objects that conceptually represent thehelpers. Objects used solely for synchronization serve as locks. Those used for waiting andnotification serve as monitors — places to put threads that need to wait and be notified.Combining helpers into a host class makes the host class more complex but also potentially moreefficient, due to short-circuited method calls and the like. Performing such simplifications along theway, we can define a more concise, slightly more efficient, and surely more frightening version ofBoundedBuffer :final class BoundedBufferWithMonitorObjects {private final Object[] array; // the elementsprivate int putPtr = 0;private int takePtr = 0;// circular indicesprivate int emptySlots;private int usedSlots = 0;// slot countsprivate int waitingPuts = 0;private int waitingTakes = 0;// counts of waiting threadsprivate final Object putMonitor = new Object();private final Object takeMonitor = new Object();public BoundedBufferWithMonitorObjects(int capacity)throws IllegalArgumentException {if (capacity <= 0)throw new IllegalArgumentException();array = new Object[capacity];emptySlots = capacity;}public void put(Object x) throws InterruptedException {synchronized(putMonitor) {while (emptySlots <= 0) {++waitingPuts;try { putMonitor.wait(); }catch(InterruptedException ie) {putMonitor.notify();throw ie;}finally { --waitingPuts; }}--emptySlots;array[putPtr] = x;putPtr = (putPtr + 1) % array.length;}synchronized(takeMonitor) { // directly notify++usedSlots;if (waitingTakes > 0)takeMonitor.notify();}}public Object take() throws InterruptedException {Object old = null;synchronized(takeMonitor) {while (usedSlots <= 0) {++waitingTakes;try { takeMonitor.wait(); }catch(InterruptedException ie) {takeMonitor.notify();throw ie;}finally { --waitingTakes; }}--usedSlots;old = array[takePtr];array[takePtr] = null;takePtr = (takePtr + 1) % array.length;}synchronized(putMonitor) {++emptySlots;if (waitingPuts > 0)putMonitor.notify();}return old;}}3.7.3 Specific NotificationsInstead of treating the little helper Objects in classes such asBoundedBufferWithMonitorObjects as the culmination of design efforts, you can treatthem as tools for implementing any design problem amenable to solution via split monitors. TheSpecific Notification pattern devised by Tom Cargill takes precisely this tactic.The basic idea is to put tasks to sleep via waits in monitors — ordinary Objects (or moretypically, instances of simple classes that help with bookkeeping) used solely for their wait sets. Onemonitor is used for each task or set of tasks that must be individually notified. In most cases, thisrequires one monitor per thread; in others, a group of threads that should all be awakened at once canuse the same monitor. These monitors serve similar purposes to the condition queues that are nativelysupported in some monitor-based concurrent programming languages (see § 3.4.4). The maindifference is that, without native support, these helper monitors must be dealt with more carefully toavoid nesting problems.Specific notifications may be useful whenever you need threads to wait and the notification policydoes not dynamically depend on the properties of the threads. Once a thread is put in its wait set, it isimpossible to access it in any way other than to wake it up. Among the common applications to whichthese constraints apply are:••Supporting specific scheduling policies through the use of an explicit queue (for exampleFIFO, LIFO, priority).Dividing incoming tasks into different queues depending on the method they are waiting toperform. This can be used to extend techniques based on conflict sets (see § 3.3.2).However, while it may be tempting to combine support for scheduling constraints such as FIFO withconstraints based on logical state or execution state, interactions between these two applicationsusually lead to both conceptual and logistical problems. For example, you need to consider caseswhere thread A should be enabled before thread B because it arrived earlier, but thread B is logicallyable to proceed while thread A is not. This may necessitate elaborate apparatus to requeue threads,manage locking orders, and arbitrarily handle corner cases.3.7.3.1 Design stepsThe main design steps are specializations of those described in § 3.7.2.1. Create or modify a class, sayHost , as follows:•••••••••••For each thread or set of threads that needs specific notification, create an object serving as amonitor. These monitors may be arranged in arrays or other collections, or dynamicallycreated during execution.Set up bookkeeping in the classes serving as monitors to manage waiting and notificationoperations and their interactions with time-out and interruption policies. As shown in theWaitNode class in § 3.7.3.2, this usually entails maintaining a released field toremember if a waiting thread has been released due to notification, interruption, or time-out.These classes may then support methods, say doWait , doTimedWait , doNotify , anddoNotifyAll , that perform reliable waiting and notification and deal with interrupts andtime-outs in the desired fashion. If you cannot add bookkeeping to the classes serving asmonitors, then these matters need to be addressed in the Host class methods.In each Host method in which tasks are to be suspended, use monitor.doWait() withthe appropriate monitor object. This code must avoid nested monitor problems by ensuringthat the wait is performed within code regions that are not synchronized on the host object.The simplest and most desirable form is:boolean needToWait;// to remember value after synchexitsynchronized (this) {needToWait = ...;if (needToWait)enqueue(monitor); // or any similar bookkeeping}if (needToWait) monitor.doWait();In each method in which tasks are to be resumed, use monitor.doNotify() , alsohandling the consequences of time-out or interruption.3.7.3.2 FIFO semaphoresSpecific notifications can be used to implement the kinds of First-In-First-Out semaphore classesdiscussed in § 3.4.1.5. FIFO semaphores can in turn be used to build other utilities that rely on FIFOproperties.The following FIFOSemaphore class (a streamlined version of one in util.concurrent ) isdefined as a subclass of the generic Semaphore class from § 3.7.1. The FIFOSemaphore classmaintains a linked WaitQueue holding WaitNodes , each serving as a monitor. An acquireoperation that cannot immediately obtain a permit enqueues a new monitor object that enters a wait .The release operation dequeues the oldest waiting node and notifies it.A released field in each WaitNode helps manage interactions between notifications andinterruptions. During a release , any monitor that has aborted due to interruption is skipped over.Conversely, an interrupted wait first checks to see if it has been notified in addition to beinginterrupted. If so, it must roll forward, ignoring the exception but resetting interrupt status (see § 3.1.2)to preserve cancellation status. (An unshown doTimedWait method can be implemented similarly,by setting released status upon time-out.) The potential for interruptions at inconvenient timesaccounts for the retry loop in release .The interactions among FIFOSemaphore , WaitQueue , and WaitNode ensure the necessaryatomicity while avoiding nested monitor problems. They also demonstrate some of the arbitrariness ofdecisions surrounding support of FIFO policies. We can promise only that the semaphore is FIFO withrespect to an arbitrary start point and end point. The start point commences with thesynchronized(this) in acquire . The end point normally occurs upon release from await due to notify . Two threads entering acquire might obtain the lock in different ordersfrom their arrivals, for example if the first one is scheduled out by the JVM before it hits thesynchronized(this) statement. Similarly, a thread released before another might finallyreturn to its caller after the other. Especially on multiprocessors, the class provides as strong aguarantee as users of the class should expect.The scheduling rules can be changed by substituting a different kind of queue here; for example onebased on Thread.getPriority . However, it is trickier to adapt this class to handle semanticrestrictions based on execution or logical state. Most semantic restrictions require notified orinterrupted threads to acquire additional locks. This would introduce complications to the scheme herethat exploits the fact that awakened threads need not access the main lock. These would need to beresolved in an application-specific manner.class FIFOSemaphore extends Semaphore {protected final WaitQueue queue = new WaitQueue();public FIFOSemaphore(long initialPermits) {super(initialPermits);}public void acquire() throws InterruptedException {if (Thread.interrupted()) throw new InterruptedException();WaitNode node = null;synchronized(this) {if (permits > 0) {// no need to queue--permits;return;}else {node = new WaitNode();queue.enq(node);}}// must release lock before node waitnode.doWait();}public synchronized void release() {for (;;) {// retry until successWaitNode node = queue.deq();if (node == null) { // queue is empty++permits;return;}else if (node.doNotify())return;// else node was already released due to// interruption or time-out, so must retry}}// Queue node class. Each node serves as a monitor.protected static class WaitNode {boolean released = false;WaitNode next = null;// to arrange in linked listsynchronized void doWait() throws InterruptedException {try {while (!released)wait();}catch (InterruptedException ie) {if (!released) {// interrupted before notified// Suppress future notifications:released = true;throw ie;}else {// interrupted after notified// ignore exception but propagate status:Thread.currentThread().interrupt();}}}synchronized boolean doNotify() { // return true if notifiedif (released)return false;else {// was interrupted or timed outreleased = true;notify();return true;}}synchronized boolean doTimedWait(long msecs)throws InterruptedException {// similar}}// Standard linked queue class.// Used only when holding Semaphore lock.protected static class WaitQueue {protected WaitNode head = null;protected WaitNode last = null;protected void enq(WaitNode node) {if (last == null)head = last = node;else {last.next = node;last = node;}}protected WaitNode deq() {WaitNode node = head;if (node != null) {head = node.next;if (head == null) last = null;node.next = null;}return node;}}}3.7.4 Further ReadingsTechniques for implementing elementary locks using, for example, Dekker's algorithm and ticket-based algorithms are presented in the concurrent programming texts by Andrews and others listed in §1.2.5. However, there is no reason to base general-purpose concurrency control utilities on suchtechniques rather than on built-in synchronized methods and blocks.The Specific Notification pattern was first described in:Cargill, Thomas. "Specific Notification for Java Thread Synchronization", Proceedings of the PatternLanguages of Programming Conference, 1996.An alternative account of refining notifyAll constructions using specific notifications can befound in:Mizuno, Masaaki. "A Structured Approach for Developing Concurrent Programs in Java", InformationProcessing Letters, 1999.Further examples and extensions of the techniques described in this section may be found in the onlinesupplement.Chapter 4. Creating ThreadsIt is impossible to categorize all the ways to exploit the functionality associated with threads. But twogeneral approaches can be distinguished by their points of view on the statement:new Thread(aRunnable).start();Is this a fancy way to invoke a method (i.e., a Runnable 's run method), or is it a way to create afancy object (i.e., a new instance of class Thread )? Clearly it is both, but focusing on one aspectversus the other leads to two approaches to using threads that were implicit in discussions in Chapter1:Task-based Here, the main reason to use a thread is to asynchronously invoke a method that performssome task. The task might range from a single method to an entire session. Thread-based techniquescan support message-passing schemes that escape the limitations of pure procedural calls. Task-baseddesigns are seen in event frameworks, parallel computation, and IO-intensive systems.Actor-based Here, the main reason to use a thread is to create and set into motion a new autonomous,active, process-like object. This object may in turn react to external events, interact with other actors,and so on. Actor-based designs are seen in reactive, control, and distributed systems. They are also thefocus of most formal approaches to concurrency.(Both the terms task and actor have many overloaded meanings and near-synonyms. We'll confineusage to the above senses.)In task-based systems, passive objects sometimes send active (thread-propelled) messages, while inactor-based systems, active objects normally send passive messages. As is usually the case forartificial dichotomies, neither approach is always best, and there is a huge middle ground that can bedesigned from either or both perspectives.Actor-based approaches are commonly used in the construction of daemons that interact with othersystems. They are also employed when defining intrinsically active entities, for example theGamePlayer in § 3.2.4. Their main methods often take a reactive looping form:for(;;) { acceptAndProcessCommand(); }Task-based approaches are commonly used when there is some conceptual or performance-basedreason to execute a given task, service, or computation asynchronously rather than relying on directprocedural invocation. Task-based designs provide a separation of concerns between logicalasynchrony and mappings to threads and thread-based constructions. They receive the bulk ofdiscussion in this chapter.As an initial example, here is one way to approach a common thread-based design, a web service.Here, a running WebService is a "daemon process" actor-style thread — it continuously interactswith its environment by listening for new incoming requests. But invocations tohandler.process are issued in a task-based manner — a new task is set in motion to handleeach incoming request. Here, for the sake of concise illustration, the request is simply a number, andthe handler just returns the negation of the number back to the client.class WebService implements Runnable {static final int PORT = 1040; // just for demoHandler handler = new Handler();public void run() {try {ServerSocket socket = new ServerSocket(PORT);for (;;) {final Socket connection = socket.accept();new Thread(new Runnable() {public void run() {handler.process(connection);}}).start();}}catch(Exception e) { } // die}public static void main(String[] args) {new Thread(new WebService()).start();}}class Handler {void process(Socket s) {DataInputStream in = null;DataOutputStream out = null;try {in = new DataInputStream(s.getInputStream());out = new DataOutputStream(s.getOutputStream());int request = in.readInt();int result = -request;// return negation to clientout.writeInt(result);}catch(IOException ex) {}// fall throughfinally {// clean uptry { if (in != null) in.close(); }catch (IOException ignore) {}try { if (out != null) out.close(); }catch (IOException ignore) {}try { s.close(); }catch (IOException ignore) {}}}}This chapter divides coverage of thread construction and structuring techniques as follows:•••••§ 4.1 presents a series of options for implementing conceptually oneway messages,sometimes by asynchronously initiating tasks using threads or thread-based lightweightexecution frameworks.§ 4.2 discusses the design of systems in which networks of components employ onewaymessaging strategies.§ 4.3 presents alternatives for constructing threads that compute results or provide services toclients that initiate them.§ 4.4 examines problem decomposition techniques that can be used to improve performanceby exploiting multiprocessors.§ 4.5 provides an overview of constructs and frameworks for designing systems of activeobjects, illustrated in part using CSP.Many of the designs presented in this chapter straddle the borders among concurrent, distributed, andparallel programming. Presentations focus on concurrent, single-JVM solutions. But they includeconstructions often seen when developing the plumbing support for systems and frameworksinvolving multiple processes or computers.4.1 Oneway MessagesA host object issues a logically oneway message to one or more recipients without depending on theconsequences of that message. Sending a oneway message somehow results in some task beingperformed. The task might consist of only a single line of code, or might represent a session thatentails acquisition of many resources and hours of computation. But the outcome of the thread issuinga oneway message does not rely on the task's outcome, or on when the task completes, or (normally)on whether it ever completes. Common examples include:EventsNotificationsPostingsActivationsCommandsRelaysMouse clicks, etc.Status change alertsMail messages, stock quotes, etc.Creating Applets, daemons, etc.Print requests, etc.Message forwardings and dispatchingsOneway interactions between senders and recipients need not be strictly asynchronous. For example,the sender may be responsible for ensuring that a recipient actually receives the message. Also, thesender or another object may later wish to cancel or roll back the effects of the resulting task (which isof course not always possible, for example if the task has already completed — see § 3.1.2).If every task could run instantaneously, you might trigger oneway messages via proceduralinvocations in which the caller waits out the task triggered by the message, even though it has noreason to do so. But there are often performance-based, conceptual, and logistical reasons to issuesome of these messages via thread-based constructions in which the associated tasks proceedindependently.4.1.1 Message FormatsMany different styles of invocation are encompassed under the notion of oneway message passing.While some of them are more closely associated with distributed or multiprocess applications (see §1.2.2), any of them can be used in conjunction with the constructions discussed in this section. Inaddition to direct method invocations, message formats may include:Command strings The recipient must parse, decode, and then dispatch the associated task. Commandstring messages are widely used in socket-based and pipe-based communication, especially in webservices.Event objects The message contains a structured description of an event. The recipient then dispatchessome arbitrary handling task that it associates with the event. Event objects are used extensively inGUI frameworks such as java.awt , as well as component frameworks supported byjava.beans .Request objects The message contains an encoding of a method name and (marshalled or serialized)arguments. The recipient issues the corresponding method call to a helper object that performs thismethod. Request objects are used in distributed object support systems such as those in java.rmiand org.omg.corba . Variants are used in Ada tasking.Class objects The message is a representation of a class (for example via a .class file) which therecipient then instantiates. This scheme is used in the java.applet framework, as well as inremote activation protocols.Runnable objects The message consists of some code that the recipient executes. Mixed forms ofrunnable events (which include both an event description and an associated action) are used in someevent frameworks. Extended forms employing serialized runnable objects are seen in mobile agentframeworks.Arbitrary objects A sender may treat any kind of object as a message by including it as methodargument or passing it through a Channel (see § 4.2.1). For example, in the JavaSpaces TMframework, senders may post any serialized object as a message (also known as an entry). Recipientsaccept only those entries with types and field values that conform to a specified set of matchingcriteria. Recipients then process these objects in any appropriate manner.Differences among these formats reflect (among other things) how much the caller knows about thecode the recipient needs to run to perform its task. It is often both most convenient and most efficientto use runnable objects, especially in thread-based frameworks that use instances of class Runnable asarguments in Thread constructors. We'll focus on this form, but occasionally illustrate others.4.1.2 Open CallsConsider the central Host object in a call chain in which the Host receives req requests from anynumber of Clients and, in the course of processing them, must issue logically oneway handlemessages to one or more Helper objects. Again, we'll ignore the facts that an arbitrary amount of effortmight be needed to decode the request before acting upon it, that the request might actually be readfrom a socket as seen in the WebService class, and so on. Also, all classes discussed in thissection can be extended to issue multicasts to multiple helpers using the constructions described in §2.4.4 and § 3.5.2.The main design force here is latency. If a Host is busy servicing requests, then it cannot accept newones. This adds response time to new requests from Clients, reducing overall service availability.Some aspects of latency can be addressed simply by using the pass-through and open call designsdescribed in § 2.4:class OpenCallHost {protected long localState;// Generic code sketchprotected final Helper helper = new Helper();protected synchronized void updateState(...) {localState = ...;}public void req(...) {updateState(...);helper.handle(...);}}Here, even if the helper.handle call is relatively time-consuming, the Host object will still beable to accept new requests from clients running in different threads. The request acceptance rate isbounded only by the time it takes to update local state.The use of open calls typically eliminates bottleneck points surrounding a given Host, but does notaddress the broader question of how to introduce concurrency into a system to begin with. Open callsare useful only when clients somehow already know enough to use some other approach that permitsindependent execution when necessary or desired.4.1.3 Thread-Per-MessageConcurrency can be introduced into oneway messaging designs by issuing a message in its ownthread, as in:class ThreadPerMessageHost {// Generic code sketchprotected long localState;protected final Helper helper = new Helper();protected synchronized void updateState() {localState = ...;}public void req(...) {updateState(...);new Thread(new Runnable() {public void run() {helper.handle(...);}}).start();}}This strategy improves throughput when multiple parallel tasks can run faster than a sequence of themcould, normally because they are either IO-bound or are compute-bound and running on amultiprocessor. It can also enhance fairness and improve availability if clients need not wait for eachother's tasks to complete.Decisions about whether to create and start threads to perform tasks are not too different fromdecisions about whether to create other kinds of objects or send other kinds of messages: The benefitsmust outweigh the costs.Thread-per-message designs introduce response latency because thread creation is more expensivethan direct method invocation. When tasks are time-consuming compared to thread construction time,are session-based, need to be isolated from other independent activities, or can exploit IO or CPUparallelism, the trade-offs are generally worth it. But performance problems can emerge even whenconstruction latencies are acceptable. The JVM implementation and/or operating system may notrespond well to the construction of too many threads. For example, they may run out of systemresources associated with threads. Also, as the number of threads increases, thread scheduling andcontext switching overhead can overwhelm processing times.4.1.3.1 ExecutorsThe coding style seen in class ThreadPerMessage can become a problem because of its directreliance on class Thread . Such usages can make it more difficult to adjust thread initializationparameters, as well as thread-specific data (see § 2.3.2) used across an application. This can beavoided by creating an interface, say:interface Executor {void execute(Runnable r);}This interface can be implemented with classes such as:class PlainThreadExecutor implements Executor {public void execute(Runnable r) {new Thread(r).start();}}These implementations may be used in classes such as:class HostWithExecutor {// Generic code sketchprotected long localState;protected final Helper helper = new Helper();protected final Executor executor;public HostWithExecutor(Executor e) { executor = e; }protected synchronized void updateState(...) {localState = ...;}public void req(...) {updateState(...);executor.execute(new Runnable() {public void run() {helper.handle(...);}});}}The use of such interfaces also permits replacement of threads with lightweight executableframeworks.4.1.4 Worker ThreadsLightweight executable frameworks fill the gap between open calls and thread-per-message designs.They apply when you need to introduce limited concurrency, at the expense of some usagerestrictions, in order to maximize (or at least improve) throughput and minimize average latencies.Lightweight executable frameworks can be constructed in many ways, but all stem from the basic ideaof using one thread to execute many unrelated tasks (here, in succession). These threads are known asworker threads, background threads, and as thread pools when more than one thread is used.Each worker continually accepts new Runnable commands from hosts and holds them in somekind of Channel (a queue, buffer, etc. — see § 3.4.1) until they can be run. This design has theclassic form of a producer-consumer relationship: the host produces tasks and workers consume themby running them.Lightweight executable frameworks can improve the structure of some task-based concurrentprograms, by allowing you to package many smaller, logically asynchronous units of execution astasks without having to worry much about performance consequences: Entering a Runnable into aqueue is likely to be faster than creating a new Thread object. And because you can control thenumber of worker threads, you can minimize chances of resource exhaustion and reduce context-switching overhead. Explicit queuing also permits greater flexibility in tuning execution semantics.For example, you can implement Channels as priority queues that order tasks with moredeterministic control than is guaranteed by Thread.setPriority . (See § 4.3.4 for anexample.)To interoperate with pure thread-based versions, worker threads can be packaged as Executors .Here is a generic implementation that could be used in the HostWithExecutor class instead ofthe thread-per-message version:class PlainWorkerPool implements Executor {protected final Channel workQueue;public void execute(Runnable r) {try {workQueue.put(r);}catch (InterruptedException ie) { // postpone responseThread.currentThread().interrupt();}}public PlainWorkerPool(Channel ch, int nworkers) {workQueue = ch;for (int i = 0; i < nworkers; ++i) activate();}protected void activate() {Runnable runLoop = new Runnable() {public void run() {try {for (;;) {Runnable r = (Runnable)(workQueue.take());r.run();}}catch (InterruptedException ie) {} // die}};new Thread(runLoop).start();}}4.1.4.1 Design choicesThe first decision to make surrounding lightweight executable frameworks based on worker threads iswhether to create or use them at all. The main question is whether there is some property of ordinaryThreads that you do not need or are willing to give up. If not, it is unlikely that you will arrive at asolution that outperforms the built-in thread support on production JVM implementations.The trade-offs that obtain the performance advantages of worker threads have several additionaltunable parameters, usage consequences, and programming obligations that can impact the design anduse of worker thread classes (including those contained in the util.concurrent packageavailable from the online supplement).Identity. Most worker threads must be treated "anonymously". Because the same worker thread isreused for multiple tasks, the use of ThreadLocal and other thread-specific contextual controltechniques (see § 2.3.2) becomes more awkward. To cope with this, you need to know about all suchcontextual data, and somehow reset it if necessary upon executing each task. (This includesinformation about security contexts maintained by run-time support classes.) However, mostlightweight executable frameworks avoid any reliance on thread-specific techniques.If identity is the only property of threads you are willing to give up, then the only potentialperformance value of worker threads is minimization of start-up overhead by reusing existing threadsto execute multiple Runnable tasks, while still possibly bounding resource consumption.Queuing. Runnable tasks that are sitting in queues do not run. This is one source of performancebenefits in most worker-thread designs — if each action were associated with a thread, it would needto be independently scheduled by the JVM. But as a consequence, queued execution cannot in generalbe used when there are any dependencies among tasks. If a currently running task blocks waiting for acondition produced by a task still waiting in the queue, the system may freeze up. Options hereinclude:••Use as many worker threads as there are simultaneously executing tasks. In this case, theChannel need not perform any queuing, so you can use SynchronousChannels(see § 3.4.1.4), queueless channels that require each put to wait for a take and vice versa.Here, the host objects merely hand off tasks to worker threads, which immediately startexecuting them. For this to work well, worker thread pools should be dynamicallyexpandable.Restrict usage to contexts in which task dependencies are impossible, for example in HTTPservers where each message is issued by an unrelated external client requesting a file. Requirethe helper objects to create actual Threads when they cannot ensure independence.•Create custom queues that understand the dependencies among the particular kinds of tasksbeing processed by the worker threads. For example, most pools used for processing tasksrepresenting transactions (see § 3.6) must keep track of transaction dependencies. And thelightweight parallel framework described in § 4.4.1 relies on special queuing policies thatapply only to subtasks created in divide-and-conquer algorithms.Saturation. As the request rate increases, a worker pool will eventually become saturated. All workerthreads will be processing tasks and the Host object(s) using the pool will be unable to hand off work.Possible responses include:•••••••Increase the pool size. In many applications, bounds are heuristic estimates. If a bound is justa guess based on values shown to work well on a particular platform under test workloads, itcan be increased. At some point, though, one of the other options must be taken unless youcan tolerate failure if the JVM runs out of enough resources to construct a new Thread .If the nature of the service allows it, use an unbounded buffered channel and let requests pileup. This risks potential system failure due to exhaustion of memory, but this takes longer tohappen than does resource exhaustion surrounding Thread construction.Establish a back-pressure notification scheme to ask clients to stop sending so many requests.If the ultimate clients are part of a distributed system, they may be able to use another serverinstead.Drop (discard) new requests upon saturation. This can be a good option if you know thatclients will retry anyway. However, unless retries are automatic, you need to add callbacks,events, or notifications back to clients to alert them of the drops so that they will knowenough to retry (see § 4.3.1).Make room for the new request by dropping old requests that have been queued but not yetrun, or even cancelling one or more executing tasks. This preference for new requests overold ones upon saturation sometimes meshes well with usage patterns. For example, in sometelecommunications systems, old unserviced tasks are usually requests by clients that havealready given up and disconnected.Block until some thread is available. This can be a good option when handlers are ofpredictable, short-lived duration, so you can be confident that the wait will unblock withoutunacceptable delays.The Host can run the task directly itself, in its current thread. This is often the best defaultchoice. In essence, the Host momentarily becomes single-threaded. The act of servicing therequest limits the rate at which it can accept new requests, thus preventing further localbreakdowns.Thread management. The PlainWorkerPool class is somewhat wasteful because it creates allworker threads upon start-up, whether they are needed or not, and lets them all live on indefinitely,even when the service is not being used. These problems can be alleviated by using a managementclass that supports:••Lazy construction: Activate a new thread only when a request cannot be serviced immediatelyby an existing idle thread. Lazy construction allows users to provide large enough pool sizelimits to avoid underutilization problems occurring when fewer threads are running than agiven computer can handle. This comes at the minor expense of occasionally higher latencieswhen a new request causes a new thread to be created. The start-up effects of lazyconstruction can be tempered by creating a small number of "warm" threads uponconstruction of the pool.Idle time-outs: Allow threads to time out waiting for work and to terminate upon time-out.This eventually causes all workers to exit if the pool is not used for prolonged periods. Whencoupled with lazy construction, these dead threads will be replaced with new ones if therequest rate later increases.In heavily resource-conscious applications, you may also associate other resources (such as sets ofreusable graphical objects) with each worker thread, thus combining resource pools (see § 3.4.1.2)with thread pools.Cancellation. You may need to distinguish cancellation (see § 3.1.2) of a task from cancellation of theworker thread performing that task. One approach is:••Upon interruption, allow the current worker thread to die, but replace it if necessary with afresh worker thread if the work queue is not empty or when a new incoming task arrives.Provide a shutdown method in the worker thread class that causes existing workers to dieand no additional workers to be created.Additionally, you may need to trigger some kind of error handling if a Host thread is cancelled duringa task hand-off. While the silent swallowing of InterruptedException without queuing atask seen in PlainWorkerPool conforms to the minimal requirements of oneway message-passing frameworks, most applications need to take other remedial actions.4.1.4.2 Event queuesMany event-based frameworks (including the ones supported in the java.aw t andjavax.swing packages) rely on designs in which exactly one worker thread operates on anunbounded queue. The queue holds instances of EventObject that must be dispatched (asopposed to Runnable objects that self-dispatch), normally to listener objects defined by theapplication. Often the listeners are the same objects as those that initially generate events.The use of a single thread operating on a single event queue simplifies usage compared to generalworker-thread designs, but also imposes some limitations that are characteristic of event frameworks:•The ordering properties of a queue can be exploited to optimize handling. For example,automatic event-filtering techniques can be used to remove or combine duplicate repaint•events for the same screen area before they hit the front of the queue and are taken by theworker thread.You can require that all methods operating on certain objects be invoked only by issuingevents onto the queue, and are thus ultimately performed by the single worker thread. Thisresults in a form of thread confinement (see § 2.3.2) of these objects. If flawlessly adhered to,this eliminates the need for dynamic locking within operations on these objects, thusimproving performance. This can also reduce complexity for applications that do nototherwise need to construct threads.This is the basis for the Swing single-thread rule: With only a few exceptions, allmanipulation of Swing objects must be performed by the event handler thread. While notstated in AWT, it is good idea to observe this rule there as well.•••Events should not be enabled until their handlers are fully constructed and are thus ready tohandle events. This holds as well for other thread-based designs (see § 2.2.7), but is a morecommon source of error here because registering an event handler or listener inside itsconstructor is not as obvious a way to prematurely enable concurrent execution as isconstructing a thread.Users of the event framework must never dispatch actions that block in ways that can unblockonly as a result of handling a future event. This problem is encountered when implementingmodal dialogs in most event frameworks, and requires an ad-hoc solution. However, morelocalized solutions can be obtained merely by setting a disabled state for interactivecomponents that should not be used until a certain re-enabling event is received. This avoidsblocking the event queue without allowing undesired actions to be triggered.Further, to maintain responsiveness of the event framework, actions should not block at all,and should not perform time-consuming operations.This set of design choices causes event frameworks to have much better performance than wouldthread-per-event designs, and makes them simpler to program by developers who do not otherwise usethreads. However, the usage restrictions have more impact in programs that do construct other threads.For example, because of the single-thread rule, even the smallest manipulations of GUI components(such as changing the text in a label) must be performed by issuing runnable event objects thatencapsulate an action to be performed by the event handler thread.In Swing and AWT applications, the methodsjavax.swing.SwingUtilities.invokeLater andjava.awt.EventQueue.invokeLater can be used to execute display-related commandsin the event handler thread. These methods create runnable event objects that are executed when takenfrom the queue. The online supplement contains links to a SwingWorker utility class that partiallyautomates conformance to these rules for threads that produce results leading to screen updates.4.1.4.3 TimersThe fact that Runnable tasks in worker thread designs may sit queued without running is a problemto be worked around in some applications. But it sometimes becomes a feature when actions areintended to be delayed.The use of worker threads can both improve efficiency and simplify usage of delayed and periodicactions — those triggered at certain times, after certain delays, or at regular intervals (for example,every day at noon). A standardized timer facility can both automate messy timing calculations andavoid excess thread construction by reusing worker threads. The main trade-off is that if a workerblocks or takes a long time processing one task, the triggering of others may become delayed longerthan they would be if separate Threads are created and scheduled by the underlying JVM.Time-based daemons can be constructed as variants of the basic worker thread design described in §4.1.4.1. For example, here are the highlights of a version that relies on an unshown priority queueclass (that might take a form similar to the scheduling queue illustrated in § 4.3.4) and is set up tosupport only one worker thread:class TimerDaemon {// Fragmentsstatic class TimerTask implements Comparable { // ...final Runnable command;final long execTime;// time to run atpublic int compareTo(Object x) {long otherExecTime = ((TimerTask)(x)).execTime;return (execTime < otherExecTime) ? -1 :(execTime == otherExecTime)? 0 : 1;}}// a heap or list with methods that preserve// ordering with respect to TimerTask.compareTostatic class PriorityQueue {void put(TimerTask t);TimerTask least();void removeLeast();boolean isEmpty();}protected final PriorityQueue pq = new PriorityQueue();public synchronized voidt){pq.put(new TimerTask(r,notifyAll();}public synchronized voidpq.put(new TimerTask(r,notifyAll();}executeAfterDelay(Runnable r,longt + System.currentTimeMillis()));executeAt(Runnable r, Date time) {time.getTime()));// wait for and then return next task to runprotected synchronized Runnable take()throws InterruptedException {for (;;) {while (pq.isEmpty())wait();TimerTask t = pq.least();}long now = System.currentTimeMillis();long waitTime = now - t.execTime;if (waitTime <= 0) {pq.removeLeast();return t.command;}elsewait(waitTime);}public TimerDaemon() { activate(); } // only one}void activate() {// same as PlainWorkerThread except using above take method}The techniques discussed in § 3.7 can be used here to improve efficiency of the waiting andnotification operations.This class can be extended to deal with periodic tasks by including additional bookkeeping to requeuethem before running them. However, this also requires dealing with the fact that periodicallyscheduled actions are almost never exactly periodic, in part because timed waits do not necessarilywake up exactly upon the given delays. The main options are either to ignore lags and reschedule byclock time, or to ignore the clock and reschedule the next execution at a fixed delay after starting thecurrent one. Fancier schemes are typically needed for multimedia synchronization — see the FurtherReadings in § 1.3.5.Timer daemons [1] can additionally support methods that cancel delayed or periodic actions. Oneapproach is to have executeAt and other scheduling methods accept or return suitably a reworkedTimerTask supporting a cancel method that sets a status flag honored by the worker thread.[1]As of this writing, a similar class is scheduled to be supported in an upcoming SDK release4.1.5 Polling and Event-Driven IOMost worker thread designs rely on blocking channels in which the worker thread waits for incomingcommands to run. However, there are a few contexts in which optimistic-style retry loops provide abetter solution. Most involve the execution of commands stemming from messages received across IOstreams.It can be a challenge to achieve low latencies and high throughputs in heavily loaded IO-boundsystems. The time taken to create a thread that performs an IO-based task adds latency, but most run-time systems are tuned such that, once threads are created, they are very responsive to new inputsarriving on IO streams. On input, they unblock with shorter latencies than you are likely to achieve viaother techniques. Especially in the case of socket-based IO, these forces generally favor thread-per-IO-session designs, where a different thread is used (or reused) for each session relying on input froma different connection.However, as the number of simultaneously active connections climbs, other approaches are (only)sometimes more attractive. Consider for example, a multiplayer game server, or a transaction server,with:•••Thousands of simultaneous socket connections that join and leave at a steady rate, forexample, as people start and finish playing a game.Relatively low input rates on any given socket at any given time. However, summing acrossall connections, the aggregate IO rates may be very high.Non-trivial computation associated with at least some inputs, for example those that causeglobal state changes in games.On large mainframe systems, this kind of problem is sometimes dealt with by creating a special-purpose front-end machine that multiplexes all of the inputs into a single stream that is then dealt withby the main service. The main service is often multithreaded, but its structure is simplified and mademore efficient because it does not need to deal with so many apparent clients at a time.A family of polling and event-driven designs approach such problems without requiring special frontends. While they are not (as of this writing) explicitly supported by the java.io and java.netclasses, enough of the ingredients are provided to allow construction of designs that can attain goodperformance in these kinds of situations. (The designs are analogous to those using socket selectand poll operations in other systems and languages.) We'll illustrate with inputs on sockets, but theapproach also applies to outputs, to files, and to IO using more exotic devices such as sensors.4.1.5.1 Event-driven tasksMany IO-based tasks are initially written in a session-based style (see § 2.3.1), continuously pullingcommands from sockets and processing them. For example:class SessionTask implements Runnable { // Generic code sketchprotected final Socket socket;protected final InputStream input;SessionTask(Socket s) throws IOException {socket = s; input = socket.getInputStream();}public void run() {// Normally run in a new threadbyte[] commandBuffer = new byte[BUFFSIZE];try {for (;;) {int bytes = input.read(commandBuffer, 0, BUFFSIZE);if (bytes != BUFFSIZE) break;processCommand(commandBuffer, bytes);}}catch (IOException ex) {cleanup();}finally {try { input.close(); socket.close(); }catch(IOException ignore) {}}}}To enable many sessions to be handled without using many threads, the tasks first must be refactoredinto an event-driven style, where an event here signifies IO availability. In this style, a session consistsof possibly many executions of its event-triggered task(s), each of which is invoked when inputbecomes available.Event-driven IO tasks are similar in form to GUI event handlers. A session-based design can beconverted into an event-driven form by:•••Isolating the basic per-command functionality in a reworked task run method that reads onecommand and performs the associated action.Defining the run method so that it can be repeatedly triggered whenever input is available tobe read (or an IO exception occurs).Manually maintaining completion status so that the per-event action is no longer triggeredwhen the session finishes, normally because the input has been exhausted or the connectionhas been closed.For example:class IOEventTask implements Runnable { // Generic codesketchprotected final Socket socket;protected final InputStream input;protected volatile boolean done = false; // latches trueIOEventTask(Socket s) throws IOException {socket = s; input = socket.getInputStream();}public void run() { // trigger only when input availableif (done) return;byte[] commandBuffer = new byte[BUFFSIZE];try {int bytes = input.read(commandBuffer, 0, BUFFSIZE);if (bytes != BUFFSIZE) done = true;else processCommand(commandBuffer, bytes);}catch (IOException ex) {cleanup();done = true;}finally {if (!done) return;try { input.close(); socket.close(); }catch(IOException ignore) {}}}// Accessor methods needed by triggering agent:boolean done(){ return done; }InputStream input() { return input; }}4.1.5.2 TriggeringWhen the events driving each event-driven task are relatively infrequent, a large number of tasks canbe processed by a small number of worker threads. The simplest case occurs when the number ofworker threads is exactly one. Here, the worker thread repeatedly polls a list of open sockets to see ifthey have any input available (via InputStream.available ) or have encountered other IO-related status changes. If so, the worker executes the associated run method.This style of worker thread differs from the ones in § 4.1.4.1 in that, rather than pulling tasks from ablocking queue and blindly running them, the worker must repeatedly check a list of registered tasksto see if any can be run. It removes each task from the list only when it claims to have completed.One generic form is:class PollingWorker implements Runnable {private List tasks = ...;private long sleepTime = ...;// Incompletevoid register(IOEventTask t){ tasks.add(t); }void deregister(IOEventTask t) { tasks.remove(t); }public void run() {try {for (;;) {for (Iterator it = tasks.iterator(); it.hasNext();) {IOEventTask t = (IOEventTask)(it.next());if (t.done())deregister(t);else {boolean trigger;try {trigger = t.input().available() > 0;}catch (IOException ex) {trigger = true; // trigger if exception on check}if (trigger)t.run();}}Thread.sleep(sleepTime); // pause between sweeps}}catch (InterruptedException ie) {}}}Several design concerns arise here:•••••Polling intrinsically relies on busy-wait loops (see § 3.2.6), which are intrinsically wasteful(but still sometimes less so than context-switching). Coping with this requires empiricallyguided decisions about how to insert sleeps, yields, or alternative actions to strike a balancebetween conserving CPU time and maintaining acceptable average response latencies.Performance is very sensitive to the characteristics of the underlying data structuremaintaining the list of registered tasks. If new tasks come and go regularly, the list of taskscan change fairly frequently. In this case, schemes such as copy-on-write (see § 2.4.4) usuallydo not work well. But there is every reason to make traversal of the list as cheap as possible.One approach is to maintain a cached list for traversal and to update it (if necessary) only atthe end of each sweep.Event-driven tasks should be triggered only when they have enough data to perform theirassociated actions. However, in many applications (for example those using free-form string-based commands), the minimal amount of data needed for triggering is not known in advance.In practice (as illustrated here), it usually suffices just to check that at least one byte isavailable. This exploits the fact that socket-based clients send packets — normally eachpacket contains an entire command. However, when commands do not arrive as units, theworker thread can stall, thus increasing latencies of other tasks unless buffering schemes areadded.A single worker thread is not likely to be acceptable if some inputs lead to time-consumingcomputations or blocking IO. One solution is to require that such computations be performedin new threads or by separate worker thread pools. However, it is sometimes more efficientinstead to employ multiple polling worker threads; enough so that on average there willalways be a thread polling for inputs.The use of multiple polling worker threads requires additional coordination to make sure thattwo workers are not both trying to run the same task at the same time, without otherwiseimpeding each other's sweeps through the list of tasks. One approach is to have task classesset and honor busy status, for example, via testAndSet (see § 3.5.1.4).Given these concerns and the context dependence of the associated design decisions, it is notsurprising that most frameworks are custom-built to suit the demands of particular applications.However, the util.concurrent package available from the online supplement includes someutilities that can be used to help build standardized solutions.4.1.6 Further ReadingsMost details about messages, formats, transports, etc., used in practice are specific to particularpackages and systems, so the best sources are their accompanying manuals and documentation.Discussions of message passing in distributed systems can be found in the sources listed in § 1.2.5.Any of several packages and frameworks can be used to extend the techniques discussed here to applyin distributed contexts. For example, most of these designs (as well as most in § 4.2 and elsewhere inthis book) can be adapted for use in JavaSpaces. Conversely, many distributed message passingtechniques can be scaled down to apply in concurrent, non-distributed settings.Design and implementation using JavaSpaces is discussed in:Freeman, Eric, Susan Hupfer, and Ken Arnold. JavaSpacesTM: Principles, Patterns, and Practice,Addison-Wesley, 1999.For different approaches, see for example the Aleph, JMS, and Ninja packages, accessible via linksfrom the online supplement. Many commercial distributed systems are based on CORBA and relatedframeworks, which also include some support for oneway message passing. See:Henning, Michi, and Steve Vinoski. Advanced CORBA Programming with C++, Addison-Wesley,1999.Pope, Alan. The CORBA Reference Guide, Addison-Wesley, 1998.Some systems-level oneway messaging strategies otherwise similar to those presented here aredescribed in:Langendoen, Koen, Raoul Bhoedjang, and Henri Bal. "Models for Asynchronous Message Handling",IEEE Concurrency, April-June 1997.An argument that single-queue, single-thread event frameworks are a better basis for applicationprogramming than thread-based frameworks may be found in:Ousterhout, John. "Why Threads Are a Bad Idea (For Most Purposes)", USENIX TechnicalConference, 1996.4.2 Composing Oneway MessagesMany interprocess and distributed designs involve groups of objects exchanging oneway messages(see § 1.2 and § 4.5). Similar techniques may be applied within individual concurrent programs. Infact, as discussed in § 4.1, a larger range of design options is available in concurrent programs than indistributed systems. Messages need not be restricted to, say, socket-based commands. Concurrentprograms may also employ lighter alternatives including direct invocations and event-basedcommunication.However, this wide range of options also introduces opportunities for creating chaotic, difficult-to-understand designs. This section describes some simple program-level (or subsystem-level)structuring techniques that tend to produce well-behaved, readily understandable, and readilyextensible designs.A flow network is a collection of objects that all pass oneway messages transferring informationand/or objects to each other along paths from sources to sinks. Flow patterns may occur in any kind ofsystem or subsystem supporting one or more series of connected steps or stages, in which each stageplays the role of a producer and/or consumer. Broad categories include:Control systems. External sensor inputs ultimately cause control systems to generate particulareffector outputs. Applications such as avionics control systems contain dozens of kinds of inputs andoutputs. For a plainer example, consider a skeletal thermostatic heater control:Assembly systems. Newly created objects undergo a series of changes and/or become integrated withother new objects before finally being used for some purpose; for example, an assembly line forCartons:Dataflow systems. Each stage transforms or otherwise processes data. For example, in pipelinedmultimedia systems, audio and/or video data is processed across multiple stages. In publish-subscribesystems, possibly many data sources send information to possibly many consumers. In Unix pipes-and-filters shell programs, stages send character data, as in a simple spell checker:Workflow systems. Each stage represents an action that needs to be performed according to some setof business policies or other requirements; for example, a simple payment system:Event systems. Stages pass around and ultimately execute code associated with objects representingmessages, user inputs, or simulated physical phenomena. The beginnings of many event systems takethe form:4.2.1 CompositionThe development of flow networks entails two main sets of concerns: design of the data being passedaround, and design of the stages that do the passing.4.2.1.1 RepresentationsFlow networks pass around representational components — families of values or objects representingthe things the flow is all about. In the introductory examples, temperatures, cardboard sheets, words,invoices, and events are the basic kinds of values and objects passed across connected stages. Oftenthese components are interesting objects in their own rights that can perform services, communicatewith other objects, and so on. But when viewed as the raw material for a flow, they are treated as merepassive representations, providing data or information rather than behavior.While they play similar roles in the overall design of a flow system, different categories ofrepresentation types affect the details of the rest of the system:•••••Information types representing the state of the world (for example values such as temperaturereadings, maintained as scalars or immutable ADT objects) differ from most others in that itis often acceptable to reuse old or current best-estimate values if necessary. In essence,producers have an inexhaustible supply of such values.Event indicators normally can be used at most once, although they may be passed aroundmany times before being used.Mutable resource types (such as cartons) may be transferred (see § 2.3.4) from each stage tothe next, ensuring that each object is being operated upon by at most one stage at any giventime.Alternatively, if the identities of mutable representation objects do not matter, they can becopied across stages as needed. Copy-based approaches are more often used in distributedflow networks in which ownership cannot be transferred across stages simply by assigningreference fields.Artificial data types can be used for control purposes. For example, a special null token maybe used as a terminator that triggers cancellation and shutdown. Similarly, a special keepalivecan be sent to inform one stage that another still exists. Alternatively, a distinct set ofsideband control methods can be employed across stages. Sideband controls are methods usedto set stages into different modes that influence their main processing. For example, athermostat Comparator may have a separate control to change its threshold.4.2.1.2 StagesStages in well-behaved flow networks all obey sets of constraints that are reminiscent of those seen inelectrical circuit design. Here is one conservative set of composition rules that generate a smallnumber of basic kinds of stages:Directionality. Flow maintains a single directionality, from sources to sinks. There are no loops orback-branches from consumers to producers. This results in a directed acyclic graph (DAG) ofinformation or object flow.Interoperability. Methods and message formats are standardized across components, normallythrough conformance to a small set of interfaces.Connectivity. Stages maintain fixed connectivity: consumers may receive messages only from knownproducers, and vice versa. So, for example, while a web service may have any number of anonymousclients, a given TemperatureComparator object may be designed to receive temperatureupdate messages only from a designated TemperatureSensor object.Connectivity is usually arranged by maintaining direct references from producers to consumers or viceversa, or by having them share access to a Channel . Alternatively, a network may be based onconstrained use of blackboards, multicast channels, or JavaSpaces (see § 4.1.6) in which producersspecially tag messages destined for particular consumers.Transfer protocols. Every message transfers information or objects. Once a stage has transferred amutable object, it never again manipulates that object. When necessary, special buffer stages may beinterposed to hold elements transferred out from one stage that cannot yet be accepted by other stages.Transfer protocols typically rely on the basic put and take operations described in § 2.3.4. Whenall messages involve put -based transfers, networks are normally labeled as push flow; when theyinvolve take -based transfers, they are normally labeled as pull flow; when they involve channelssupporting both put and take (and possibly exchange ), they can take various mixed forms.Threads. Stages may implement oneway message passing using any of the patterns described in § 4.1,as long as every (potentially) simultaneously live connection from a given producer to a givenconsumer employs a different thread or thread-based message-sending construction.It is rarely necessary to satisfy this requirement by issuing every message, or every stream ofmessages from a producer to a consumer, in a different thread. You can instead exploit connectivityrules to use threads only as needed. Most sources in push-based systems intrinsically employ threads.Additionally, any push stage with multiple successors that may ultimately hit a Combiner stage mustissue the messages independently. Otherwise, if a thread is blocked at the combine point, there may bea possibility that the Combiner will never see the other inputs necessary to unblock it.Sources have nopredecessors.Sinks have nosuccessors.Linear stages have atmost one predecessorand one successor.Routers send a messageto one of theirsuccessors.Multicasters sendmessages to all theirsuccessors.Collectors acceptmessages from one oftheir predecessors at atime.Combiners requiremessages from all theirpredecessors.Conversely, most sinks in pull-based systems intrinsically employ thread-based messageconstructions, as do stages involved in split/join connections proceeding from the opposite directionpictured above.These rules can be liberalized in various ways. In fact, you can adopt any set of composition rules youlike. But the listed constraints serve to eliminate large classes of safety and liveness problems whilealso satisfying common reusability and performance goals: unidirectional flow avoids deadlock,connectivity management avoids unwanted interleavings across different flows, transfer protocolsavoid safety problems due to inadvertent sharing without the need for extensive dynamicsynchronization, and interface conformance assures type safety while still permitting interoperabilityamong components.4.2.1.3 ScriptingAdoption of standard set of composition rules makes possible the construction of higher-level toolsthat arrange for stages to operate cooperatively, without otherwise imposing centralized dynamicsynchronization control. Composition of flow networks can be treated as a form of scripting in theusual sense of the word — semi-automated programming of the code that glues together instances ofexisting object types. This is the kind of programming associated with languages such as JavaScript,Visual Basic, Unix shells, and FlowMark (a workflow tool). Development of a scripting tool, orintegration with an existing one, is an optional step in building systems based around flows.This architecture is analogous to that of GUI builders consisting of a base set of widgets, packers andlayout managers, code to instantiate a particular GUI, and a visual scripter that helps set it all up.Alternatively, it may be possible to script flows through direct manipulation tools by which, forexample, components communicate instantly once dragged-and-dropped to connect with others.4.2.2 Assembly LineThe remainder of this section illustrates the design and implementation of flow systems via anexample assembly line applet that builds series of "paintings" in a style vaguely reminiscent of theartists Piet Mondrian and Mark Rothko. Only the principal classes are given here. Some includeunimplemented method declarations. The full code may be found in the online supplement, which alsoincludes other application-level examples of flow-based systems.4.2.2.1 RepresentationsTo start out, we need some base representation types. In this system, all elements can be defined assubclasses of abstract class Box , where every Box has a color and a size, can display itself whenasked, and can be made to deeply clone ( duplicate ) itself. The color mechanics are default-implemented. Others are left abstract, to be defined differently in different subclasses:abstract class Box {protected Color color = Color.white;publicpublicpublicpublicpublicdisplay}synchronized Color getColor(){return color;}synchronized void setColor(Color c) {color = c;}abstract java.awt.Dimension size();abstract Box duplicate();// cloneabstract void show(Graphics g, Point origin);//The overall theme of this example is to start off with sources that produce simple basic boxes, andthen push them through stages that paint, join, flip, and embed them to form the paintings.BasicBoxes are the raw material:class BasicBox extends Box {protected final Dimension size;public BasicBox(int xdim, int ydim) {size = new Dimension(xdim, ydim);}public synchronized Dimension size() { return size; }public void show(Graphics g, Point origin) {g.setColor(getColor());g.fillRect(origin.x, origin.y, size.width, size.height);}public synchronized Box duplicate() {Box p = new BasicBox(size.width, size.height);p.setColor(getColor());return p;}}Two fancier kinds of boxes can be made by joining two existing boxes side by side and adding a line-based border surrounding them. Joined boxes can also flip themselves. All this can be done eitherhorizontally or vertically. The two resulting classes can be made subclasses of JoinedPair toallow sharing of some common code:abstract class JoinedPair extends Box {protected Box fst; // one of the boxesprotected Box snd; // the other oneprotected JoinedPair(Box a, Box b) {fst = a;snd = b;}public synchronized void flip() { // swap fst/sndBox tmp = fst; fst = snd; snd = tmp;}//}other internal helper methodsclass HorizontallyJoinedPair extends JoinedPair {public HorizontallyJoinedPair(Box l, Box r) {super(l, r);}public synchronized Box duplicate() {HorizontallyJoinedPair p =new HorizontallyJoinedPair(fst.duplicate(),snd.duplicate());p.setColor(getColor());return p;}// ... other implementations of abstract Box methods}class VerticallyJoinedPair extends JoinedPair {// similar}The final kind of fancy box wraps one Box within a border:class WrappedBox extends Box {protected Dimension wrapperSize;protected Box inner;public WrappedBox(Box innerBox, Dimension size) {inner = innerBox;wrapperSize = size;}// ... other implementations of abstract Box methods}4.2.2.2 InterfacesLooking ahead to how we might want to string stages together, it is worthwhile to standardizeinterfaces. We'd like to be able to connect any stage to any other stage for which it could make sense,so we want bland, noncommittal names for the principal methods.Since we are doing oneway push-based flow, these interfaces mainly describe put-style methods. Infact, we could just call them all put , except that this doesn't work very well for two-input stages. Forexample, a VerticalJoiner needs two put methods, one supplying the top Box and one thebottom Box . We could avoid this by designing Joiners to take alternate inputs as the tops andbottoms, but this would make them harder to control. Instead, we'll use the somewhat ugly but easilyextensible names putA , putB , and so on:interface PushSource {void produce();}interface PushStage {void putA(Box p);}interface DualInputPushStage extends PushStage {void putB(Box p);}4.2.2.3 AdaptersWe can make the "B" channels of DualInputPushStages completely transparent to otherstages by defining a simple Adapter class that accepts a putA but relays it to the intended recipient'sputB . In this way, most stages can be built to invoke putA without knowing or caring that the boxis being fed into some successor's B channel:class DualInputAdapter implements PushStage {protected final DualInputPushStage stage;public DualInputAdapter(DualInputPushStage s) { stage = s; }public void putA(Box p) { stage.putB(p); }}4.2.2.4 SinksSinks have no successors. The simplest kind of sink doesn't even process its input, and thus serves as away to throw away elements. In the spirit of Unix pipes and filters, we can call it:class DevNull implements PushStage {public void putA(Box p) { }}More interesting sinks require more interesting code. For example, in the applet used to produce theimage shown at the beginning of this section, the Applet subclass itself was defined toimplement PushStage . It served as the ultimate sink by displaying the assembled objects.4.2.2.5 ConnectionsInterfaces standardize on the method names for stages but do nothing about the linkages to successors,which must be maintained using some kind of instance variables in each stage object. Except for sinkssuch as DevNull , each stage has at least one successor. There are several implementation options,including:•••Have each object maintain a collection object holding all its successors.Use a master connection registry that each stage interacts with to find out its successor(s).Create the minimal representation: define a base class for stages with exactly one successorand one for those with exactly two successors.The third option is simplest and works fine here. (In fact, it is always a valid option. Stages with threeor more outputs can be built by cascading those for only two. Of course, you wouldn't want to do thisif most stages had large and/or variable numbers of successors.)This leads to base classes that support either one or two links and have one or two correspondingattachment methods, named using a similar ugly suffix convention ( attach1 , attach2 ). Becauseconnections are dynamically assignable, they are accessed only under synchronization:class SingleOutputPushStage {private PushStage next1 = null;protected synchronized PushStage next1() { return next1; }public synchronized void attach1(PushStage s) { next1 = s; }}class DualOutputPushStage extends SingleOutputPushStage {private PushStage next2 = null;protected synchronized PushStage next2() { return next2; }public synchronized void attach2(PushStage s) { next2 = s; }}4.2.2.6 Linear stagesNow we can build all sorts of classes that extend either of the base classes, simultaneouslyimplementing any of the standard interfaces. The simplest transformational stages are linear, single-input/single-output stages. Painters , Wrappers , and Flippers are merely:class Painter extends SingleOutputPushStageimplements PushStage {protected final Color color; // the color to paint boxespublic Painter(Color c) { color = c; }public void putA(Box p) {p.setColor(color);next1().putA(p);}}class Wrapper extends SingleOutputPushStageimplements PushStage {protected final int thickness;public Wrapper(int t) { thickness = t; }public void putA(Box p) {Dimension d = new Dimension(thickness, thickness);next1().putA(new WrappedBox(p, d));}}class Flipper extends SingleOutputPushStageimplements PushStage {public void putA(Box p) {if (p instanceof JoinedPair)((JoinedPair) p).flip();next1().putA(p);}}Painter and Wrapper stages apply to any kind of Box . But Flippers only make sense forJoinedPairs : if a Flipper receives something other than a JoinedPair , it just passes itthrough. In a more "strongly typed" version, we might instead choose to drop boxes other thanJoinedPairs , perhaps by sending them to DevNull .4.2.2.7 CombinersWe have two kinds of Combiners, horizontal and vertical Joiners . Like the representation classes,these classes have enough in common to factor out a superclass. Joiner stages block further inputsuntil they can combine one item each from putA and putB . This can be implemented via guardmechanics that hold up acceptance of additional items from putA until existing ones have beenpaired up with those from putB , and vice versa:abstract class Joiner extends SingleOutputPushStageimplements DualInputPushStage {protected Box a = null;protected Box b = null;// incoming from putA// incoming from putBprotected abstract Box join(Box p, Box q);protected synchronized Box joinFromA(Box p) {while (a != null)// wait until last consumedtry { wait(); }catch (InterruptedException e) { return null; }a = p;return tryJoin();}protected synchronized Box joinFromB(Box p) { // symmetricalwhile (b != null)try { wait(); }catch (InterruptedException ie) { return null; }b = p;return tryJoin();}protected synchronized Box tryJoin() {if (a == null || b == null) return null; // cannot joinBox joined = join(a, b);// make combined boxa = b = null;// forget old boxesnotifyAll();// allow new putsreturn joined;}public void putA(Box p) {Box j = joinFromA(p);if (j != null) next1().putA(j);}public void putB(Box p) {Box j = joinFromB(p);if (j != null) next1().putA(j);}}class HorizontalJoiner extends Joiner {protected Box join(Box p, Box q) {return new HorizontallyJoinedPair(p, q);}}class VerticalJoiner extends Joiner {protected Box join(Box p, Box q) {return new VerticallyJoinedPair(p, q);}}4.2.2.8 CollectorsA Collector accepts messages on either channel and relays them to a single successor:class Collector extends SingleOutputPushStageimplements DualInputPushStage {public void putA(Box p) { next1().putA(p);}public void putB(Box p) { next1().putA(p); }}If for some reason we needed to impose a bottleneck here, we could define an alternative form ofcollector in which these methods are declared as synchronized . This could also be used toguarantee that at most one activity is progressing through a given collector at any given time.4.2.2.9 Dual output stagesOur multiple-output stages should generate threads or use one of the other options discussed in § 4.1to drive at least one of their outputs (it doesn't matter which). This maintains liveness when elementsare ultimately passed to Combiner stages (here, the Joiners ). For simplicity of illustration, thefollowing classes create new Threads . Alternatively, we could set up a simple worker thread poolto process these messages.Alternators output alternate inputs to alternate successors:class Alternator extends DualOutputPushStageimplements PushStage {protected boolean outTo2 = false; // control alternationprotected synchronized boolean testAndInvert() {boolean b = outTo2;outTo2 = !outTo2;return b;}public void putA(final Box p) {if (testAndInvert())next1().putA(p);else {new Thread(new Runnable() {public void run() { next2().putA(p); }}).start();}}}Cloners multicast the same element to both successors:class Cloner extends DualOutputPushStageimplements PushStage {public void putA(Box p) {final Box p2 = p.duplicate();next1().putA(p);new Thread(new Runnable() {public void run() { next2().putA(p2); }}).start();}}A Screener is a stage that directs all inputs obeying some predicate to one channel, and all othersto the other:We can build a generic Screener by encapsulating the BoxPredicate to check in an interfaceand implementing it, for example, with a class that makes sure that a Box fits within a given(symmetric, in this case) bound. The Screener itself accepts a BoxPredicate and uses it todirect outputs:interface BoxPredicate {boolean test(Box p);}class MaxSizePredicate implements BoxPredicate {protected final int max; // max size to let throughpublic MaxSizePredicate(int maximum) { max = maximum; }public boolean test(Box p) {return p.size().height <= max && p.size().width <= max;}}class Screener extends DualOutputPushStageimplements PushStage {protected final BoxPredicate predicate;public Screener(BoxPredicate p) { predicate = p; }public void putA(final Box p) {if (predicate.test(p)) {new Thread(new Runnable() {public void run() { next1().putA(p); }}).start();}elsenext2().putA(p);}}4.2.2.10 SourcesHere is a sample source, one that produces BasicBoxes of random sizes. For convenience, it isalso equipped with an autonomous loop run method repeatedly invoking produce , interspersedwith random production delays:class BasicBoxSource extends SingleOutputPushStageimplements PushSource, Runnable {protected final Dimension size;// maximum sizesprotected final int productionTime; // simulated delaypublic BasicBoxSource(Dimension s, int delay) {size = s;productionTime = delay;}protected Box makeBox() {return new BasicBox((int)(Math.random() * size.width) + 1,(int)(Math.random() * size.height) + 1);}public void produce() {next1().putA(makeBox());}public void run() {try {for (;;) {produce();Thread.sleep((int)(Math.random() * 2* productionTime));}}catch (InterruptedException ie) { } // die}}4.2.2.11 CoordinationWithout a scripting tool based on these classes, we have to program assembly lines by manuallycreating instances of desired stages and linking them together. This is easy in principle, but tediousand error-prone in practice because of the lack of visual guidance about what stages are connected towhat.Here's a fragment of the flow used in the applet that produced the image displayed at the beginning ofthis section:The code setting this up may be found in the online supplement. The main constructor mostly consistsof many lines of the form:Stage aStage = new Stage();aStage.attach(anotherStage);This is followed by invoking start on threads running all the sources.4.2.3 Further ReadingsFlow patterns often serve as the computational versions of use cases, scenarios, scripts, and relatedconcepts from high-level object-oriented analysis. Most of the books on OO design and on designpatterns listed in § 1.3.5 and § 1.4.5 describe issues relevant to the analysis, design andimplementation of flow-based systems. Domain-specific issues surrounding packet networking,telecommunications, and multimedia systems often requiring more elaborate flow-based designs arediscussed in the texts on concurrent and distributed systems in § 1.2.5.4.3 Services in ThreadsMany tasks compute results or provide services that are not immediately used by their clients, but areeventually required by them. In these situations, unlike those involving oneway messages, a client'sactions at some point become dependent on completion of the task.This section describes some of the available design alternatives: adding callbacks to onewaymessages, relying on Thread.join , building utilities based on Futures, and creating workerthreads. Section § 4.4 revisits and extends these techniques in the context of improving theperformance of computationally intensive tasks on parallel processors.4.3.1 Completion CallbacksFrom the perspective of pure oneway message passing, the most natural way to deal with completionis for a client to activate a task via a oneway message to a server, and for the server later to indicatecompletion by sending a oneway callback message to the caller. This efficient, asynchronous,notification-based style applies best in loosely-coupled designs in which completion of the servicetriggers some independent action in the client. Completion callback designs are sometimes structurallyidentical to Observer designs (see § 3.5.2).For example, consider an application that offers several features, of which one or more require that acertain file be read in first. Because IO is relatively slow, you don't want to disable other featureswhile the file is being read in — this would decrease responsiveness. One solution is to create aFileReader service that asynchronously reads in the file, and then issues a message back to theapplication when it has completed, so that the application can proceed with the feature(s) that requireit.4.3.1.1 InterfacesTo set up such a FileReader , or any other service using completion callbacks, you must firstdefine a client interface for callback messages. The methods in this interface are substitutes of sortsfor the kinds of return types and exceptions that would be associated with procedural versions of theservice. This usually requires two kinds of methods, one associated with normal completion, and oneassociated with failure that is invoked upon any exception.Additionally, callback methods often require an argument indicating which action completed, so thatthe client can sort them out when there are multiple calls. In many cases this can be accomplishedsimply by sending back some of the call arguments. In more general schemes, the service hands backa unique identifier (usually known as a cookie) both as the return value for the initial request and as anargument in any callback method. Variants of this technique are used behind the scenes in remoteinvocation frameworks that implement procedural calls via asynchronous messages across networks.In the case of FileReader , we could use interfaces such as:interface FileReader {void read(String filename, FileReaderClient client);}interface FileReaderClient {void readCompleted(String filename, byte[] data);void readFailed(String filename, IOException ex);}4.3.1.2 ImplementationsThere are two styles for implementing these interfaces, depending on whether you'd like the client orthe server to create the thread that performs the service. Generally, if the service can be useful withoutrunning in its own thread, then control should be assigned to clients.In the more typical case in which the use of threads is intrinsic to completion callback designs, controlis assigned to the service method. Note that this causes callback methods to be executed in the threadconstructed by the service, not one directly constructed by the client. This can lead to surprisingresults if any code relies on thread-specific properties such as ThreadLocal andjava.security.AccessControlContext (see § 2.3.2) that are not known by theservice.Here we could implement a client and server using a service-creates-thread approach as:class FileReaderApp implements FileReaderClient {Fragmentsprotected FileReader reader = new AFileReader();//public void readCompleted(String filename, byte[] data) {// ... use data ...}public void readFailed(String filename, IOException ex){// ... deal with failure ...}public void actionRequiringFile() {reader.read("AppFile", this);}public void actionNotRequiringFile() { ... }}class AFileReader implements FileReader {public void read(final String fn, final FileReaderClient c) {new Thread(new Runnable() {public void run() { doRead(fn, c); }}).start();}protected void doRead(String fn, FileReaderClient client) {byte[] buffer = new byte[1024]; // just for illustrationtry {FileInputStream s = new FileInputStream(fn);s.read(buffer);if (client != null) client.readCompleted(fn, buffer);}catch (IOException ex) {if (client != null) client.readFailed(fn, ex);}}}The service class here is written to deal with a null client argument, thus accommodating clientsthat do not need callbacks. While this is not particularly likely here, callbacks in many services can betreated as optional. As an alternative, you could define and use a NullFileReaderClientclass that contains no-op versions of the callback methods (see Further Readings). Also, as far as theservice is concerned, the callback target might as well be any object at all, for example some helper ofthe object that requests the service. You can also replace callbacks with event notifications using thetechniques illustrated in § 3.1.1.6.4.3.1.3 Guarding callback methodsIn some applications, clients can process completion callbacks only when they are in particular states.Here, the callback methods themselves should contain guards that suspend processing of eachincoming callback until the client can deal with it.For example, suppose we have a FileReaderClient that initiates a set of asynchronous filereads and needs to process them in the order issued. This construction mimics how remote invocationsare usually handled: Typically each request is assigned a sequence number, and replies are processedin sequence order. This can be a risky strategy, since it will cause indefinite never completes. Thisdrawback could be addressed by associating time-outs with the waits.class FileApplication implements FileReaderClient { //Fragmentsprivate String[] filenames;private int currentCompletion; // index of ready file{public synchronized void readCompleted(String fn, byte[] d)// wait until ready to process this callbackwhile (!fn.equals(filenames[currentCompletion])) {try { wait(); }catch(InterruptedException ex) { return; }}// ... process data...// wake up any other thread waiting on this condition:++currentCompletion;notifyAll();}public synchronized void readFailed(String fn, IOExceptione){// similar...}public synchronized void readfiles() {currentCompletion = 0;for (int i = 0; i < filenames.length; ++i)reader.read(filenames[i],this);}}4.3.2 Joining ThreadsWhile completion callbacks are very flexible, they are at best awkward to use when a caller just needsto wait out a particular task that it started.If an operation occurring in some thread A cannot continue until some thread B completes, you canblock thread A via any of the waiting and notification techniques discussed in Chapter 3. For example,assuming the existence of a Latch (see § 3.4.2) named terminated accessible from both threadsA and B , thread A may wait via terminated.acquire() , and thread B may executeterminated.release() upon otherwise completing its task.However, there is usually no reason to set up your own waiting and notification constructions, sincethis functionality is already provided by Thread.join : The join method blocks the caller whilethe target isAlive . Terminating threads automatically perform notifications. The monitor objectused internally for this waiting and notification is arbitrary and may vary across JVMimplementations. In most, the target Thread object itself is used as the monitor object. (This is onereason for not extending class Thread to add run methods that invoke waiting or notificationmethods.) In cases where these details of Thread.join don't fit the needs of a particularapplication, you can always fall back to the manual approach.Either Thread.join or explicitly coded variants can be used in designs where a client needs aservice to be performed but does not immediately rely on its results or effects. (This is sometimesknown as deferred-synchronous invocation.) This is often the case when the service task is time-consuming and can benefit from CPU and/or IO parallelism, so that running it in a separate thread canimprove overall throughput.One common application is image processing. Obtaining the raw data for an image from a file orsocket and then converting it into a form that can be displayed are time-consuming operations thatinvolve both CPU and IO processing. Often, this processing can be overlapped with other display-related operations.A version of this strategy is used by java.awt.MediaTracker and related classes, whichshould be used when they apply. Here, we'll illustrate a more generic version that can be extended andrefined in various ways to support specialized applications.To set this up, suppose there is a generic Pic interface for images, and a Renderer interfacedescribing services that accept a URL pointing to image data and ultimately return a Pic . (In a morerealistic setting, the render method would surely also throw various failure exceptions. Here, wewill assume that it simply returns null on any failure.) Also, assume existence of aStandardRenderer class implementing interface Renderer .Thread.join can be used to write clients such as the following PictureApp class (whichinvokes several made-up methods just for the sake of illustration). It creates a Runnable waiterobject that both initiates the rendering thread and keeps track of the returned result.While it is common practice, the use of unsynchronized (or direct) access of internal result fieldsas seen in the waiter object is a bit delicate. Since access is not synchronized, correctness relies onthe fact that both thread termination and the join method intrinsically employ synchronizedmethods or blocks (see § 2.2.7).interface Pic {byte[] getImage();}interface Renderer {Pic render(URL src);}class PictureApp {// Code sketch// ...private final Renderer renderer = new StandardRenderer();public void show(final URL imageSource) {class Waiter implements Runnable {private Pic result = null;Pic getResult() { return result; }public void run() {result = renderer.render(imageSource);}};Waiter waiter = new Waiter();Thread t = new Thread(waiter);t.start();displayBorders();displayCaption();// do other things// while renderingtry {t.join();}catch(InterruptedException e) {cleanup();return;}Pic pic = waiter.getResult();if (pic != null)displayImage(pic.getImage());else// ... deal with assumed rendering failure}}Thread.join returns control to the caller whether the thread completed successfully orabnormally. For simplicity of illustration, nullness of the result field is used here to indicate anykind of failure, including cancellation of the renderer. The version in § 4.3.3.1 illustrates a moreresponsible approach.4.3.3 FuturesThe operations underlying join-based constructions can be packaged in a more convenient andstructured fashion by:••Creating Futures — "virtual" data objects that automatically block when clients try to invoketheir field accessors before their computation is complete. A Future acts as an "IOU" for agiven data object.Creating versions of service methods that start up one or more threads and then return Futureobjects that are unblocked when computations complete.Because the mechanics surrounding futures are built into data access and service methods, they can beapplied in a general fashion only if both the data objects and the service methods are defined usinginterfaces, not classes. However, if the associated interfaces are defined, Futures are easy to set up.For example, a Future-based AsynchRenderer can employ proxies around concreteimplementation classes (see § 1.4.2):class AsynchRenderer implements Renderer {private final Renderer renderer = new StandardRenderer();static class FuturePic implements Pic { // inner classprivate Pic pic = null;private boolean ready = false;synchronized void setPic(Pic p) {pic = p;ready = true;notifyAll();}}}public synchronized byte[] getImage() {while (!ready)try { wait(); }catch (InterruptedException e) { return null; }return pic.getImage();}public Pic render(final URL src) {final FuturePic p = new FuturePic();new Thread(new Runnable() {public void run() { p.setPic(renderer.render(src)); }}).start();return p;}For illustration, AsynchRenderer uses explicit waiting and notification operations based on aready flag rather than relying on Thread.join .Applications relying on this class can be written in a simple fashion:class PicturAppWithFuture {// Codesketchprivate final Renderer renderer = new AsynchRenderer();public void show(final URL imageSource) {Pic pic = renderer.render(imageSource);displayBorders();displayCaption();}// do other things ...byte[] im = pic.getImage();if (im != null)displayImage(im);else // deal with assumed rendering failure}4.3.3.1 CallablesMost designs based on Futures take exactly the form illustrated in class AsynchRenderer . Theconstruction and use of such classes can be further standardized and automated by stepping up to ablander interface.In the same way that interface Runnable describes any pure action, a Callable interface can beused to describe any service method that accepts an Object argument, returns an Object result,and may throw an Exception :interface Callable {Object call(Object arg) throws Exception;}The use of Object here (awkwardly) accommodates, for example, adaptation of methods acceptingmultiple arguments by stuffing them into array objects.While there are other options, it is most convenient to package up support mechanics via a single classthat coordinates usage. The following FutureResult class shows one set of choices. (It is astreamlined version of one in the util.concurrent package available from the onlinesupplement.)The FutureResult class maintains methods to get the result Object that is returned, or theException that is thrown by a Callable . Unlike our Pic versions where all failures were justindicated via null values, it deals with interruptions more honestly by throwing exceptions back toclients attempting to obtain results.To differentiate properly between exceptions encountered in the service versus those encounteredtrying to execute the service, exceptions thrown by the Callable are repackaged usingj ava.lang.reflect.InvocationTargetException , a general-purpose class forwrapping one exception inside another.Also, for the sake of generality, the FutureResult does not itself create threads. Instead, itsupports method setter that returns a Runnable that users can then execute within a thread orany other code Executor (see § 4.1.4). This makes Callables usable within lightweightexecutable frameworks that are otherwise set up to handle tasks initiated via oneway messages. As analternative strategy, you could set up a Caller framework that is otherwise similar to Executor ,but is more specialized to the needs of service-style tasks, for example supporting methods to scheduleexecution, check status, and control responses to exceptions.class FutureResult {// Fragmentsprotected Object value = null;protected boolean ready = false;protected InvocationTargetException exception = null;public synchronized Object get()throws InterruptedException, InvocationTargetException {while (!ready) wait();if (exception != null)throw exception;elsereturn value;}public Runnable setter(final Callable function) {return new Runnable() {public void run() {try {set(function.call());}catch(Throwable e) {setException(e);}}};}synchronized void set(Object result) {value = result;ready = true;notifyAll();}synchronized void setException(Throwable e) {exception = new InvocationTargetException(e);ready = true;notifyAll();}// ... other auxiliary and convenience methods ...}The FutureResult class can be used directly to support generic Futures or as a utility inconstructing more specialized versions. As an example of direct use:class PictureDisplayWithFutureResult {sketch// Codeprivate final Renderer renderer = new StandardRenderer();// ...public void show(final URL imageSource) {try {FutureResult futurePic = new FutureResult();Runnable command = futurePic.setter(new Callable() {public Object call() {return renderer.render(imageSource);}});new Thread(command).start();displayBorders();displayCaption();displayImage(((Pic)(futurePic.get())).getImage());}}catch (InterruptedException ex) {cleanup();return;}catch (InvocationTargetException ex) {cleanup();return;}}This example demonstrates some of the minor awkwardnesses introduced by reliance on genericutilities that help standardize usage protocols. This is one reason that you might want to useFutureResult in turn to construct a more specialized and easier-to-use version with the samemethods and structure as the AsynchRenderer class.4.3.4 Scheduling ServicesAs discussed in § 4.1.4, worker thread designs can sometimes improve performance compared tothread-per-task designs. They can also be used to schedule and optimize execution of service requestsmade by different clients.As a famous example, consider a class controlling read and write access for a disk containing manycylinders but only one read/write head. The interface for the service contains just read and writemethods. In practice, it would surely use file block indicators instead of raw cylinder numbers andwould deal with or throw various IO exceptions, here abbreviated as a single Failure exception.interface Disk {void read(int cylinderNumber, byte[] buffer) throws Failure;void write(int cylinderNumber, byte[] buffer) throwsFailure;}Rather than servicing access requests in the order they are made, it is faster on average to sweep thehead across the cylinders, accessing cylinders in ascending order and then resetting the head positionback to the beginning after each sweep. (Depending in part on the type of disk, it may be even betterto arrange requests in both ascending and descending sweeps, but we will stick to this version.)This policy would be tricky to implement without some kind of auxiliary data structure. The enablingcondition for a request to execute is:Wait until the current request cylinder number is the least greater cylinder number relative to that ofthe current disk head of all of those currently waiting, or is the least numbered cylinder if the headcylinder number is greater than that of all requests.This condition is too awkward, inefficient, and possibly even deadlock-prone to try to coordinateacross a set of otherwise independent clients. But it can be implemented fairly easily with the help ofan ordered queue employed by a single worker thread. Tasks can be added to the queue in cylinder-based order, then executed when their turns arrive. This "elevator algorithm" is easiest to arrange byusing a two-part queue, one for the current sweep and one for the next sweep.The resulting framework combines Future-like constructs with the worker thread designs from § 4.1.4.To set this up, we can define a Runnable class to include the extra bookkeeping associated withDiskTasks . The queue class uses the semaphore-based approach discussed in § 3.4.1, but hereapplied to ordered linked lists. The server class constructs a worker thread that runs tasks from thequeue. The public service methods create tasks, place them on the queue, and then wait them outbefore returning to clients.abstract class DiskTask implements Runnable {protected final int cylinder;// read/write parametersprotected final byte[] buffer;protected Failure exception = null;// to relay outprotected DiskTask next = null;// for use in queueprotected final Latch done = new Latch(); // status indicatorDiskTask(int c, byte[] b) { cylinder = c; buffer = b; }abstract void access() throws Failure; // read or writepublic void run() {try { access(); }catch (Failure ex) { setException(ex); }finally { done.release(); }}void awaitCompletion() throws InterruptedException {done.acquire();}synchronized Failure getException() { return exception; }synchronized void setException(Failure f) { exception = f; }}class DiskReadTask extends DiskTask {DiskReadTask(int c, byte[] b) { super(c, b); }void access() throws Failure { /* ... raw read ... */ }}class DiskWriteTask extends DiskTask {DiskWriteTask(int c, byte[] b) { super(c, b); }void access() throws Failure { /* ... raw write ... */ }}class ScheduledDisk implements Disk {protected final DiskTaskQueue tasks = new DiskTaskQueue();public void read(int c, byte[] b) throws Failure {readOrWrite(new DiskReadTask(c, b));}public void write(int c, byte[] b) throws Failure {readOrWrite(new DiskWriteTask(c, b));}protected void readOrWrite(DiskTask t) throws Failure {tasks.put(t);try {t.awaitCompletion();}catch (InterruptedException ex) {Thread.currentThread().interrupt(); // propagatethrow new Failure(); // convert to failure exception}Failure f = t.getException();if (f != null) throw f;}public ScheduledDisk() {// construct worker threadnew Thread(new Runnable() {public void run() {try {for (;;) {tasks.take().run();}}catch (InterruptedException ie) {} // die}}).start();}}class DiskTaskQueue {protected DiskTask thisSweep = null;protected DiskTask nextSweep = null;protected int currentCylinder = 0;protected final Semaphore available = new Semaphore(0);void put(DiskTask t) {insert(t);available.release();}DiskTask take() throws InterruptedException {available.acquire();return extract();}synchronized void insert(DiskTask t) {DiskTask q;if (t.cylinder >= currentCylinder) {// determine queueq = thisSweep;if (q == null) { thisSweep = t; return; }}else {q = nextSweep;if (q == null) { nextSweep = t; return; }}DiskTask trail = q;// ordered linked list insertq = trail.next;for (;;) {if (q == null || t.cylinder < q.cylinder) {trail.next = t; t.next = q;return;}else {trail = q; q = q.next;}}}synchronized DiskTask extract() { // PRE: not emptyif (thisSweep == null) {// possibly swap queuesthisSweep = nextSweep;nextSweep = null;}DiskTask t = thisSweep;thisSweep = t.next;currentCylinder = t.cylinder;return t;}}4.3.5 Further ReadingsABCL was among the first concurrent object-oriented languages to offer Futures as a languageconstruct. See:Yonezawa, Akinori, and Mario Tokoro. Object-Oriented Concurrent Programming, MIT Press, 1988.Futures are known as wait-by-necessity constructions in Eiffel// (a parallel extension to Eiffel). See:Caromel, Denis, and Yves Roudier. "Reactive Programming in Eiffel//", in Jean-Pierre Briot, Jean-Marc Geib and Akinori Yonezawa (eds.) Object Based Parallel and Distributed Computing, LNCS1107, Springer Verlag, 1996.Futures and related constructs in the Scheme and Multilisp programming languages are described in:Dybvig, R. Kent and Robert Hieb. "Engines from Continuations", Computer Languages, 14(2):109-123, 1989.Feeley, Marc. An Efficient and General Implementation of Futures on Large Scale Shared-MemoryMultiprocessors, PhD Thesis, Brandeis University, 1993.Additional techniques associated with completion callbacks in networking applications are describedin:Pyarali, Irfan, Tim Harrison, and Douglas C. Schmidt. "Asynchronous Completion Token", in RobertMartin, Dirk Riehle, and Frank Buschmann (eds.), Pattern Languages of Program Design, Volume 3,Addison-Wesley, 1999.The Null Object pattern is often useful for simplifying callback designs in which clients do not alwaysrequire callback messages. See:Woolf, Bobby. "Null Object", in Robert Martin, Dirk Riehle, and Frank Buschmann (eds.), PatternLanguages of Program Design, Volume 3, Addison-Wesley, 1999.4.4 Parallel DecompositionParallel programs are specifically designed to take advantage of multiple CPUs for solvingcomputation-intensive problems. The main performance goals are normally throughput and scalability— the number of computations that can be performed per unit time, and the potential for improvementwhen additional computational resources are available. However, these are often intertwined withother performance goals. For example, parallelism may also improve response latencies for a servicethat hands off work to a parallel execution facility.Among the main challenges of parallelism in the Java programming language is to construct portableprograms that can exploit multiple CPUs when they are present, while at the same time working wellon single processors, as well as on time-shared multiprocessors that are often processing unrelatedprograms.Some classic approaches to parallelism don't mesh well with these goals. Approaches that assumeparticular architectures, topologies, processor capabilities, or other fixed environmental constraints areill suited to commonly available JVM implementations. While it is not a crime to build run-timesystems with extensions specifically geared to particular parallel computers, and to write parallelprograms specifically targeted to them, the associated programming techniques necessarily fall outsidethe scope of this book. Also, RMI and other distributed frameworks can be used to obtain parallelismacross remote machines. In fact, most of the designs discussed here can be adapted to use serializationand remote invocation to achieve parallelism over local networks. This is becoming a common andefficient means of coarse-grained parallel processing. However, these mechanics also lie outside thescope of this book.We instead focus on three families of task-based designs, fork/join parallelism, computation trees, andbarriers. These techniques can yield very efficient programs that exploit multiple CPUs when present,yet still maintain portability and sequential efficiency. Empirically, they are known to scale well, atleast up through dozens of CPUs. Moreover, even when these kinds of task-based parallel programsare tuned to maximally exploit a given hardware platform, they require only minor retunings tomaximally exploit other platforms.As of this writing, probably the most common targets for these techniques are applications servers andcompute servers that are often, but by no means always, multiprocessors. In either case, we assumethat CPU cycles are usually available, so the main goal is to exploit them to speed up the solution ofcomputational problems. In other words, these techniques are unlikely to be very helpful whenprograms are run on computers that are already nearly saturated.4.4.1 Fork/JoinFork/join decomposition relies on parallel versions of divide-and-conquer techniques familiar insequential algorithm design. Solutions take the form:pseudoclass Solver {// Pseudocode// ...Result solve(Param problem) {if (problem.size <= BASE_CASE_SIZE)return directlySolve(problem);else {Result l, r;IN-PARALLEL {l = solve(lefthalf(problem));r = solve(rightHalf(problem));}return combine(l, r);}}}It takes some hard work and inspiration to invent a divide-and-conquer algorithm. But many commoncomputationally intensive problems have known solutions of approximately this form. Of course,there may be more than two recursive calls, multiple base cases, and arbitrary pre- and post-processingsurrounding any of the cases.Familiar sequential examples include quicksort, mergesort, and many data structure, matrix, andimage processing algorithms. Sequential recursive divide-and-conquer designs are easy to parallelizewhen the recursive tasks are completely independent; that is, when they operate on different parts of adata set (for example different sections of an array) or solve different sub-problems, and need nototherwise communicate or coordinate actions. This often holds in recursive algorithms, even those notoriginally intended for parallel implementation.Additionally, there are recursive versions of algorithms (for example, matrix multiplication) that arenot used much in sequential contexts, but are more widely used on multiprocessors because of theirreadily parallelizable form. And other parallel algorithms perform extensive transformations andpreprocessing to convert problems into a form that can be solved using fork/join techniques. (SeeFurther Readings in § 4.4.4.)The IN-PARALLEL pseudocode is implemented by forking and later joining tasks performing therecursive calls. However, before discussing how to do this, we first examine issues and frameworksthat permit efficient parallel execution of recursively generated tasks.4.4.1.1 Task granularity and structureMany of the design forces encountered when implementing fork/join designs surround taskgranularity:Maximizing parallelism. In general, the smaller the tasks, the more opportunities for parallelism. Allother things being equal, using many fine-grained tasks rather than only a few coarse-grained taskskeeps more CPUs busy, improves load balancing, locality and scalability, decreases the percentage oftime that CPUs must idly wait for one another, and leads to greater throughput.Minimizing overhead. Constructing and managing an object to process a task in parallel, rather thanjust invoking a method to process it serially, is the main unavoidable overhead associated with task-based programming compared with sequential solutions. It is intrinsically more costly to create anduse task objects than to create and use stack-frames. Additionally, the use of task objects can add tothe amount of argument and result data that must be transmitted and can impact garbage collection.All other things being equal, total overhead is minimized when there are only a few coarse-grainedtasks.Minimizing contention. A parallel decomposition is not going to lead to much speed-up if each taskfrequently communicates with others or must block waiting for resources held by others. Tasks shouldbe of a size and structure that maintain as much independence as possible. They should minimize (inmost cases, eliminate) use of shared resources, global (static) variables, locks, and other dependencies.Ideally, each task would contain simple straight-line code that runs to completion and then terminates.However, fork/join designs require at least some minimal synchronization. The main object thatcommences processing normally waits for all subtasks to finish before proceeding.Maximizing locality. Each subtask should be the only one operating on some small piece of aproblem, not only conceptually but also at the level of lower-level resources and memory accesspatterns. Refactorings that achieve good locality of reference can significantly improve performanceon modern heavily cached processors. When dealing with large data sets, it is not uncommon topartition computations into subtasks with good locality even when parallelism is not the main goal.Recursive decomposition is often a productive way to achieve this. Parallelism accentuates the effectsof locality. When parallel tasks all access different parts of a data set (for example, different regions ofa common matrix), partitioning strategies that reduce the need to transmit updates across caches oftenachieve much better performance.4.4.1.2 FrameworksThere is no general optimal solution to granularity and related task structuring issues. Any choicerepresents a compromise that best resolves the competing forces for the problem at hand. However, itis possible to build lightweight execution frameworks that support a wide range of choices along thecontinuum.Thread objects are unnecessarily heavy vehicles for supporting purely computational fork/jointasks. For example, these tasks never need to block on IO, and never need to sleep . They requireonly an operation to synchronize across subtasks. Worker thread techniques discussed in § 4.1.4 canbe extended to construct frameworks efficiently supporting only the necessary constructs. While thereare several approaches, for concreteness we'll limit discussion to a framework inutil.concurrent that restricts all tasks to be subclasses of class FJTask . Here is a briefsketch of principal methods. More details are discussed along with examples in § 4.4.1.4 through §4.4.1.7.abstract class FJTask implements Runnable {boolean isDone();// True after task is runvoid cancel();// Prematurely set as donevoid fork();// Start a dependent taskvoid start();// Start an arbitrary taskstatic void yield();// Allow another task torunvoid join();// Yield caller until donestatic void invoke(FJTask t);// Directly run tstatic void coInvoke(FJTask t,FJTask u);// Fork and join t and ustatic void coInvoke(FJTask[] tasks); // coInvoke allvoid reset();// Clear to allow reuse}An associated FJTaskRunnerGroup class provides control and entry points into this framework.A FJTaskRunnerGroup is constructed with a given number of worker threads that shouldordinarily be equal to the number of CPUs on a system. The class supports method invoke thatstarts up a main task, which will in turn normally create many others.FJTasks must employ only these task control methods, not arbitrary Thread or monitor methods.While the names of these operations are the same or similar to those in class Thread , theirimplementations are very different. In particular, there are no general suspension facilities. Forexample, the join operation is implemented simply by having the underlying worker thread runother tasks to completion until the target task is noticed to have completed (via isDone ). Thiswouldn't work at all with ordinary threads, but is effective and efficient when all tasks are structuredas fork/join methods.These kinds of trade-offs make FJTask construction and invocation substantially cheaper thanwould be possible for any class supporting the full Thread interface. As of this writing, on at leastsome platforms, the overhead of creating, running, and otherwise managing a FJTask for the kindsof examples illustrated below is only between four and ten times that of performing equivalentsequential method calls.The main effect is to lessen the impact of overhead factors when making choices about taskpartitioning and granularity. The granularity threshold for using tasks can be fairly small — on theorder of a few thousand instructions even in the most conservative cases — without noticeablydegrading performance on uniprocessors. Programs can exploit as many CPUs as are available oneven the largest platforms without the need for special tools to extract or manage parallelism.However, success also depends on construction of task classes and methods that themselves minimizeoverhead, avoid contention, and preserve locality.4.4.1.3 Defining tasksSequential divide-and-conquer algorithms can be expressed as fork/join-based classes via thefollowing steps:1. Create a task class with:o Fields to hold arguments and results. Most should be strictly local to a task, neveraccessed from any other task. This eliminates the need for synchronizationsurrounding their use. However, in the typical case where result variables areaccessed by other tasks, they should either be declared as volatile or beaccessed only via synchronized methods.o A constructor that initializes argument variables.o A run method that executes the reworked method code.2. Replace the original recursive case with code that:o Creates subtask objects.o Forks each one to run in parallel.o Joins each of them.o Combines results by accessing result variables in the subtask objects.3. Replace (or extend) the original base case check with a threshold check. Problem sizes lessthan the threshold should use the original sequential code. This generalization of base casechecks maintains efficiency when problem sizes are so small that task overhead overshadowspotential gains from parallel execution. Tune performance by determining a good thresholdsize for the problem at hand.4. Replace the original method with one that creates the associated task, waits it out, and returnsany results. (In the FJTask framework, the outermost call is performed viaFJTaskRunnerGroup.invoke .)4.4.1.4 FibonacciWe'll illustrate the basic steps with a very boring and unrealistic, but very simple classic example:recursively computing fib, the Fibonacci function. This function can be programmed sequentially as:int seqFib(int n) {if (n <= 1)return n;elsereturn seqFib(n-1) + seqFib(n-2);}This example is unrealistic because there is a much faster non-recursive solution for this particularproblem, but it is a favorite for demonstrating both recursion and parallelism. Because it does so littleother computation, it makes the basic structure of fork/join designs easier to see, yet it generates manyrecursive calls — at least fib(n) calls to compute fib(n). The first few values of the sequence are 0, 1,1, 2, 3, 5, 8; fib(10) is 55; fib(20) is 6,765; fib(30) is 832,040; fib(40) is 102,334,155.Function seqFib can be transformed into a task class such as the following:class Fib extends FJTask {static final int sequentialThreshold = 13; // for tuningvolatile int number;// argument/resultFib(int n) { number = n; }int getAnswer() {if (!isDone())throw new IllegalStateException("Not yet computed");return number;}public void run() {int n = number;if (n <=numberelse {Fib f1Fib f2sequentialThreshold)= seqFib(n);= new Fib(n - 1);= new Fib(n - 2);coInvoke(f1, f2);}}// base case// create subtasks// fork then join bothnumber = f1.number + f2.number;// combine resultspublic static void main(String[] args) { // sample drivertry {int groupSize = 2;// 2 worker threadsint num = 35;// compute fib(35)FJTaskRunnerGroup group = newFJTaskRunnerGroup(groupSize);Fib f = new Fib(num);group.invoke(f);int result = f.getAnswer();System.out.println("Answer: " + result);}catch (InterruptedException ex) {} // die}}Notes:•••The class maintains a field holding the argument for which to compute the Fibonaccifunction. Also, we need a variable to hold the result. However, as is fairly typical in suchclasses, there is no need to keep two variables. For economy (bearing in mind that manymillions of Fib objects might be constructed in the course of a computation), we can micro-optimize to use one variable, and overwrite the argument with its result after it is computed.(This is the first of several hand-optimizations that are uncomfortably petty, but are shownhere in order to demonstrate minor tweaks that can be pragmatically important in constructingefficient parallel programs.)The number field is declared as volatile to ensure visibility from other tasks/threadsafter it is computed (see § 2.2.7). Here and in subsequent examples, volatile fields areread and/or written only once per task execution, and otherwise held in local variables. Thisavoids interfering with potential compiler optimizations that are otherwise disabled whenusing volatile .Alternatively, we could have synchronized access to the number field. But there is no goodreason to do so. The use of volatile fields is much more common in lightweight paralleltask frameworks than in general-purpose concurrent programming. Tasks usually do notrequire other synchronization and control mechanics, yet often need to communicate resultsvia field access. The most common reason for using synchronized instead ofvolatile is to deal with arrays. Individual array elements cannot be declared asvolatile . Processing arrays within synchronized methods or blocks is the simplestway to ensure visibility of array updates, even in the typical case in which locking is not•••••••••otherwise required. An occasionally attractive alternative is instead to create arrays each ofwhose elements is a forwarding object with volatile fields.The method isDone returns true after the completion of a run method that has beenexecuted via invoke or coInvoke . It is used as a guard in getAnswer to help detectprogramming errors that could occur if the ultimate consumer of an answer tries to access itprematurely. (There is no chance of this happening here, but this safeguard helps avoidunintended usages.)The sequentialThreshold constant establishes granularity. It represents the balancepoint at which it is not worth the overhead to create tasks, also reflecting the goal ofmaintaining good sequential performance. For example, on one set of runs on a four-CPUsystem, setting sequentialThreshold to 13 resulted in a 4% performancedegradation versus seqFib for large argument values when using a single worker thread.But it sped up by a factor of at least 3.8 with four worker threads, processing several millionFib tasks per second.Rather than wiring in a compile-time constant, we could have defined the threshold as a run-time variable and set it to a value based on the number of CPUs available or other platformcharacteristics. This is useful in task-based programs that do not scale linearly, as is likely tobe true even here. As the number of CPUs increase, so do communication and resourcemanagement costs, which could be balanced by increasing the threshold.The parallel analog of recursion is performed via a convenient method,coInvoke(FJTask t, FJTask u) , which in turn acts as:t.fork(); invoke(u); t.join();The fork method is a specialized analog of Thread.start . A forked task is alwaysprocessed in stack-based LIFO order when it is run by the same underlying worker thread thatspawned it, but in queue-based FIFO order with respect to other tasks if run by anotherworker thread running in parallel. This represents a cross of sorts between normal stack-basedsequential calls, and normal queue-based thread scheduling. This policy (implemented viadouble-ended scheduling queues) is ideal for recursive task-based parallelism (see FurtherReadings), and more generally whenever dealing with strictly dependent tasks — those thatare spawned either by the tasks that ultimately join them or by their subtasks.In contrast, FJTask.start behaves more like Thread.start . It employs queue-based FIFO scheduling with respect to all worker threads. It is used, for example, byFJTaskRunnerGroup.invoke to start up execution of a new main task.The join method should be used only for tasks initiated via fork . It exploits terminationdependency patterns of fork/join subtasks to optimize execution.The FJTask.invoke method runs the body of one task within another task, and waits outcompletion. Seen differently, it is the one-task version of coInvoke , an optimization ofu.fork(); u.join() .Effective use of any lightweight executable framework requires the same understanding of supportmethods and their semantics as does programming with ordinary Threads . The FJTaskframework exploits the symbiosis between recursion and parallel decomposition, and so encouragesthe divide-and-conquer programming style seen in Fib . However, the range of programming idiomsand design patterns conforming to this general style is fairly broad, as illustrated by the followingexamples.4.4.1.5 Linking subtasksFork/join techniques may be applied even when the number of forked subtasks varies dynamically.Among several related tactics for carrying this out, you can add link fields so that subtasks can bemaintained in lists. After spawning all tasks, an accumulate (also known as reduction) operation cantraverse the list sequentially, joining and using the results of each subtask.Stretching the Fib example a bit, the FibVL class illustrates one way to set this up. This style ofsolution is not especially useful here, but is applicable in contexts in which a dynamic number ofsubtasks are created, possibly across different methods. Notice that the subtasks here are joined in theopposite order in which they were created. Since the processing order of results does not matter here,we use the simplest possible linking algorithm (prepending), which happens to reverse the order oftasks during traversal. This strategy applies whenever the accumulation step is commutative andassociative with respect to results, so tasks can be processed in any order. If the order did matter, wewould need to adjust list construction or traversal accordingly.class FibVL extends FJTask {volatile int number; // as beforefinal FibVL next;// embedded linked list of siblingtasksFibVL(int n, FibVL list) { number = n; next = list; }public void run() {int n = number;if(n <= sequentialThreshold)number = seqFib(n);else {FibVL forked = null;// list of subtasksforked = new FibVL(n - 1, forked); // prepends to listforked.fork();forked = new FibVL(n - 2, forked);forked.fork();number = accumulate(forked);}}}// Traverse list, joining each subtask and adding to resultint accumulate(FibVL list) {int sum = 0;for (FibVL f = list; f != null; f = f.next) {f.join();sum += f.number;}return sum;}4.4.1.6 CallbacksRecursive task-based fork/join parallelism may be extended to apply when other local synchronizationconditions are used instead of join . In the FJTask framework, t.join() is implemented as anoptimized version of:while (!t.isDone()) yield();Method yield here allows the underlying worker thread to process other tasks. (More specifically,in the FJTask framework, the thread will process at least one other task if one exists.)Any other condition may be used in this construction rather than isDone , as long as you are certainthat the predicate being waited for will eventually become true due to the actions of a subtask (or oneof its subtasks, and so on). For example, rather than relying on join, task control can rely on countersthat keep track of task creation and completion. A counter can be incremented on each fork anddecremented when the forked task has produced a result. This and related counter-based schemes canbe attractive choices when subtasks communicate back results via callbacks rather than via access toresult fields. Counters of this form are small-scale, localized versions of the barriers discussed in §4.4.3.Callback-based fork/join designs are seen, for example, in problem-solving algorithms, games,searching, and logic programming. In many such applications, the number of subtasks that are forkedcan vary dynamically, and subtask results are better captured by method calls than by field extraction.Callback-based approaches also permit greater asynchrony than techniques such as the linked tasks in§ 4.4.1.5. This can lead to better performance when subtasks differ in expected duration, since theresult processing of quickly completing subtasks can sometimes overlap with continued processing oflonger ones. However, this design gives up all result ordering guarantees, and thus is applicable onlywhen subtask result processing is completely independent of the order in which results are produced.Callback counters are used in the following class FibVCB , which is not at all well-suited for theproblem at hand but serves to exemplify techniques. This code illustrates a typical but delicatecombination of task-local variables, volatiles , and locking in an effort to keep task controloverhead to a minimum:class FibVCB extends FJTask {// ...volatile int number = 0;// as beforefinal FibVCB parent;// is null for outermost callint callbacksExpected = 0;volatile int callbacksReceived = 0;FibVCB(int n, FibVCB p) { number = n; parent = p; }// Callback method invoked by subtasks upon completionsynchronized void addToResult(int n) {number += n;++callbacksReceived;}public void run() {int n = number;// same structure as join-based versionif (n <= sequentialThreshold)number = seqFib(n);else {// Clear number so subtasks can fill innumber = 0;// Establish number of callbacks expectedcallbacksExpected = 2;new FibVCB(n - 1, this).fork();new FibVCB(n - 2, this).fork();// Wait for callbacks from childrenwhile (callbacksReceived < callbacksExpected) yield();}}}// Call back parentif (parent != null) parent.addToResult(number);Notes:•••••••All mutual exclusion locking is restricted to small code segments protecting field accesses, asmust be true for any class in a lightweight task framework. Tasks are not allowed to blockunless they are sure they will be able to continue soon. In particular, this frameworkunenforceably requires that synchronized blocks not span forks and subsequentjoins or yields .To help eliminate some synchronization, the callback count is split into two counters,callbacksExpected and callbacksReceived . The task is done when they areequal.The callbacksExpected counter is used only by the current task, so access need notbe synchronized , and it need not be volatile . In fact, since exactly two callbacksare always expected in the recursive case and the value is never needed outside the runmethod, this class could easily be reworked in a way that eliminates all need for this variable.However, such a variable is needed in more typical callback-based designs where the numberof forks may vary dynamically and may be generated across multiple methods.The addToResult callback method must be synchronized to avoid interferenceproblems when subtasks call back at about the same time.So long as both number and callbacksReceived are declared as volatile , andcallbacksReceived is updated as the last statement of addToResult , the yieldloop test need not involve synchronization because it is waiting for a latching threshold that,once reached, will never change (see § 3.4.2.1).We could also define a reworked getAnswer method that uses these mechanics so that itreturns an answer if all callbacks have been received. However, since this method is designedto be called by external (non-task) clients upon completion of the overall computation, thereis no compelling reason to do this. The version from the original Fib class suffices.Despite these measures, the overhead associated with task control in this version is greaterthan that of the original version using coInvoke . If you were to use it anyway, you wouldprobably choose a slightly larger sequential threshold, and thus exploit slightly lessparallelism.4.4.1.7 CancellationIn some designs, there is no need for keeping counts of callbacks or exhaustively traversing throughsubtask lists. Instead, tasks complete when any subtask (or one of its subtasks, and so on) arrives at asuitable result. In these cases, you can avoid wasting computation by cancelling any subtasks in themidst of producing results that will not be needed.The options here are similar to those seen in other situations involving cancellation (see § 3.1.2). Forexample, subtasks can regularly invoke a method (perhaps isDone ) in their parents that indicatesthat an answer has already been found, and if so to return early. They must also set their own status, soany of their subtasks can do the same. This can be implemented here using FJTask.cancel thatjust prematurely sets isDone status. This suppresses execution of tasks that have not yet beenstarted, but has no effect on tasks in the midst of execution unless the tasks' run methods themselvesdetect updated status and deal with it.When an entire set of tasks are all trying to compute a single result, an even simpler strategy suffices:Tasks may regularly check a global ( static ) variable that indicates completion. However, whenthere are many tasks, and many CPUs, more localized strategies may still be preferable to one thatplaces so much pressure on the underlying system by generating many accesses to the same memorylocation, especially if it must be accessed under synchronization. Additionally, bear in mind that thetotal overhead associated with cancellation should be less than the cost of just letting small tasks runeven if their results are not needed.For example, here is a class that solves the classic N-Queens problem, searching for the placement ofN queens that do not attack each other on a chessboard of size NxN. For simplicity of illustration, itrelies on a static Result variable. Here tasks check for cancellation only upon entry into themethod. They will continue looping through possible extensions even if a result has already beenfound. However, the generated tasks will immediately exit. This can be slightly wasteful, but mayobtain a solution more quickly than a version that checks for completion upon every iteration of everytask.Note also here that the tasks do not bother joining their subtasks since there is no reason to do so. Onlythe ultimate external caller (in main ) needs to wait for a solution; this is supported here by addingstandard waiting and notification methods to the Result class. (Also, for compactness, this versiondoes not employ any kind of granularity threshold. It is easy to add one, for example by directlyexploring moves rather than forking subtasks when the number of rows is close to the board size.)class NQueens extends FJTask {static int boardSize; // fixed after initialization in main// Boards are arrays where each cell represents a row,// and holds the column number of the queen in that rowstatic class Result {// holder for ultimate resultprivate int[] board = null; // non-null when solvedsynchronized boolean solved() { return board != null; }synchronized void set(int[] b) { // Support use by non-Tasksif (board == null) { board = b; notifyAll(); }}synchronized int[] await() throws InterruptedException {while (board == null) wait();return board;}}static final Result result = new Result();public static void main(String[] args) {boardSize = ...;FJTaskRunnerGroup tasks = new FJTaskRunnerGroup(...);int[] initialBoard = new int[0]; // start with empty boardtasks.execute(new NQueens(initialBoard));int[] board = result.await();// ...}final int[] sofar;// initial configurationNQueens(int[] board) { this.sofar = board;public void run() {if (!result.solved()) {int row = sofar.length;if (row >= boardSize)result.set(sofar);else {}// skip if already solved// done// try all expansionsfor (int q = 0; q < boardSize; ++q) {row{// Check if queen can be placed in column q of nextboolean attacked = false;for (int i = 0; i < row; ++i) {int p = sofar[i];if (q == p || q == p - (row-i) || q == p + (row-i))}}attacked = true;break;// If so, fork to explore moves from newconfigurationif (!attacked) {// build extended board representationint[] next = new int[row+1];}}}}}for (int k = 0; k < row; ++k) next[k] = sofar[k];next[row] = q;new NQueens(next).fork();}4.4.2 Computation TreesA number of computationally intensive algorithms involve tasks of the form:For a fixed number of steps, or until convergence, do {Update one section of a problem;Wait for other tasks to finish updating their sections;}Most often, such algorithms perform update operations on partitioned arrays, matrices, or imagerepresentations. For example, many physical dynamics problems involve repeated local updates to thecells of a matrix. Jacobi algorithms and related relaxation techniques repeatedly recalculate estimatedvalues across neighboring cells, typically using an averaging formula such as:void oneStep(double[][] oldMatrix,double[][] newMatrix, int i, int j) {newMatrix[i][j] = 0.25 * (oldMatrix[i-1][j] +oldMatrix[i][j-1] +oldMatrix[i+1][j] +oldMatrix[i][j+1]);}Normally, to save space, two different matrices are swapped as newMatrix and oldMatrixacross successive steps.Algorithms requiring that all tasks periodically wait for all others to complete do not always scalequite as well as more loosely coupled fork/join designs. Even so, these algorithms are common,efficient, and amenable to significant parallel speedups.4.4.2.1 Building and using treesIt would be inefficient to repeatedly apply fork/join decomposition in iterative designs in order toupdate sections in parallel. Because the sections are the same across iterations, they can be constructedjust once and then repeatedly invoked so that on each iteration, the corresponding updates execute inthe same order as would be produced by a recursive solution.Computation trees are explicit representations of the tree-structured computations implicitly arising infork/join recursion. These trees have two kinds of nodes, internal nodes and leaf nodes, correspondingto the recursive and base cases of a recursive solution. They can be constructed and used for iterativeupdate problems via the following steps:1. Create a tree of task objects representing the recursive partitions, where:o Each internal node contains references to subpartitions, and has an update methodthat performs fork/join processing of each of them.o Each leaf node represents a finest-granularity partition, and has an update methodthat operates directly on it.2. For a fixed number of steps, or until convergence, do:o Execute the task performing the root partition's update method.For example, the following code illustrates the highlights of a set of classes that perform Jacobiiteration using the averaging formula shown above. In addition to updating, this version also keepstrack of the differences among computed cell values across iterations, and stops when the maximumdifference is within a constant EPSILON . Also, like many programs of this form, this code assumesthat the matrices have been set up with extra edge cells that are never updated, so boundary conditionsnever need to be checked. (Alternatives include recomputing edge values using special edge formulasafter each pass, and treating edges as toroidally wrapping around the mesh.)The recursive decomposition strategy used here is to divide the mesh into quadrants, stopping whenthe number of cells is at most leafCells , which serves as the granularity threshold. This strategyworks well so long as the numbers of rows and columns in the matrix are approximately equal. If theyare not, additional classes and methods could be defined to divide across only one dimension at a time.The approach here assumes that the matrix as a whole already exists, so rather than actually dividingup cells, task nodes just keep track of the row and column offsets of this matrix that each partition isworking on.The subclass-based design used here reflects the different structure and behavior of internal versusleaf nodes. Both are subclasses of abstract base JTree :abstract class JTree extends FJTask {volatile double maxDiff; // for convergence check}class Interior extends JTree {private final JTree[] quads;Interior(JTree q1, JTree q2, JTree q3, JTree q4) {quads = new JTree[] { q1, q2, q3, q4 };}public void run() {coInvoke(quads);double md = 0.0;for (int i = 0; i < quads.length; ++i) {md = Math.max(md,quads[i].maxDiff);quads[i].reset();}maxDiff = md;}}class Leaf extends JTree {private final double[][] A; private final double[][] B;private final int loRow;private final int hiRow;private final int loCol;private final int hiCol;private int steps = 0;Leaf(double[][] A, double[][] B,int loRow, int hiRow, int loCol, int hiCol) {this.A = A;this.B = B;this.loRow = loRow; this.hiRow = hiRow;this.loCol = loCol; this.hiCol = hiCol;}public synchronized void run() {boolean AtoB = (steps++ % 2) == 0;double[][] a = (AtoB)? A : B;double[][] b = (AtoB)? B : A;double md = 0.0;for (int i = loRow; i <= hiRow; ++i) {for (int j = loCol; j <= hiCol; ++j) {b[i][j] = 0.25 * (a[i-1][j] + a[i][j-1] +a[i+1][j] + a[i][j+1]);md = Math.max(md, Math.abs(b[i][j] - a[i][j]));}}maxDiff = md;}}The driver class first builds a tree that represents the partitioning of its argument matrix. The buildmethod could itself be parallelized. But because the base actions are just node constructions, thegranularity threshold would be so high that parallelization would be worthwhile only for hugeproblem sizes.The run method repeatedly sets the root task in motion and waits out completion. For simplicity ofillustration, it continues until convergence. Among other changes necessary to turn this into a realisticprogram, you would need to initialize the matrices and deal with possible lack of convergence within abounded number of iterations. Because each iteration entails a full synchronization point waiting forthe root task to finish, it is relatively simple to insert additional operations that maintain or reportglobal status between iterations.class Jacobi extends FJTask {static final double EPSILON = 0.001; // convergencecriterionfinal JTree root;final int maxSteps;Jacobi(double[][] A, double[][] B,int firstRow, int lastRow, int firstCol, int lastCol,int maxSteps, int leafCells) {this.maxSteps = maxSteps;root = build(A, B, firstRow, lastRow, firstCol, lastCol,leafCells);}public void run() {for (int i = 0; i < maxSteps; ++i) {invoke(root);if (root.maxDiff < EPSILON) {System.out.println("Converged");return;}else root.reset();}}static JTree build(double[][] a, double[][] b,int lr, int hr, int lc, int hc, int size) {if ((hr - lr + 1) * (hc - lc + 1) <= size)return new Leaf(a, b, lr, hr, lc, hc);int mr = (lr + hr) / 2; // midpointsint mc = (lc + hc) / 2;return new Interior(build(a, b, lr,mr, lc,mc, size),build(a, b, lr,mr, mc+1, hc, size),build(a, b, mr+1, hr, lc,mc, size),build(a, b, mr+1, hr, mc+1, hc, size));}}4.4.3 BarriersRecursive decomposition is a powerful and flexible technique, but does not always fit well with thestructure of iterative problems, and usually requires adoption of a lightweight execution frameworkfor efficient implementation. A more direct path to a solution of many iterative problems is first todivide the problem into segments, each with an associated task performing a loop that mustperiodically wait for other segments to complete. From the perspective of tree-based approaches, thesedesigns flatten out all the internal nodes and just deal with the leaves.As with recursive tasks, there are opportunities to specialize Threads to make them more attuned tothe demands of parallel iteration (see Further Readings). However, there is usually less to be gainedby doing so, in part because all thread construction overhead is restricted to the start-up phase. Herewe illustrate the basic mechanics using regular Threads each executing a single Runnable .When using Threads , granularity thresholds must in general be substantially higher than whenusing lightweight executable classes (although still substantially lower than those needed indistributed parallel designs). But the basic logic of iterative algorithms is otherwise identical,regardless of granularity. In many iterative problems, little potential parallelism is wasted by usingcoarse granularities. When all threads perform approximately the same actions for approximately thesame durations, creating only as many tasks as CPUs, or perhaps a small multiple of the number ofCPUs, can work well.While it is always possible to hand-craft the necessary control mechanics using waiting andnotification constructs, it is both more convenient and less error-prone instead to rely on standardizedsynchronization aids that encapsulate these mechanics. The synchronization device of choice initerative designs is a cyclic barrier. A cyclic barrier is initialized with a fixed number of parties thatwill be repeatedly synchronizing. It supports only one method, barrier , that forces each caller towait until all parties have invoked the method, and then resets for the next iteration. A basicCyclicBarrier class can be defined as follows:class CyclicBarrier {protected final int parties;protected int count;// parties currently being waitedforprotected int resets = 0; // times barrier has been trippedCyclicBarrier(int c) { count = parties = c; }synchronized int barrier() throws InterruptedException {int index = --count;if (index > 0) {// not yet trippedint r = resets;// wait until next resetdo { wait(); } while (resets == r);}else {// tripcount = parties;// reset count for next time++resets;notifyAll();// cause all other parties toresume}return index;}}(The util.concurrent version of this class available from the online supplement deals moreresponsibly with interruptions and time-outs. Fancier versions that reduce memory contention on thelock and on the fields may be worth constructing on systems with very large numbers of processors.)The CyclicBarrier.barrier method defined here returns the number of other threads thatwere still waiting when the barrier was entered, which can be useful in some algorithms. As anotherby-product, the barrier method is intrinsically synchronized , so it also serves as a memorybarrier to ensure flushes and loads of array element values in its most typical usage contexts (see §2.2.7).A barrier may also be construed as a simple consensus operator (see § 3.6). It gathers "votes" amongseveral threads about whether they should all continue to the next iteration. Release occurs when allvotes have been collected and agreement has thus been reached. (However, unlike transactionframeworks, threads using this CyclicBarrier class are not allowed to vote "no".)With barriers, many parallel iterative algorithms become easy to express. In the simplest cases, theseprograms might take the form (eliding all problem-specific details):class Segment implements Runnable {// Code sketchfinal CyclicBarrier bar; // shared by all segmentsSegment(CyclicBarrier b, ...) { bar = b; ...; }void update() { ... }}public void run() {// ...for (int i = 0; i < iterations; ++i) {update();bar.barrier();}// ...}class Driver {// ...void compute(Problem problem) throws ... {int n = problem.size / granularity;CyclicBarrier barrier = new CyclicBarrier(n);Thread[] threads = new Thread[n];// createfor (int i = 0; i < n; ++i)threads[i] = new Thread(new Segment(barrier, ...));// triggerfor (int i = 0; i < n; ++i) threads[i].start();}}// await terminationfor (int i = 0; i < n; ++i) threads[i].join();This structure suffices for problems requiring known numbers of iterations. However, many problemsrequire checks for convergence or some other global property between iterations. (Conversely, in afew chaotic relaxation algorithms you don't even need a barrier after each iteration, but can instead letsegments free-run for a while between barriers and/or checks.)One way to provide convergence checks is to rework the CyclicBarrier class to optionally runa supplied Runnable command whenever a barrier is about to be reset. A more classic approach,which illustrates a technique useful in other contexts as well, is to rely on the index returned bybarrier . The caller obtaining index zero (as an arbitrary, but always legal choice) can perform thecheck while all others are quietly waiting for a second barrier.For example, here a a barrier-based version of a segment class for the Jacobi problem described in §4.4.2. Collections of JacobiSegment objects can be initialized and run by a driver of the genericform given above.class JacobiSegment implements Runnable {// Incomplete// These are same as in Leaf class version:double[][] A;double[][] B;final int firstRow; final int lastRow;final int firstCol; final int lastCol;volatile double maxDiff;int steps = 0;void update() { /* Nearly same as Leaf.run */ }final CyclicBarrier bar;final JacobiSegment[] allSegments; // for convergence checkvolatile boolean converged = false;JacobiSegment(double[][] A, double[][] B,int firstRow, int lastRow,}int firstCol, int lastCol,CyclicBarrier b, JacobiSegment[] allSegments) {this.A = A;this.B = B;this.firstRow = firstRow; this.lastRow = lastRow;this.firstCol = firstCol; this.lastCol = lastCol;this.bar = b;this.allSegments = allSegments;public void run() {try {while (!converged) {update();int myIndex = bar.barrier(); // wait for all to updateif (myIndex == 0) convergenceCheck();bar.barrier();// wait for convergence check}}catch(Exception ex) {// clean up ...}}void convergenceCheck() {for (int i = 0; i < allSegments.length; ++i)if (allSegments[i].maxDiff > EPSILON) return;for (int i = 0; i < allSegments.length; ++i)allSegments[i].converged = true;}}4.4.4 Further ReadingsFor a survey of approaches to high-performance parallel processing, seeSkillicorn, David, and Domenico Talia, "Models and Languages for Parallel Computation",Computing Surveys, June 1998.Most texts on parallel programming concentrate on algorithms designed for use on fine-grainedparallel machine architectures, but also cover design techniques and algorithms that can beimplemented using the kinds of stock multiprocessors most amenable to supporting a JVM. See, forexample:Foster, Ian. Designing and Building Parallel Programs, Addison Wesley, 1995.Roosta, Seyed. Parallel Processing and Parallel Algorithms, Springer-Verlag, 1999.Wilson, Gregory. Practical Parallel Programming, MIT Press, 1995.Zomaya, Albert (ed.). Parallel and Distributed Computing Handbook, McGraw-Hill, 1996.Pattern-based accounts of parallel programming include:Massingill, Berna, Timothy Mattson, and Beverly Sanders. A Pattern Language for ParallelApplication Programming, Technical report, University of Florida, 1999.MacDonald, Steve, Duane Szafron, and Jonathan Schaeffer. "Object-Oriented Pattern-Based ParallelProgramming with Automatically Generated Frameworks", in Proceedings of the 5th USENIXConference on Object-Oriented Tools and Systems (COOTS), 1999.The FJTask framework internally relies on a work-stealing task scheduler based on the one in Cilk,a C-based parallel programming framework. In work-stealing schedulers, each worker thread normallyruns (in LIFO order) tasks that it constructs, but when idle steals (in FIFO order) those constructed byother worker threads. More details, including explanations of the senses in which this scheme isoptimal for recursive fork/join programs, may be found in:Frigo, Matteo, Charles Leiserson, and Keith Randall. "The Implementation of the Cilk-5Multithreaded Language", Proceedings of 998 ACM SIGPLAN Conference on ProgrammingLanguage Design and Implementation (PLDI), 1998.The online supplement includes more realistic examples of the techniques discussed in this section. Italso provides links to the Cilk package and related frameworks, including Hood (a C++ follow-on toCilk) and Filaments (a C package that includes a specialized framework supporting barrier-basediterative computation).4.5 Active ObjectsIn the task-based frameworks illustrated throughout most of this chapter, threads are used to propelconceptually active messages sent among conceptually passive objects. However, it can be productiveto approach some design problems from the opposite perspective — active objects sending each otherpassive messages.To illustrate, consider an active object that conforms to the WaterTank description in Chapter 1:pseudoclass ActiveWaterTank extends Thread {//Pseudocode// ...public void run() {for (;;) {accept message;if (message is of form addWater(float amount)) {if (currentVolume >= capacity) {if (overflow != null) {send overflow.addWater(amount);accept response;if (response is of form OverflowException)reply response;else ...else ...else ...}else if (message is of form removeWater(float amount)) {...}}}}Pseudocode is used here because there is no built-in syntax for passing messages from one activeobject to another, only for direct invocation among passive objects. However, as discussed in § 4.1.1,similar issues may be encountered even when using passive objects. Any of the solutions describedthere apply equally well here: adopting message formats of various kinds, transported across streams,channels, event queues, pipes, sockets, and so on. In fact, as shown in the WebService exampleleading off this chapter, it is easy to add task-based constructions to designs otherwise based on activeobjects. Conversely, most task-based designs discussed in this chapter work equally well when someobjects are active rather than passive.Further, the use of Runnables as messages leads to a boring but universal (at least in some senses)form of active object: a minor variant of a common worker thread design that also conforms to theinitial abstract characterization of active objects as interpreters in § 1.2.4:class ActiveRunnableExecutor extends Thread {Channel me = ... // used for all incoming messages}public void run() {try {for (;;) {((Runnable)(me.take())).run();}}catch (InterruptedException ie) {} // die}Of course, such classes are not very useful unless they also include internal methods that manufactureRunnables to execute and/or send to other active objects. It is possible, but unnatural, to writeentire programs in this fashion.However, many components in reactive systems can be usefully construed as active objects thatoperate under more constrained rules and message-passing disciplines. This includes especially thoseobjects that interact with other computers or devices, often the main externally visible objects in aprogram.In distributed frameworks such as CORBA and RMI, externally visible active objects are themselvesascribed interfaces listing the messages that they accept. Internally, they usually have a more uniformstructure than does ActiveWaterTank . Typically, they contain a main run loop that repeatedlyaccepts external requests, dispatches to internal passive objects providing the corresponding service,and then constructs reply messages that are sent back to clients. (The internal passive objects are theones explicitly programmed when using CORBA and RMI. The active objects, sometimes known asskeletons, are usually generated automatically by tools.)It is very possible to take an active, actor-style approach to the design of other components as well.One reason for designing entire systems from this point of view is to take advantage of well-developed theory and design techniques associated with particular sets of rules surrounding activeentities and their messages. The remainder of this section gives a brief overview of the most well-known and influential such framework, CSP.4.5.1 CSPC.A.R. Hoare's theory of Communicating Sequential Processes (CSP) provides both a formalapproach to concurrency and an associated set of design techniques. As discussed in the FurtherReadings in § 4.5.2, there are a number of closely related approaches, but CSP has had the largestimpact on concurrent design and programming. CSP has served as the basis of programminglanguages (including occam ), was influential in the design of others (including Ada), and can besupported in the Java programming language through the use of library classes.The following account illustrates the JCSP package developed by Peter Welch and colleagues. Thepackage is available via links from the online supplement. This section provides only a brief synopsis.Interested readers will want to obtain copies of the package, its documentation, and related texts.4.5.1.1 Processes and channelsA CSP process can be construed as a special kind of actor-style object, in which:••••Processes have no method interface and no externally invocable methods. Because there areno invocable methods, it is impossible for methods to be invoked by different threads. Thusthere is no need for explicit locking.Processes communicate only by reading and writing data across channels.Processes have no identity, and so cannot be explicitly referenced. However, channels serveas analogs of references (see § 1.2.4), allowing communication with whichever process is atthe other end of a channel.Processes need not spin forever in a loop accepting messages (although many do). They mayread and write messages on various channels as desired.A CSP channel can be construed as a special kind of Channel , in which:•All channels are synchronous (see § 3.4.1.4), and so contain no internal buffering. (However,you can construct processes that perform buffering.)••Channels support only read ("?") and write ("!") operations carrying data values. Theoperations behave in the same way as take and put .The most fundamental channels are one-to-one. They may be connected only to a single pairof processes, a writer and a reader. Multiple-reader and multiple-writer channels may also bedefined.4.5.1.2 CompositionMuch of the elegance of CSP stems from its simple and analytically tractable composition rules. The"S" in CSP stands for Sequential, so basic processes perform serial computations on internal data (forexample adding numbers, conditional tests, assignment, looping). Higher-level processes are built bycomposition; for a channel c , variable x , and processes P and Q :c?x -> Pc!x -> PP ; QP || QP [] QReading from c enables PWriting to c enables PP followed by QP and Q in parallelP or Q (but not both)The choice operator P [] Q requires that P and Q both be communication-enabled processes (of formd?y -> R or d!y -> R ). The choice of which process runs depends on which communication isready: Nothing happens until one or both communications are ready. If one is (or becomes) ready, thatbranch is taken. If both are (or become) ready, either choice may be taken (nondeterministically).4.5.1.3 JCSPThe JCSP package supports CSP-based design in a straightforward way. It consists of an executionframework that efficiently supports CSP constructs represented via interfaces, classes, and methods,including:••••Interfaces ChannelInput (supporting read ), ChannelOutput (supportingwrite ) and Channel (supporting both) operate on Object arguments, but specialversions for int arguments are also provided. The principal implementation class isOne2OneChannel that supports use only by a single reader and a single writer. Butvarious multiway channels are also provided.Interface CSProcess describes processes supporting only method run . Implementationclasses Parallel and Sequence (and others) have constructors that accept arrays ofother CSProcess objects and create composites.The choice operator [] is supported via the Alternative class. Its constructor acceptsarrays with elements of type Guard . Alternative supports a select method thatreturns an index denoting which of them can (and then must) be chosen. A fairSelectmethod works in the same way but provides additional fairness guarantees — over the courseof multiple selects, it will choose fairly among all ready alternatives rather than alwaysselecting one of them. The only usages of Alternative demonstrated below use guardtype AltingChannelInput , which is implemented by One2OneChannel .Additional utilities include CSProcess implementations such as Timer (which doesdelayed writes and can also be used for time-outs in Alternative ), Generate (whichgenerates number sequences), Skip (which does nothing at all — one of the CSPprimitives), and classes that permit interaction and display via AWT.4.5.1.4 Dining philosophersAs a classic demonstration, consider the famous Dining Philosophers problem. A table holds fiveforks (arranged as pictured) and a bowl of spaghetti. It seats five philosophers, each of whom eat for awhile, then think for a while, then eat, and so on. Each philosopher requires two forks — the ones onthe left and right — to eat (no one knows why; it is just part of the story) but releases them whenthinking.The main problem to be solved here is that, without some kind of coordination, the philosophers couldstarve when they pick up their left forks and then block forever trying to pick up their right forkswhich are being held by other philosophers.There are many paths to a solution (and yet more paths to non-solution). We'll demonstrate onedescribed by Hoare that adds a requirement (enforced by a Butler) that at any given time, at most fourphilosophers are allowed to be seated. This requirement suffices to ensure that at all times at least onephilosopher can eat — if there are only four philosophers, at least one of them can get both forks. Thissolution does not by itself ensure that all five philosophers eventually eat. But this guarantee can beobtained via use of Alternative.fairSelect in the Butler class to ensure fairprocessing of seating messages.We'll use a simple, pure CSP style where all channels are one-to-one and messages have no content(using null for messages). This puts a stronger focus on the synchronization and processconstruction issues. The system is composed of a College with five Philosophers , fiveForks , and one Butler (standing in the bowl of spaghetti!), connected usingOne2OneChannels .Since everything must be either a process or a channel, forks must be processes. A Forkcontinuously loops waiting for a message from one of its users (either its left-hand or right-handphilosopher). When it gets a message from one indicating a fork pick-up, it waits for anotherindicating a fork put-down. (While it might be more tasteful to indicate pick-ups versus put-downs viadifferent kinds of messages or message contents, this protocol using null messages suffices.)In JCSP, this can be written as:class Fork implements CSProcess {private final AltingChannelInput[] fromPhil;Fork(AltingChannelInput l, AltingChannelInput r) {fromPhil = new AltingChannelInput[] { l, r };}public void run() {Alternative alt = new Alternative(fromPhil);for (;;) {int i = alt.select();fromPhil[i].read();fromPhil[i].read();}// await message from either// pick up// put down}}The Butler process makes sure that at most N-1 (i.e., four here) philosophers are seated at anygiven time. It does this by enabling both enter and exit messages if there are enough seats, butonly exit messages otherwise. Because Alternative operates on arrays of alternatives, thisrequires a bit of manipulation to set up. (Some other utilities in JCSP could be used to simplify this.)The exit channels are placed before the enter channels in the chans array so that the properchannel will be read no matter which Alternative is used. The fairSelect is employedhere to ensure that the same four philosophers are not always chosen if a fifth is also trying to enter.class Butler implements CSProcess {private final AltingChannelInput[] enters;private final AltingChannelInput[] exits;Butler(AltingChannelInput[] e, AltingChannelInput[] x) {enters = e;exits = x;}public void run() {int seats = enters.length;int nseated = 0;// set up arrays for selectAltingChannelInput[] chans = newAltingChannelInput[2*seats];for (int i = 0; i < seats; ++i) {chans[i] = exits[i];chans[seats + i] = enters[i];}Alternative either = new Alternative(chans);Alternative exit = new Alternative(exits);for (;;) {// if max number are seated, only allow exitsAlternative alt = (nseated < seats-1)? either : exit;int i = alt.fairSelect();chans[i].read();}// if i is in first half of array, it is an exit messageif (i < seats) --nseated; else ++nseated;}}The Philosopher processes run forever in a loop, alternating between thinking and eating. Beforeeating, philosophers must first enter their seats, then get both forks. After eating, they do the opposite.The eat and think methods are just no-ops here, but could be fleshed out to (for example) helpanimate a demonstration version by reporting status to JCSP channels and processes that interface intoAWT.class Philosopher implements CSProcess {privateprivateprivateprivatefinalfinalfinalfinalChannelOutputChannelOutputChannelOutputChannelOutputleftFork;rightFork;enter;exit;Philosopher(ChannelOutput l, ChannelOutput r,ChannelOutput e, ChannelOutput x) {leftFork = l;rightFork = r;enter = e;exit = x;}public void run() {for (;;) {think();enter.write(null);// get seatleftFork.write(null);// pick up leftrightFork.write(null);// pick up righteat();leftFork.write(null);rightFork.write(null);exit.write(null);// put down left// put down right// leave seat}}}private void eat() {}private void think() {}Finally, we can create a College class to represent the parallel composition of the Forks ,Philosophers , and Butler . The channels are constructed using a JCSP convenience functioncreate that creates arrays of channels. The Parallel constructor accepts an array ofCSProcess , which is first loaded with all of the participants.class College implements CSProcess {final static int N = 5;private final CSProcess action;College() {One2OneChannel[]One2OneChannel[]One2OneChannel[]One2OneChannel[]lefts = One2OneChannel.create(N);rights = One2OneChannel.create(N);enters = One2OneChannel.create(N);exits = One2OneChannel.create(N);Butler butler = new Butler(enters, exits);Philosopher[] phils = new Philosopher[N];for (int i = 0; i < N; ++i)phils[i] = new Philosopher(lefts[i], rights[i],enters[i], exits[i]);Fork[] forks = new Fork[N];for (int i = 0; i < N; ++i)forks[i] = new Fork(rights[(i + 1) % N], lefts[i]);action = new Parallel(new CSProcess[] {butler,new Parallel(phils),new Parallel(forks)});}public void run() { action.run(); }public static void main(String[] args) {new College().run();}}4.5.2 Further ReadingsCSP has proven to be a successful approach to the design and analysis of systems that can be usefullyexpressed as bounded sets of identityless, interfaceless processes communicating via synchronouschannels. CSP was introduced in:Hoare, C. A. R. Communicating Sequential Processes, Prentice Hall, 1985.An updated account appears in:Roscoe, A. William. The Theory and Practice of Concurrency, Prentice Hall, 1997.Several of the texts listed in Chapter 1 (including the book by Burns and Welling in § 1.2.5.4) discussCSP in the course of describing constructs in occam and Ada.Other related formalisms, design techniques, languages, and frameworks have adopted different baseassumptions that adhere more closely to the characteristics of other concurrent systems and/or todifferent styles of analysis. These include Milner's CCS and π-calculus, and Berry's Esterel. See:Milner, Robin. Communication and Concurrency, Prentice Hall, 1989.Berry, Gerard. "The Foundations of Esterel", in Gordon Plotkin, Colin Stirling, and Mads Tofte (eds.),Proof, Language and Interaction, MIT Press, 1998.As package support becomes available for these and related approaches to concurrent system design,they become attractive alternatives to the direct use of thread-based constructs in the development ofsystems that are best viewed conceptually as collections of active objects. For example, Triveni is anapproach based in part on Esterel, and is described in:Colby, Christopher, Lalita Jategaonkar Jagadeesan, Radha Jagadeesan, Konstantin Läufer, and CarlosPuchol. "Objects and Concurrency in Triveni: A Telecommunication Case Study in Java", USENIXConference on Object-Oriented Technologies and Systems (COOTS), 1998.Triveni is supported by a Java programming language package (see the online supplement). Among itsmain differences from CSP is that active objects in Triveni communicate by issuing events. Trivenialso includes computation and composition rules surrounding the interruption and suspension ofactivities upon reception of events, which adds to expressiveness especially in real-time designcontexts.
88
a
across
actions
also
an
and
based
be
because
by
callbacks
Calls
can
cannot
care
catching
centralized
clients
code
compensating
control
different
difficult
error
escape
events
exception
exceptions
expected
extensible
failure
failures
flow
handlers
handling
how
However
in
is
it
know
known
make
manage
method
more
need
needed
notification
notifications
objects
of
offload
one
operations
or
other
otherwise
part
parts
predict
processing
related
replacing
requires
resilient
respond
responses
rules
some
stack
system
t
techniques
that
the
their
they
thread
threads
to
use
used
useful
when
with
wouldn
you
